1
00:00:04,970 --> 00:00:08,670
Okay. Let's get started again.

2
00:00:08,670 --> 00:00:11,445
Okay. So welcome back to, um,

3
00:00:11,445 --> 00:00:14,895
week three of CS224N.

4
00:00:14,895 --> 00:00:20,760
Okay. So we- we've got a bit of a change of pace today after week two.

5
00:00:20,760 --> 00:00:24,190
So, um, this week in week three,

6
00:00:24,190 --> 00:00:28,205
we're actually going to have some human language,

7
00:00:28,205 --> 00:00:32,630
and so this lecture has no partial derivative signs in it.

8
00:00:32,630 --> 00:00:35,030
And so we'll be moving away, um,

9
00:00:35,030 --> 00:00:39,715
from sort of working out the so technicalities of doing, um,

10
00:00:39,715 --> 00:00:42,735
new networks and back propagation,

11
00:00:42,735 --> 00:00:45,435
um, and a sort of math heavy week two.

12
00:00:45,435 --> 00:00:46,680
So then, this week,

13
00:00:46,680 --> 00:00:48,855
what we actually want- well,

14
00:00:48,855 --> 00:00:51,165
in today's lecture, we want to look at, well,

15
00:00:51,165 --> 00:00:55,455
what kind of structures do human language sentences have,

16
00:00:55,455 --> 00:00:58,515
and how we can build models that,

17
00:00:58,515 --> 00:01:02,990
um, build that kind of structure for sentences that we see.

18
00:01:02,990 --> 00:01:05,090
Um, so first of all,

19
00:01:05,090 --> 00:01:08,795
I'm gonna sort of explain and motivate a bit about,

20
00:01:08,795 --> 00:01:11,150
um, structure of human language sentences.

21
00:01:11,150 --> 00:01:13,250
So, that's kind of like, um,

22
00:01:13,250 --> 00:01:16,040
linguistics in 20 minutes or something.

23
00:01:16,040 --> 00:01:19,850
Um, then going particularly focusing on dependency grammars,

24
00:01:19,850 --> 00:01:23,495
and then gonna present a method for doing dependency structure,

25
00:01:23,495 --> 00:01:27,905
dependency grammar parsing called transition-based dependency parsing.

26
00:01:27,905 --> 00:01:33,795
And then talk about how you can make neural, um, dependency parsers.

27
00:01:33,795 --> 00:01:36,390
Um, so, um, going on just,

28
00:01:36,390 --> 00:01:38,130
you know, a couple of announcements.

29
00:01:38,130 --> 00:01:42,120
So, assignment two was due one minute ago,

30
00:01:42,120 --> 00:01:44,595
so I hope everyone's succeeded,

31
00:01:44,595 --> 00:01:47,430
um, in getting assignment two out of the way.

32
00:01:47,430 --> 00:01:49,200
If you're still working on it,

33
00:01:49,200 --> 00:01:50,720
do make sure to make, um,

34
00:01:50,720 --> 00:01:52,790
use of the office hours and get help for that.

35
00:01:52,790 --> 00:01:56,060
Coming out just today is assignment three.

36
00:01:56,060 --> 00:01:58,640
Um, assignment three, um,

37
00:01:58,640 --> 00:02:01,385
is basically about this lecture.

38
00:02:01,385 --> 00:02:03,350
Um, so, [LAUGHTER] in assignment three,

39
00:02:03,350 --> 00:02:06,994
what you're doing is building a neural dependency parser,

40
00:02:06,994 --> 00:02:09,980
and so we hope that you can put together what you learned about

41
00:02:09,980 --> 00:02:13,445
neural networks last week and the content of today,

42
00:02:13,445 --> 00:02:17,750
and jump straight right in to building a neural dependency parser.

43
00:02:17,750 --> 00:02:21,830
Um, the other thing that happens in assignment three is that,

44
00:02:21,830 --> 00:02:25,080
we start using a deep learning framework PyTorch.

45
00:02:25,080 --> 00:02:28,680
So, for doing assignment three, instruction zero,

46
00:02:28,680 --> 00:02:30,945
and this is in the PDF for the assignment,

47
00:02:30,945 --> 00:02:34,515
is to install PyTorch as a Python package,

48
00:02:34,515 --> 00:02:36,255
and start using that.

49
00:02:36,255 --> 00:02:43,710
Um, so we've attempted to make assignment three sort of be a highly scaffolded tutorial,

50
00:02:43,710 --> 00:02:47,360
where you can start to learn how to do things in PyTorch by just,

51
00:02:47,360 --> 00:02:50,730
um, writing a few lines of code at a time.

52
00:02:50,730 --> 00:02:53,130
Hopefully that works out for people.

53
00:02:53,130 --> 00:02:55,020
Um, if you have any issues with,

54
00:02:55,020 --> 00:02:56,580
with that, um, well,

55
00:02:56,580 --> 00:02:58,830
obviously, you can send Piazza messages,

56
00:02:58,830 --> 00:03:00,180
come to office hours.

57
00:03:00,180 --> 00:03:02,830
I mean, the one other thing you could think of doing is that there's sort of

58
00:03:02,830 --> 00:03:06,220
a one hour introduction to PyTorch on the PyTorch site,

59
00:03:06,220 --> 00:03:09,895
where you down- where you're directed for installing PyTorch,

60
00:03:09,895 --> 00:03:13,000
and you could also look at that if that was maybe helpful.

61
00:03:13,000 --> 00:03:16,710
Um, now the final mentions, yes.

62
00:03:16,710 --> 00:03:19,320
So, um, final projects, um, you know,

63
00:03:19,320 --> 00:03:22,060
we're going to sort of focus on those more in week five,

64
00:03:22,060 --> 00:03:25,120
but if it's not bad to be thinking about things you could do,

65
00:03:25,120 --> 00:03:27,145
if you're under a custom final project.

66
00:03:27,145 --> 00:03:30,400
You're certainly encouraged to come and talk to me or the TAs.

67
00:03:30,400 --> 00:03:34,315
We have under the sort of office hours page on the website,

68
00:03:34,315 --> 00:03:37,810
a listing of the expertise of some of the different TAs.

69
00:03:37,810 --> 00:03:42,220
Um, since I missed my office hours yesterday,

70
00:03:42,220 --> 00:03:46,520
I'm gonna have a shortened office hour tomorrow from 1:00 to 2:20.

71
00:03:46,520 --> 00:03:49,490
Um, that's at the same time as the,

72
00:03:49,490 --> 00:03:53,045
um, normal CS224N, um,

73
00:03:53,045 --> 00:03:56,300
office hours, so you can kind of come for any reason you want,

74
00:03:56,300 --> 00:03:58,430
but it might be especially good to come to me if you want

75
00:03:58,430 --> 00:04:00,910
to talk about, um, final projects.

76
00:04:00,910 --> 00:04:07,475
Okay. So, let's leap in and start talking about the structure of sentences.

77
00:04:07,475 --> 00:04:15,650
And so, I just sort of want to explain something about human language sentence structure,

78
00:04:15,650 --> 00:04:18,530
and how people think about that structure,

79
00:04:18,530 --> 00:04:22,775
and what kind of goals then people in natural language processing

80
00:04:22,775 --> 00:04:27,725
have of sort of building structure to understand the meaning of sentences.

81
00:04:27,725 --> 00:04:31,890
Um, all of the examples I'm going to give today are in English,

82
00:04:31,890 --> 00:04:36,390
um, because that's the language that you're all expected to have some competence in.

83
00:04:36,390 --> 00:04:39,545
But this really isn't meant to be sort of facts about English.

84
00:04:39,545 --> 00:04:43,460
This is meant to be sort of ideas of how you can think about the structure of

85
00:04:43,460 --> 00:04:48,145
human language sentences that are applied to all sorts of languages.

86
00:04:48,145 --> 00:04:51,575
Okay. So in general,

87
00:04:51,575 --> 00:04:54,410
there are two different ways that

88
00:04:54,410 --> 00:04:57,650
linguists have thought about the structure of sentences,

89
00:04:57,650 --> 00:04:59,420
though there's some relations to them.

90
00:04:59,420 --> 00:05:02,165
One of them is called phrase structure,

91
00:05:02,165 --> 00:05:04,085
or phrase structure grammars.

92
00:05:04,085 --> 00:05:08,480
And if you vaguely remember from CS103 if you did that,

93
00:05:08,480 --> 00:05:12,900
when you spent about the lecture on context-free grammars, um,

94
00:05:12,900 --> 00:05:15,050
phrase structure grammars are using the tools of

95
00:05:15,050 --> 00:05:17,930
context-free grammars to put structures over sentences.

96
00:05:17,930 --> 00:05:22,670
So, I'm first of all going to just briefly introduce that, so you've seen it,

97
00:05:22,670 --> 00:05:24,590
but actually the main tool that we're going to

98
00:05:24,590 --> 00:05:27,700
use in this class and for assignment three,

99
00:05:27,700 --> 00:05:30,560
is to do put dependency structures over,

100
00:05:30,560 --> 00:05:33,110
um, sentences, so I'll then go about that.

101
00:05:33,110 --> 00:05:36,290
So, the idea of phrase structure is to say that

102
00:05:36,290 --> 00:05:40,810
sentences are built out of units that progressively nest.

103
00:05:40,810 --> 00:05:44,140
So, we start off with words that, cat, cuddly,

104
00:05:44,140 --> 00:05:48,280
et cetera, and then we're gonna put them into bigger units that we call phrases,

105
00:05:48,280 --> 00:05:50,425
like "The cuddly cat by the door",

106
00:05:50,425 --> 00:05:54,190
and then you can keep on combining those up into even bigger phrases,

107
00:05:54,190 --> 00:05:56,465
like, "The cuddly cat by the door."

108
00:05:56,465 --> 00:06:00,660
Um, [NOISE] Okay, that's that.

109
00:06:00,660 --> 00:06:02,235
So, how does this work?

110
00:06:02,235 --> 00:06:04,230
Well, so the idea of it,

111
00:06:04,230 --> 00:06:06,570
and this is sort of the way linguists thinks,

112
00:06:06,570 --> 00:06:08,205
is to say, "Well,

113
00:06:08,205 --> 00:06:10,260
here's this language, which,

114
00:06:10,260 --> 00:06:12,465
you know, might not be English.

115
00:06:12,465 --> 00:06:15,055
It might be Oaxacan or some other language.

116
00:06:15,055 --> 00:06:17,320
What kind of structure does it have?

117
00:06:17,320 --> 00:06:21,985
And well, we could look at lots of sentences of the language.

118
00:06:21,985 --> 00:06:24,205
And so the linguist is gonna think,

119
00:06:24,205 --> 00:06:25,585
"Well, I can see,

120
00:06:25,585 --> 00:06:28,485
um, patterns, like the cat,

121
00:06:28,485 --> 00:06:29,820
a dog, the dog,

122
00:06:29,820 --> 00:06:31,280
a cat, et cetera.

123
00:06:31,280 --> 00:06:34,940
So, it's sort of seems like there's one word class here,

124
00:06:34,940 --> 00:06:37,940
which linguists often referred to as determiners.

125
00:06:37,940 --> 00:06:40,700
Um, they're also referred to as article sometimes in English.

126
00:06:40,700 --> 00:06:44,390
There's another word class here of nouns.

127
00:06:44,390 --> 00:06:48,295
And so, what I- to capture this pattern here,

128
00:06:48,295 --> 00:06:51,230
it seems like we can make this unit, um,

129
00:06:51,230 --> 00:06:55,025
that I see all over the place in language, um,

130
00:06:55,025 --> 00:06:57,095
which is made of a,

131
00:06:57,095 --> 00:07:00,340
um, a determiner, followed by a noun.

132
00:07:00,340 --> 00:07:02,190
So, I've write, um,

133
00:07:02,190 --> 00:07:04,275
a phrase structure grammar role,

134
00:07:04,275 --> 00:07:07,490
a context-free grammar role of- I can have

135
00:07:07,490 --> 00:07:11,245
a noun phrase that goes to a determiner, and a noun.

136
00:07:11,245 --> 00:07:12,795
Okay. But, you know,

137
00:07:12,795 --> 00:07:16,980
that's not the only thing that I can, um, see.

138
00:07:16,980 --> 00:07:20,870
So, I can also see, um,

139
00:07:20,870 --> 00:07:24,470
other examples in my language of the large cat,

140
00:07:24,470 --> 00:07:25,955
or a barking dog,

141
00:07:25,955 --> 00:07:28,400
or the cuddly cat, the cuddly dog.

142
00:07:28,400 --> 00:07:33,080
So, that seems that I need to put a bit more stuff into my grammar.

143
00:07:33,080 --> 00:07:38,430
So, maybe I can say from my grammar that a noun phrase goes to a determiner,

144
00:07:38,430 --> 00:07:41,195
and then optionally, you can put in an adjective,

145
00:07:41,195 --> 00:07:42,710
and then you can have a noun.

146
00:07:42,710 --> 00:07:45,800
And then I poke around a little bit further and I

147
00:07:45,800 --> 00:07:48,995
can find examples like the cat in a crate,

148
00:07:48,995 --> 00:07:52,220
or a barking dog by the door.

149
00:07:52,220 --> 00:07:55,100
And I can see lots of sentences like this.

150
00:07:55,100 --> 00:07:58,470
And so I want to put those into my grammar.

151
00:07:58,470 --> 00:08:01,410
But at that point, I noticed something special, because look,

152
00:08:01,410 --> 00:08:04,245
here are some other things,

153
00:08:04,245 --> 00:08:08,540
and these things look a lot like the things I started off with.

154
00:08:08,540 --> 00:08:09,590
So, it seems like,

155
00:08:09,590 --> 00:08:12,230
which sort of having a phrase with

156
00:08:12,230 --> 00:08:17,840
the same expansion potential that's nested inside this bigger phrase,

157
00:08:17,840 --> 00:08:21,150
because these ones can also be, um, expanded, right?

158
00:08:21,150 --> 00:08:24,720
I could have something like the green door something in here.

159
00:08:24,720 --> 00:08:27,315
So, I just wanna capture that in some way.

160
00:08:27,315 --> 00:08:32,885
So, maybe I could say that a noun phrase goes to a determiner,

161
00:08:32,885 --> 00:08:36,315
optionally an adjective, a noun,

162
00:08:36,315 --> 00:08:37,650
and then a something else,

163
00:08:37,650 --> 00:08:39,930
which I'll call a prepositional phrase.

164
00:08:39,930 --> 00:08:42,530
And then I'm gonna write a second rule saying that

165
00:08:42,530 --> 00:08:46,820
a prepositional phrase goes to a preposition,

166
00:08:46,820 --> 00:08:49,665
that's gonna be these words here,

167
00:08:49,665 --> 00:08:53,595
um, followed by a noun phrase.

168
00:08:53,595 --> 00:09:00,980
So then I'm reuse- [NOISE] I'm reusing my noun phrase that I defined up here.

169
00:09:00,980 --> 00:09:04,205
So then I could immediately generate other stuff.

170
00:09:04,205 --> 00:09:05,870
I can sort of say,

171
00:09:05,870 --> 00:09:10,515
"The cat by the, the large door."

172
00:09:10,515 --> 00:09:11,970
Or indeed I could say,

173
00:09:11,970 --> 00:09:15,190
"The cat by the large crate."

174
00:09:15,190 --> 00:09:18,990
Um, "The cat by the large crate on the table",

175
00:09:18,990 --> 00:09:20,160
or something like that,

176
00:09:20,160 --> 00:09:23,900
because once I can have the prepositional phrase includes a noun phrase,

177
00:09:23,900 --> 00:09:26,960
and a noun phrase includes a prepositional phrase,

178
00:09:26,960 --> 00:09:29,990
I've already got something that I can kind of

179
00:09:29,990 --> 00:09:33,650
recursively go back and forth between noun phrases,

180
00:09:33,650 --> 00:09:36,265
and I can make infinitely big sentences, right?

181
00:09:36,265 --> 00:09:39,090
Yeah?

182
00:09:39,090 --> 00:09:42,530
Yeah? So, I could write something like, yeah,

183
00:09:42,530 --> 00:09:46,690
"The cat by

184
00:09:46,690 --> 00:09:55,110
the large crate on the,

185
00:09:55,120 --> 00:10:02,410
um, large table, um, by the door."

186
00:10:02,410 --> 00:10:06,365
Right. I can keep on going and make big sentences.

187
00:10:06,365 --> 00:10:08,150
And I could say, well,

188
00:10:08,150 --> 00:10:12,260
I've got a- I don't have space to fit it on this slide,

189
00:10:12,260 --> 00:10:15,680
but I've got an analysis of this according to my grammar,

190
00:10:15,680 --> 00:10:21,110
where that's a noun phrase goes to a determiner noun prepositional phrase.

191
00:10:21,110 --> 00:10:23,855
The prepositional phrase goes to a preposition,

192
00:10:23,855 --> 00:10:25,520
and a noun phrase,

193
00:10:25,520 --> 00:10:27,920
and this noun phrase goes to a determiner,

194
00:10:27,920 --> 00:10:32,385
adjective, noun prepositional phrase.

195
00:10:32,385 --> 00:10:35,040
And that goes to a preposition,

196
00:10:35,040 --> 00:10:36,415
and another noun phrase,

197
00:10:36,415 --> 00:10:40,270
and I keep on going and I can produce big sentences.

198
00:10:40,270 --> 00:10:45,570
Okay. You know, that kind of then continues on,

199
00:10:45,570 --> 00:10:47,835
because, um, you know,

200
00:10:47,835 --> 00:10:50,970
I can then start seeing more bits of grammar.

201
00:10:50,970 --> 00:10:52,290
So, I could say, "Well,

202
00:10:52,290 --> 00:10:54,450
I can now talk to the cat."

203
00:10:54,450 --> 00:10:56,760
Um, and so if I wanna capture,

204
00:10:56,760 --> 00:10:59,970
um, this talking to a cat here, well,

205
00:10:59,970 --> 00:11:02,100
that now means I've got a verb,

206
00:11:02,100 --> 00:11:05,760
because words like talk and walk are verbs.

207
00:11:05,760 --> 00:11:07,830
And then talk to the cat,

208
00:11:07,830 --> 00:11:09,180
it seems like after that,

209
00:11:09,180 --> 00:11:11,210
it could become a prepositional phrase.

210
00:11:11,210 --> 00:11:14,555
And so I could write another rule saying that a verb phrase

211
00:11:14,555 --> 00:11:18,410
goes to a verb followed by a prepositional phrase.

212
00:11:18,410 --> 00:11:21,110
And then I can make more bigger sentences like that.

213
00:11:21,110 --> 00:11:27,060
And I could look at more sentences of the language and start building up these,

214
00:11:27,060 --> 00:11:32,310
these context-free grammar rules to describe the structure of the language.

215
00:11:32,310 --> 00:11:34,285
And that's part of what linguists do,

216
00:11:34,285 --> 00:11:38,465
and different languages, um, have different structures.

217
00:11:38,465 --> 00:11:40,890
So, um, for example,

218
00:11:40,890 --> 00:11:43,235
like in this, uh,

219
00:11:43,235 --> 00:11:46,620
little grammar I've had and in general in English, um,

220
00:11:46,620 --> 00:11:51,995
what you do, what you find is that prepositional phrases following the verb.

221
00:11:51,995 --> 00:11:54,940
But if you go to a different language like Chinese,

222
00:11:54,940 --> 00:11:57,980
what you find is the prepositional phrases come before the verb.

223
00:11:57,980 --> 00:11:59,310
And so, we could say okay,

224
00:11:59,310 --> 00:12:02,400
there are different rules for Chinese, um,

225
00:12:02,400 --> 00:12:07,305
and I could start writing a context-free grammar for them. Okay, beauty.

226
00:12:07,305 --> 00:12:10,169
Um,so that's the idea of context-free grammars,

227
00:12:10,169 --> 00:12:12,265
and actually, you know,

228
00:12:12,265 --> 00:12:15,980
this is the dominant approached linguistic structure

229
00:12:15,980 --> 00:12:20,570
that you'll see if you go and do a linguistics class in the linguistics department,

230
00:12:20,570 --> 00:12:24,180
people make these kinds of Phrase Structure Grammar trees.

231
00:12:24,180 --> 00:12:26,160
Um, but just to be contrary,

232
00:12:26,160 --> 00:12:28,205
no, it's not actually just to be contrary,

233
00:12:28,205 --> 00:12:30,660
it's because this alternative approach has been

234
00:12:30,660 --> 00:12:33,555
very dominant in computational linguistics.

235
00:12:33,555 --> 00:12:36,625
What I'm going to show you instead, um,

236
00:12:36,625 --> 00:12:40,655
is the view point of dependency structure.

237
00:12:40,655 --> 00:12:44,100
So, the idea of dependency structure

238
00:12:44,100 --> 00:12:47,750
is rather than having these sort of phrasal categories,

239
00:12:47,750 --> 00:12:50,314
like, noun phrases and prepositional phrases,

240
00:12:50,314 --> 00:12:51,745
and things like that,

241
00:12:51,745 --> 00:12:54,775
we are going to directly, um,

242
00:12:54,775 --> 00:12:58,945
represent the structure of sentences by saying,

243
00:12:58,945 --> 00:13:05,630
how words, how arguments or modifiers of other words in a recursive faction.

244
00:13:05,630 --> 00:13:09,895
Which is sort of another way of saying how the dependence on other words.

245
00:13:09,895 --> 00:13:11,100
So, we have a sentence,

246
00:13:11,100 --> 00:13:13,840
''Look in the large crate in the kitchen by the door''.

247
00:13:13,840 --> 00:13:16,300
And if we want to we can give these word,

248
00:13:16,300 --> 00:13:19,865
words word classes, so we can still say this is a verb,

249
00:13:19,865 --> 00:13:21,375
and this is a preposition,

250
00:13:21,375 --> 00:13:22,829
and this is a determiner,

251
00:13:22,829 --> 00:13:24,465
and this is an adjective,

252
00:13:24,465 --> 00:13:25,940
and this is a noun.

253
00:13:25,940 --> 00:13:27,920
But to represent the structure,

254
00:13:27,920 --> 00:13:30,305
what we're going to say is, "Well,

255
00:13:30,305 --> 00:13:35,105
look here is the the root of this whole sentence."

256
00:13:35,105 --> 00:13:37,440
So, that's where things start.

257
00:13:37,440 --> 00:13:42,530
Um, and then, well, where are we going to look is in the large crate,

258
00:13:42,530 --> 00:13:46,875
so that is a dependent of look.

259
00:13:46,875 --> 00:13:52,799
And well, if we- then we have for the crate,

260
00:13:52,799 --> 00:13:55,890
it's got some modifies its a large crate.

261
00:13:55,890 --> 00:13:57,660
So, that's a dependent of crate.

262
00:13:57,660 --> 00:13:59,515
Its the large crate,

263
00:13:59,515 --> 00:14:01,395
that's a dependence of crate.

264
00:14:01,395 --> 00:14:05,285
And in this system of dependencies I'm going to show you,

265
00:14:05,285 --> 00:14:08,425
we've got in as kind of,

266
00:14:08,425 --> 00:14:11,360
um, a modifier of crate in the large crate.

267
00:14:11,360 --> 00:14:13,020
I could come back to that.

268
00:14:13,020 --> 00:14:16,355
Well, but this crate has its own modification,

269
00:14:16,355 --> 00:14:18,385
because it's a crate in the kitchen.

270
00:14:18,385 --> 00:14:21,665
So, we have, in the kitchen,

271
00:14:21,665 --> 00:14:23,910
as a modifier of crate.

272
00:14:23,910 --> 00:14:26,740
And it's the kitchen in the kitchen,

273
00:14:26,740 --> 00:14:29,735
these are dependence of crate.

274
00:14:29,735 --> 00:14:34,115
And well, then we have this next bit by the door.

275
00:14:34,115 --> 00:14:36,075
And as I'll discuss in a minute, well,

276
00:14:36,075 --> 00:14:39,345
what does the by the door modifying?

277
00:14:39,345 --> 00:14:40,950
It's still modifying the crate,

278
00:14:40,950 --> 00:14:42,770
it saying, ''It's the crate by the door.''

279
00:14:42,770 --> 00:14:47,465
Okay. So, the by the door is also a dependent of crate,

280
00:14:47,465 --> 00:14:53,775
and then we've got the structure of dependencies coming off of it.

281
00:14:53,775 --> 00:14:56,265
Okay. And so that's then, um,

282
00:14:56,265 --> 00:14:59,010
the structure you get may be drawn a little bit more

283
00:14:59,010 --> 00:15:02,110
neatly when I did that in advance like this.

284
00:15:02,110 --> 00:15:05,790
And so we call these things, uh, dependency structure.

285
00:15:05,790 --> 00:15:08,670
And so crucially, what we're doing here,

286
00:15:08,670 --> 00:15:14,145
um, is that we're- sorry,

287
00:15:14,145 --> 00:15:15,750
I had two different examples.

288
00:15:15,750 --> 00:15:17,010
[NOISE] different examples.

289
00:15:17,010 --> 00:15:19,330
[LAUGHTER] Um, um,

290
00:15:19,330 --> 00:15:21,275
what we're doing is saying, what,

291
00:15:21,275 --> 00:15:24,840
what words modify other words?

292
00:15:24,840 --> 00:15:28,365
And so, that allows us to sort of

293
00:15:28,365 --> 00:15:32,570
understand how the different parts of the sentence relate to each other.

294
00:15:32,570 --> 00:15:34,945
And so, overall, you know,

295
00:15:34,945 --> 00:15:37,225
then- let me just so say here,

296
00:15:37,225 --> 00:15:39,920
you might want to why do we need sentence structure?

297
00:15:39,920 --> 00:15:41,760
You know, the way, um,

298
00:15:41,760 --> 00:15:44,280
language seems to work when you're talking to

299
00:15:44,280 --> 00:15:47,429
your friends is that you just blab of something,

300
00:15:47,429 --> 00:15:50,735
and I understand what you're saying, and, um,

301
00:15:50,735 --> 00:15:52,995
what goes on beyond that, um,

302
00:15:52,995 --> 00:15:55,905
is sort of not really accessible to consciousness.

303
00:15:55,905 --> 00:16:01,780
But well, to be able to have machines that interpret language correctly,

304
00:16:01,780 --> 00:16:05,660
we sort of need to understand the structure of these sentences,

305
00:16:05,660 --> 00:16:10,485
because unless we know what words are arguments and modifiers of other words,

306
00:16:10,485 --> 00:16:13,560
we can't actually work out what sentences mean.

307
00:16:13,560 --> 00:16:17,260
And I'll show some examples of that as to how things go wrong immediately,

308
00:16:17,260 --> 00:16:19,410
because actually, a lot of the time there are

309
00:16:19,410 --> 00:16:22,230
different possible interpretations you can have.

310
00:16:22,230 --> 00:16:23,495
And so, in general,

311
00:16:23,495 --> 00:16:24,845
our goal is, you know,

312
00:16:24,845 --> 00:16:27,815
up until now we've sort of looked at the meaning of words, right?

313
00:16:27,815 --> 00:16:29,140
We did word vectors,

314
00:16:29,140 --> 00:16:31,325
and we found that words there was similar meaning,

315
00:16:31,325 --> 00:16:32,550
and things like that.

316
00:16:32,550 --> 00:16:36,960
Um, and you can get somewhere in human languages with just saying words.

317
00:16:36,960 --> 00:16:40,085
I mean you can say, "Hi",

318
00:16:40,085 --> 00:16:44,350
and friendly, um, and things like that,

319
00:16:44,350 --> 00:16:46,695
but you can't get very far with just words, right?

320
00:16:46,695 --> 00:16:48,890
The way human beings can express

321
00:16:48,890 --> 00:16:52,550
complex ideas and explain and teach things to each other,

322
00:16:52,550 --> 00:16:57,500
is you can put together words to express more complex meanings.

323
00:16:57,500 --> 00:17:00,570
And then, you can do that over and over again

324
00:17:00,570 --> 00:17:04,120
recursively to build up more and more complex meanings,

325
00:17:04,120 --> 00:17:07,420
so that by the time you're reading the morning newspaper,

326
00:17:07,420 --> 00:17:10,805
you know most sentences are sort of 20-30 words long,

327
00:17:10,805 --> 00:17:12,225
and they're saying, um,

328
00:17:12,225 --> 00:17:14,335
some complex meaning, like you know,

329
00:17:14,335 --> 00:17:17,965
"Overnight Senate Republicans resolve that they would not do blah blah blah blah.''

330
00:17:17,965 --> 00:17:20,070
And you understand that flawlessly,

331
00:17:20,070 --> 00:17:22,850
by just sort of putting together those meanings of words.

332
00:17:22,850 --> 00:17:25,230
And so, we need to be able to know what is connected to

333
00:17:25,230 --> 00:17:28,010
what in order to be able to do that.

334
00:17:28,010 --> 00:17:30,740
And one of the ways of saying, um,

335
00:17:30,740 --> 00:17:32,765
that's important is saying,

336
00:17:32,765 --> 00:17:34,805
''What can go wrong?''

337
00:17:34,805 --> 00:17:38,675
Okay. So here, is a newspaper article.

338
00:17:38,675 --> 00:17:42,380
Uh, ''San Jose cop kills man with knife''.

339
00:17:42,380 --> 00:17:46,605
Um, now, this has two meanings and the two meanings, um,

340
00:17:46,605 --> 00:17:50,630
depend on, well, what you decide depends on what,

341
00:17:50,630 --> 00:17:52,190
you know, what modifies what?

342
00:17:52,190 --> 00:17:55,535
So, what are the two meanings. Meaning one.

343
00:17:55,535 --> 00:17:57,580
The cop stabs the guy. [LAUGHTER]

344
00:17:57,580 --> 00:17:59,310
The cop stabs the guy.

345
00:17:59,310 --> 00:18:02,235
Right. So, meaning one is the cop stabs that guy.

346
00:18:02,235 --> 00:18:04,625
So, what we've got here is,

347
00:18:04,625 --> 00:18:07,330
we've got the cops that are killing.

348
00:18:07,330 --> 00:18:12,070
So, this is what we'll say is the subject of kill,

349
00:18:12,070 --> 00:18:15,635
is the cops, and I'll just call them the San Jose cops here.

350
00:18:15,635 --> 00:18:19,365
And well, there's what they kill which say that,

351
00:18:19,365 --> 00:18:24,155
the man is an object of killing.

352
00:18:24,155 --> 00:18:27,615
Um, and then while one person is the,

353
00:18:27,615 --> 00:18:30,460
the cop using knife to kill the person.

354
00:18:30,460 --> 00:18:34,790
And so that's then that this is, um,

355
00:18:34,790 --> 00:18:38,739
modifier and here if we complex we call it an instrumental

356
00:18:38,739 --> 00:18:43,200
modifier to say that the cops are killing people with a knife.

357
00:18:43,200 --> 00:18:45,300
That's one possible analysis.

358
00:18:45,300 --> 00:18:49,055
Okay. Then, there's a second meaning sentence can have.

359
00:18:49,055 --> 00:18:52,275
The second meaning sentence can have. [NOISE]

360
00:18:52,275 --> 00:18:55,380
Okay. The second meaning the sentence can have is,

361
00:18:55,380 --> 00:18:57,225
that's the man has a knife.

362
00:18:57,225 --> 00:18:59,490
So, um, in that case,

363
00:18:59,490 --> 00:19:01,350
what we wanna say is, well, you know,

364
00:19:01,350 --> 00:19:03,165
is this word man,

365
00:19:03,165 --> 00:19:06,540
and this man has, uh,

366
00:19:06,540 --> 00:19:12,600
noun modifier, um, which is sort of saying something that the man possesses,

367
00:19:12,600 --> 00:19:14,595
and then this dependency is the same,

368
00:19:14,595 --> 00:19:16,860
and it's a man with a knife.

369
00:19:16,860 --> 00:19:23,430
Okay. And so, the interpretations of these sentences that you can get depend on putting

370
00:19:23,430 --> 00:19:30,405
different structures over the sentences in terms of who is- what is modifying what?

371
00:19:30,405 --> 00:19:33,675
Um, here is another one that's just like that one.

372
00:19:33,675 --> 00:19:37,020
Um, scientists count whales from space.

373
00:19:37,020 --> 00:19:38,850
[LAUGHTER] Okay.

374
00:19:38,850 --> 00:19:42,960
So again, this sentence has two possible structures, right?

375
00:19:42,960 --> 00:19:46,860
[LAUGHTER] That we have, the scientists are the subject that are

376
00:19:46,860 --> 00:19:51,330
counting and the whales are the object.

377
00:19:51,330 --> 00:19:57,135
Um, and, well, one possibility is that this is how they're doing the counting,

378
00:19:57,135 --> 00:20:02,520
um, so that they're counting the whales from space using something like a satellite.

379
00:20:02,520 --> 00:20:06,000
Um, but the other possibility is that these parts are the same,

380
00:20:06,000 --> 00:20:07,230
this is the subject,

381
00:20:07,230 --> 00:20:08,835
and this is the object,

382
00:20:08,835 --> 00:20:12,750
but these are whales from space which, you know,

383
00:20:12,750 --> 00:20:16,875
we could have analyzed as a noun phrase goes to,

384
00:20:16,875 --> 00:20:19,050
um, and now, on a PP,

385
00:20:19,050 --> 00:20:21,330
you know, um, constituency grammar,

386
00:20:21,330 --> 00:20:23,340
but its dependency grammar we saying, "Oh,

387
00:20:23,340 --> 00:20:28,275
this is now a modifier of the whales,

388
00:20:28,275 --> 00:20:31,200
and that they are whales from space, um,

389
00:20:31,200 --> 00:20:34,184
that are starting to turn up as in the bottom example."

390
00:20:34,184 --> 00:20:40,440
Right? So, obviously what you want is this one is correct and this one is here wrong.

391
00:20:40,440 --> 00:20:46,455
Um, and so this choice is referred to as a prepositional phrase attachment ambiguity,

392
00:20:46,455 --> 00:20:51,810
and it's one of the most common ambiguities in the parsing of English, right?

393
00:20:51,810 --> 00:20:55,140
So, here's our prepositional phrase from space.

394
00:20:55,140 --> 00:20:56,370
And so in general,

395
00:20:56,370 --> 00:21:00,840
when you have prepositional phrases and before it you have verbs,

396
00:21:00,840 --> 00:21:03,480
and noun phrases, or nouns,

397
00:21:03,480 --> 00:21:06,405
that the prepositional phrase can modify

398
00:21:06,405 --> 00:21:09,525
either of the things that come beforehand, right?

399
00:21:09,525 --> 00:21:12,330
And so this is a crucial way in which

400
00:21:12,330 --> 00:21:16,200
human languages are different from programming languages, right?

401
00:21:16,200 --> 00:21:20,360
In programming languages, we have hard rules

402
00:21:20,360 --> 00:21:24,890
as to how you meant to interpret things that dangle afterwards, right?

403
00:21:24,890 --> 00:21:27,140
So, in programming languages,

404
00:21:27,140 --> 00:21:31,765
you have an else is always construed with the closest if.

405
00:21:31,765 --> 00:21:33,930
Well, if that's not what you want, um,

406
00:21:33,930 --> 00:21:37,110
you have to use parentheses or indentation or something like that.

407
00:21:37,110 --> 00:21:39,870
I guess, it's different in Python because you have to use indentation.

408
00:21:39,870 --> 00:21:43,365
But if we think of something like C or a similar language, right?

409
00:21:43,365 --> 00:21:45,165
Um, if you haven't used,

410
00:21:45,165 --> 00:21:46,965
um, braces to indicate,

411
00:21:46,965 --> 00:21:51,060
it's just deterministically, the else goes with the closest if.

412
00:21:51,060 --> 00:21:54,105
Um, but that's not how human languages are.

413
00:21:54,105 --> 00:21:55,920
Human languages are, um,

414
00:21:55,920 --> 00:21:59,940
this prepositional phrase can go with anything proceeding,

415
00:21:59,940 --> 00:22:04,485
and the hearer is assumed to be smart enough to work out the right one.

416
00:22:04,485 --> 00:22:07,050
And, you know, that's actually a pa- large part of why

417
00:22:07,050 --> 00:22:10,440
human communication is so efficient, right?

418
00:22:10,440 --> 00:22:14,250
Like, um, we can do such a good job at communicating with

419
00:22:14,250 --> 00:22:18,360
each other because most of the time we don't have to say very much,

420
00:22:18,360 --> 00:22:21,495
and there's this really smart person on the other end, um,

421
00:22:21,495 --> 00:22:25,905
who can interpret the words that we say in the right way.

422
00:22:25,905 --> 00:22:31,800
Um, so, that's where if you want to have artificial intelligence and smart computers,

423
00:22:31,800 --> 00:22:37,065
we then start to need to build language understanding devices who can also,

424
00:22:37,065 --> 00:22:38,910
um, work on that basis.

425
00:22:38,910 --> 00:22:44,985
That they can just decide what would be the right thing for form space to modify.

426
00:22:44,985 --> 00:22:46,560
And if we have that working really well,

427
00:22:46,560 --> 00:22:49,050
we can then apply it back to programming languages,

428
00:22:49,050 --> 00:22:52,725
and you could just not put in any braces in your programming languages,

429
00:22:52,725 --> 00:22:55,110
and the compiler would work out what you meant.

430
00:22:55,110 --> 00:22:58,575
Um, okay. So, this is prepositional phrase attachment.

431
00:22:58,575 --> 00:23:02,445
It's sort of seems maybe not that hard there,

432
00:23:02,445 --> 00:23:04,965
but you know, it, it gets worse, I mean,

433
00:23:04,965 --> 00:23:06,990
this isn't as fun an example,

434
00:23:06,990 --> 00:23:12,465
but it's a real example of a sentence from The Wall Street Journal actually.

435
00:23:12,465 --> 00:23:18,120
The board approved this acquisition by Royal Trustco Limited of Toronto for $0,27,

436
00:23:18,120 --> 00:23:20,955
$27 a share at its monthly meeting.

437
00:23:20,955 --> 00:23:22,635
Boring sentence, but, um,

438
00:23:22,635 --> 00:23:24,660
what is the structure of this sentence?

439
00:23:24,660 --> 00:23:26,670
Well, you know, we've got a verb here,

440
00:23:26,670 --> 00:23:29,805
and we've got exactly the same subject,

441
00:23:29,805 --> 00:23:32,295
and for this noun,

442
00:23:32,295 --> 00:23:34,965
um, object coming after it.

443
00:23:34,965 --> 00:23:36,570
But then what happens after that?

444
00:23:36,570 --> 00:23:38,670
Well, here, we've got a prepositional phrase.

445
00:23:38,670 --> 00:23:40,575
Here, we've got a prepositional phrase.

446
00:23:40,575 --> 00:23:44,700
You've just got a see four prepositional phrases in a row.

447
00:23:44,700 --> 00:23:48,600
And so, well, what we wanna

448
00:23:48,600 --> 00:23:52,845
do is say for each of these prepositional phrases what they modify,

449
00:23:52,845 --> 00:23:55,589
and starting off there only two choices,

450
00:23:55,589 --> 00:23:58,020
the verb and the noun proceeding as before.

451
00:23:58,020 --> 00:24:01,590
But it's gonna get more complicated as we go in, because look,

452
00:24:01,590 --> 00:24:02,910
there's another noun here,

453
00:24:02,910 --> 00:24:04,245
and another noun here,

454
00:24:04,245 --> 00:24:06,825
and another noun here.

455
00:24:06,825 --> 00:24:11,475
Um, so once we start getting further in there'll be more possibilities.

456
00:24:11,475 --> 00:24:13,185
Okay. So, let's see if we can,

457
00:24:13,185 --> 00:24:14,400
um, work it out.

458
00:24:14,400 --> 00:24:18,720
So, um, by Royal Trustco Limited, what's that modifying?

459
00:24:18,720 --> 00:24:25,709
[NOISE] Right. You see acquisition,

460
00:24:25,709 --> 00:24:28,800
so it's not the board approved by Royal Trustco Limited,

461
00:24:28,800 --> 00:24:32,145
it's an acquisition by Royal Trustco Limited.

462
00:24:32,145 --> 00:24:36,750
Okay. So, this one is a dependent of the acquisition.

463
00:24:36,750 --> 00:24:39,975
Okay. Um, now, we went to of Toronto,

464
00:24:39,975 --> 00:24:41,580
and we have three choices,

465
00:24:41,580 --> 00:24:43,875
that could be this, this, or this.

466
00:24:43,875 --> 00:24:48,340
Okay. So, of Toronto is modifying.

467
00:24:50,060 --> 00:24:51,540
Acquisition. [NOISE]

468
00:24:51,540 --> 00:24:53,010
Its acquisition of Toronto?

469
00:24:53,010 --> 00:24:59,055
[LAUGHTER] No, I think that's a wrong answer.

470
00:24:59,055 --> 00:25:04,080
Um. [LAUGHTER] Is there another guess for what of Toronto is modifying?

471
00:25:04,080 --> 00:25:05,640
Royal Trustco.

472
00:25:05,640 --> 00:25:09,180
Royal Trustco, right. So, it's Royal Trustco Limited of Toronto.

473
00:25:09,180 --> 00:25:14,550
So, this of Toronto is a dependent of Royal Trustco Limited.

474
00:25:14,550 --> 00:25:16,170
And Royal Trustco Limited,

475
00:25:16,170 --> 00:25:17,580
right, that's this again,

476
00:25:17,580 --> 00:25:18,840
sort of this noun phrase,

477
00:25:18,840 --> 00:25:21,840
so it can also have modifiers by prepositional phrase.

478
00:25:21,840 --> 00:25:29,400
Okay. For $27 a share is modifying acquisition, right?

479
00:25:29,400 --> 00:25:32,220
[NOISE] So now, we leap right back.

480
00:25:32,220 --> 00:25:34,320
[NOISE] I'm drawing this wrong.

481
00:25:34,320 --> 00:25:37,170
Now, we leap right back and,

482
00:25:37,170 --> 00:25:40,350
um, is now the acquisition that's being modified.

483
00:25:40,350 --> 00:25:45,600
And then finally, we have at its monthly meeting is modifying?

484
00:25:45,600 --> 00:25:47,940
[NOISE]

485
00:25:47,940 --> 00:25:48,120
Approved.

486
00:25:48,120 --> 00:25:49,410
Well, the approved, right?

487
00:25:49,410 --> 00:25:50,520
It's approved, yeah.

488
00:25:50,520 --> 00:25:53,055
It's approved that its monthly meeting.

489
00:25:53,055 --> 00:25:55,110
Okay. [NOISE] I drew that on,

490
00:25:55,110 --> 00:25:59,730
[NOISE] I drew that one the wrong way around with the arrow.

491
00:25:59,730 --> 00:26:01,830
Sorry, it should have been done this way.

492
00:26:01,830 --> 00:26:05,260
I'm getting my arrows wrong. [NOISE] Um, um.

493
00:26:06,390 --> 00:26:13,670
Okay. So that we've got this pattern of how things are modifying.

494
00:26:13,770 --> 00:26:17,175
Um, [NOISE] and so actually, you know,

495
00:26:17,175 --> 00:26:21,390
once you start having a lot of things that have choices like this,

496
00:26:21,390 --> 00:26:25,165
you stop having- if I wanna put an analysis ac-

497
00:26:25,165 --> 00:26:29,680
on to this sentence I've to work out the, the right structure,

498
00:26:29,680 --> 00:26:36,415
I have to potentially consider an exponential number of possible structures because,

499
00:26:36,415 --> 00:26:40,435
I've got this situation where for the first prepositional phrase,

500
00:26:40,435 --> 00:26:43,540
there were two places that could have modified.

501
00:26:43,540 --> 00:26:45,610
For the second prepositional phrase,

502
00:26:45,610 --> 00:26:47,965
there are three places that could have modified.

503
00:26:47,965 --> 00:26:49,180
For the fourth one,

504
00:26:49,180 --> 00:26:51,580
there are five places that could have modified.

505
00:26:51,580 --> 00:26:53,605
That just sounds like a factorial.

506
00:26:53,605 --> 00:26:57,325
It's not quite as bad as the factorial, because normally,

507
00:26:57,325 --> 00:27:01,930
once you've let back that kind of closes off the ones in the middle.

508
00:27:01,930 --> 00:27:04,900
And so, further prepositional phrases have to be

509
00:27:04,900 --> 00:27:08,140
at least as far back in terms of what they modify.

510
00:27:08,140 --> 00:27:13,000
And so, if you get into this sort of combinatorics stuff the number of analyses you get

511
00:27:13,000 --> 00:27:17,830
when you get multiple prepositional phrases is the sequence called the Catalan numbers.

512
00:27:17,830 --> 00:27:20,890
Ah, but that's still an exponential series.

513
00:27:20,890 --> 00:27:26,080
And it's sort of one that turns up in a lot of places when they're tree-like contexts.

514
00:27:26,080 --> 00:27:30,910
So, if any of you are doing or have done CS228,

515
00:27:30,910 --> 00:27:32,140
where you see, um,

516
00:27:32,140 --> 00:27:35,575
triangular- triangulation of, ah,

517
00:27:35,575 --> 00:27:40,210
probabilistic graphical models and you ask how many triangulations there are,

518
00:27:40,210 --> 00:27:43,375
that's sort of like making a tree over your variables.

519
00:27:43,375 --> 00:27:47,605
And that's, again, gives you the number of them as the Catalan series.

520
00:27:47,605 --> 00:27:49,180
Okay. But- so the point is,

521
00:27:49,180 --> 00:27:52,315
we ha- end up with a lot of ambiguities.

522
00:27:52,315 --> 00:27:55,060
Okay. So, that's prepositional phrase attachments.

523
00:27:55,060 --> 00:27:56,950
A lot of those going on.

524
00:27:56,950 --> 00:27:59,320
They are far from the only kind of ambiguity.

525
00:27:59,320 --> 00:28:01,900
So, I wanted to tell you about a few others.

526
00:28:01,900 --> 00:28:08,950
Um, okay, shuttle veteran and longtime NASA executive Fred Gregory appointed to board.

527
00:28:08,950 --> 00:28:12,790
Um, why is this sentence ambiguous?

528
00:28:12,790 --> 00:28:14,929
What are the different reading of this statement?

529
00:28:14,929 --> 00:28:16,400
[NOISE].

530
00:28:16,400 --> 00:28:20,800
Yes?

531
00:28:20,800 --> 00:28:22,150
Uh, it's a better [inaudible]

532
00:28:22,150 --> 00:28:24,700
Okay. So, um, right answer.

533
00:28:24,700 --> 00:28:26,920
So, yeah there are two possibilities, right?

534
00:28:26,920 --> 00:28:30,235
That is either that there's somebody who's

535
00:28:30,235 --> 00:28:34,030
a shuttle veteran and a long time NASA executive,

536
00:28:34,030 --> 00:28:35,875
and their name is Fred Gregory,

537
00:28:35,875 --> 00:28:38,395
and that they've been appointed to the board.

538
00:28:38,395 --> 00:28:42,550
Um, or, um, the other possibility

539
00:28:42,550 --> 00:28:46,570
is that there's a shuttle veteran and there's a long time NASA executive,

540
00:28:46,570 --> 00:28:51,175
Fred Gregory, and both of them have been appointed to the board.

541
00:28:51,175 --> 00:28:56,980
And so, again, we can start to indicate the structure of that using our dependency.

542
00:28:56,980 --> 00:28:58,360
So, we can ether,

543
00:28:58,360 --> 00:29:02,980
um, say, okay, um,

544
00:29:02,980 --> 00:29:09,955
there's Fred Gregory and then this person is, um,

545
00:29:09,955 --> 00:29:15,205
a shuttle veteran and long ta- and whoops,

546
00:29:15,205 --> 00:29:17,680
and longtime NASA executive.

547
00:29:17,680 --> 00:29:20,140
Or we can say, well,

548
00:29:20,140 --> 00:29:28,690
we're doing appointment of a veteran and the longtime NASA executive, Fred Gregory.

549
00:29:28,690 --> 00:29:31,060
And so, we can represent by dependencies,

550
00:29:31,060 --> 00:29:33,715
um, these two different structures.

551
00:29:33,715 --> 00:29:37,645
Okay. Um, that's, um, one.

552
00:29:37,645 --> 00:29:40,120
Um, That one is not very funny again.

553
00:29:40,120 --> 00:29:45,775
So- so, here's a funnier example that illustrates the same ambiguity effectively.

554
00:29:45,775 --> 00:29:49,630
Um, so, here's precedence first physical.

555
00:29:49,630 --> 00:29:52,570
Doctor: No heart, cognitive issues.

556
00:29:52,570 --> 00:29:56,590
[LAUGHTER] Um, so, there isn't actually an explicit,

557
00:29:56,590 --> 00:29:59,620
um, coordination word here.

558
00:29:59,620 --> 00:30:02,830
But effectively in, um,

559
00:30:02,830 --> 00:30:06,445
a natural language or certainly English, um,

560
00:30:06,445 --> 00:30:11,170
you can use kind of just comma of sort of list intonation

561
00:30:11,170 --> 00:30:16,300
to effectively act as if it was an "And" or an "Or", right?

562
00:30:16,300 --> 00:30:22,645
So, here, um, we have again two possibilities that either we have

563
00:30:22,645 --> 00:30:26,650
issues and the dep- and the dependencies

564
00:30:26,650 --> 00:30:31,240
of- the dependencies of issues is that there are no issues.

565
00:30:31,240 --> 00:30:36,025
So, that's actually a determiner, ah, no issues.

566
00:30:36,025 --> 00:30:40,210
Um, and then it's sort of like no heart or cognitive issues.

567
00:30:40,210 --> 00:30:42,790
So, heart is another dependent.

568
00:30:42,790 --> 00:30:45,610
It's sort of a non-compound heart issues.

569
00:30:45,610 --> 00:30:48,745
And so, we refer to that as an independency,

570
00:30:48,745 --> 00:30:53,890
and then it's heart or, um, cognitive.

571
00:30:53,890 --> 00:30:57,040
Um, so that heart or cognitive is

572
00:30:57,040 --> 00:31:03,400
a conjoined phrase inside of this "No heart" or "Cognitive issues".

573
00:31:03,400 --> 00:31:05,410
But there's another possibility,

574
00:31:05,410 --> 00:31:07,075
um, which is, um,

575
00:31:07,075 --> 00:31:14,470
that the coordination is at the top level that we have "No heart" and "Cognitive issues".

576
00:31:14,470 --> 00:31:16,885
And, um, at that point,

577
00:31:16,885 --> 00:31:23,604
we ha- have the "Cognitive" as an adjective modifier of the "Issues" and the "No heart",

578
00:31:23,604 --> 00:31:26,410
the determiner is just a modifier of "Heart",

579
00:31:26,410 --> 00:31:29,530
and then these being conjoined together.

580
00:31:29,530 --> 00:31:36,920
So, um, "Heart" has a depend- has a coordinated dependency of "Issues".

581
00:31:37,020 --> 00:31:40,880
Okay. That's one one.

582
00:31:40,980 --> 00:31:44,005
Um, I've got more funny ones.

583
00:31:44,005 --> 00:31:48,580
Susan gets- [NOISE] [LAUGHTER] Okay.

584
00:31:48,580 --> 00:31:52,240
So, what the person [LAUGHTER] who wrote this intended to

585
00:31:52,240 --> 00:31:57,460
have is that there- we- Here we've got an adjective modifier ambiguity.

586
00:31:57,460 --> 00:32:00,490
So, the intended reading was, um,

587
00:32:00,490 --> 00:32:08,935
that "First" is an adjectival modifier of "First hand" and it's firsthand experience.

588
00:32:08,935 --> 00:32:12,700
Um, so, the "First hand" is a modifier of

589
00:32:12,700 --> 00:32:18,295
"Experience" and the "Job" is also a modifier of "Experience".

590
00:32:18,295 --> 00:32:21,265
And then we have the same kind of subject,

591
00:32:21,265 --> 00:32:26,275
object, um, reading on that one.

592
00:32:26,275 --> 00:32:31,810
Um, but unfortunately, um, this sentence, um,

593
00:32:31,810 --> 00:32:34,585
has a different reading, um,

594
00:32:34,585 --> 00:32:38,050
where you change the modification relationships.

595
00:32:38,050 --> 00:32:47,830
Um, and you have it's the first experience and it goes like this. Um. [LAUGHTER] Okay.

596
00:32:47,830 --> 00:32:50,395
[NOISE] One more example.

597
00:32:50,395 --> 00:32:57,265
Um, "Mutilated body washes up on Rio beach to be used for Olympics beach volleyball."

598
00:32:57,265 --> 00:33:01,780
Um, wha- what are- [LAUGHTER]

599
00:33:01,780 --> 00:33:06,100
what are the two ambigui- What are the two readings that you can get for this one?

600
00:33:06,100 --> 00:33:11,860
[NOISE]

601
00:33:11,860 --> 00:33:15,610
We've got this big phrase that I want to try and put

602
00:33:15,610 --> 00:33:20,305
a structure of to be used for Olympic beach volleyball,

603
00:33:20,305 --> 00:33:22,300
um, and then, you know,

604
00:33:22,300 --> 00:33:26,170
this is sort of like a prepositional phrase attachment ambiguity

605
00:33:26,170 --> 00:33:30,715
but this time instead of it's a prepositional phrase that's being attached,

606
00:33:30,715 --> 00:33:34,060
we've now got this big verb phrase we call it, right,

607
00:33:34,060 --> 00:33:37,960
so that when you've sort of got most of a sentence but without any subject to it,

608
00:33:37,960 --> 00:33:40,510
that's sort of a verb phrase to be used for

609
00:33:40,510 --> 00:33:44,095
Olympic beach volleyball which might be then infinitive form.

610
00:33:44,095 --> 00:33:48,850
Sometimes it's in part of CPO form like being used for beach volleyball.

611
00:33:48,850 --> 00:33:54,970
And really, those kind of verb phrases they sort of just like, um, prepositional phrases.

612
00:33:54,970 --> 00:33:58,120
Whenever they appear towards the right end of sentences,

613
00:33:58,120 --> 00:34:01,840
they can modify various things like verbs or nouns.

614
00:34:01,840 --> 00:34:05,830
Um, so, here, um, we have two possibilities.

615
00:34:05,830 --> 00:34:09,070
So, this to be used for Olympics beach volleyball.

616
00:34:09,070 --> 00:34:14,650
Um, what the right answer is meant to be is that that is a dependent of the Rio beach.

617
00:34:14,650 --> 00:34:15,835
So, it's a, um,

618
00:34:15,835 --> 00:34:18,475
modifier of the Rio Beach.

619
00:34:18,475 --> 00:34:20,845
Um, but the funny reading is,

620
00:34:20,845 --> 00:34:23,380
um, that instead of that, um,

621
00:34:23,380 --> 00:34:28,135
we can have here is another noun phrase muti- mutilated body,

622
00:34:28,135 --> 00:34:32,425
um, and it's the mutilated body that's going to be used.

623
00:34:32,425 --> 00:34:35,590
Um, and so then this would be, uh,

624
00:34:35,590 --> 00:34:39,820
a noun phrase modifier [NOISE] of that.

625
00:34:39,820 --> 00:34:45,430
Okay. Um, so knowing the right structure of sentences is

626
00:34:45,430 --> 00:34:48,130
important to understand the interpretations you're

627
00:34:48,130 --> 00:34:51,775
meant to get and the interpretations you're not meant to get.

628
00:34:51,775 --> 00:34:55,330
Okay. But it's, it's sort of, um, okay,

629
00:34:55,330 --> 00:34:58,780
you know, I was using funny examples for the obvious reason, but, you know,

630
00:34:58,780 --> 00:35:01,720
this is sort of essential to all the things that

631
00:35:01,720 --> 00:35:05,140
we'd like to get out of language most of the time.

632
00:35:05,140 --> 00:35:07,180
So, you know, this is back to the kind of

633
00:35:07,180 --> 00:35:10,240
boring stuff that we often work with of reading through

634
00:35:10,240 --> 00:35:14,170
biomedical research articles and trying to extract facts

635
00:35:14,170 --> 00:35:18,220
about protein-protein interactions from them or something like that.

636
00:35:18,220 --> 00:35:19,720
So, you know, this is, um,

637
00:35:19,720 --> 00:35:28,465
the results demonstrated that KaiC interacts rhythmically with SasA Ka- KaiA and KaiB.

638
00:35:28,465 --> 00:35:33,550
Um, and well, [NOISE] I turned the notification's off.

639
00:35:33,550 --> 00:35:40,705
[NOISE] Um, so, if we wanna get out sort of protein-protein interaction,

640
00:35:40,705 --> 00:35:42,130
um, facts, you know, well,

641
00:35:42,130 --> 00:35:47,395
we have this KaiC that's interacting with these other proteins over there.

642
00:35:47,395 --> 00:35:53,560
And well, the way we can do that is looking at patterns in our dependency analysis,

643
00:35:53,560 --> 00:35:56,245
and so that we can sort of, um,

644
00:35:56,245 --> 00:36:00,055
see this repeated pattern where you have, um,

645
00:36:00,055 --> 00:36:07,930
the noun subject here interacts with a noun modifier,

646
00:36:07,930 --> 00:36:12,760
and then it's going to be these things that are beneath that of the SasA

647
00:36:12,760 --> 00:36:18,055
and its conjoin things KaiA and KaiB are the things that interacts with.

648
00:36:18,055 --> 00:36:24,340
So, we can kind of think of these two things as essentially, um, patterns.

649
00:36:24,340 --> 00:36:26,920
[NOISE] I actually mis-edited this.

650
00:36:26,920 --> 00:36:29,170
Sorry. This should also be nmod:with.

651
00:36:29,170 --> 00:36:33,910
[NOISE] Um, we can kind of think of

652
00:36:33,910 --> 00:36:36,010
these two things as sort of patterns and

653
00:36:36,010 --> 00:36:40,315
dependencies that we could look for to find examples of,

654
00:36:40,315 --> 00:36:46,495
um, just protein-protein interactions that appear in biomedical text.

655
00:36:46,495 --> 00:36:51,940
Okay. Um, so that's the general idea of what we wanna do,

656
00:36:51,940 --> 00:36:55,690
and so the total we want to do it with is these Dependency Grammars.

657
00:36:55,690 --> 00:36:59,305
And so, I've sort of shown you some Dependency Grammars.

658
00:36:59,305 --> 00:37:03,280
I just want us to sort of motivate Dependency Grammar a bit more,

659
00:37:03,280 --> 00:37:05,830
um, formally and fully, right?

660
00:37:05,830 --> 00:37:08,365
So, Dependency Grammar, um,

661
00:37:08,365 --> 00:37:13,210
postulates the what is syntactic structure is is that you have, um,

662
00:37:13,210 --> 00:37:15,970
relations between lexical items that are sort of

663
00:37:15,970 --> 00:37:19,690
binary asymmetric relations which we draw as arrows,

664
00:37:19,690 --> 00:37:21,520
because they are binary and asymmetric,

665
00:37:21,520 --> 00:37:23,890
and we call dependencies.

666
00:37:23,890 --> 00:37:26,290
And there's sort of two ways, common ways,

667
00:37:26,290 --> 00:37:29,290
of writing them, and I've sort of shown both now.

668
00:37:29,290 --> 00:37:33,565
One way is you sort of put the words in a line and that makes it.

669
00:37:33,565 --> 00:37:35,680
He see, let's see the whole sentence.

670
00:37:35,680 --> 00:37:38,470
You draw this sort of loopy arrows above them and

671
00:37:38,470 --> 00:37:41,905
the other way is you sort of more represent it as a tree,

672
00:37:41,905 --> 00:37:44,470
where you put the head of the whole sentence at the top,

673
00:37:44,470 --> 00:37:49,240
submitted and then you say the dependence of submitted,

674
00:37:49,240 --> 00:37:51,970
uh, bills were in Brownback and then you say,

675
00:37:51,970 --> 00:37:54,250
um, the dependence of each of those.

676
00:37:54,250 --> 00:37:58,240
Um, so, it was bills on ports and immigration.

677
00:37:58,240 --> 00:38:01,840
So, the dependence of bills and were submitted words,

678
00:38:01,840 --> 00:38:05,755
the dependent of submitted and you're giving this kind of tree structure.

679
00:38:05,755 --> 00:38:12,700
Okay. Um, so, in addition to the arrows commonly what we do is we

680
00:38:12,700 --> 00:38:19,120
put a type on each arrow which says what grammatical relations holding them between them.

681
00:38:19,120 --> 00:38:21,640
So, is this the subject of the sentence?

682
00:38:21,640 --> 00:38:23,620
Is it the object of the verb?

683
00:38:23,620 --> 00:38:25,225
Is that a, um,

684
00:38:25,225 --> 00:38:27,280
a conjunct and things like that?

685
00:38:27,280 --> 00:38:30,550
We have a system of dependency labels.

686
00:38:30,550 --> 00:38:32,815
Um, so, for the assignment,

687
00:38:32,815 --> 00:38:36,910
what we're gonna do is use universal dependencies,

688
00:38:36,910 --> 00:38:38,140
which I'll show you more,

689
00:38:38,140 --> 00:38:39,955
a little bit more in a minute.

690
00:38:39,955 --> 00:38:41,125
And if you think,

691
00:38:41,125 --> 00:38:42,790
"Man, this stuff is fascinating.

692
00:38:42,790 --> 00:38:45,250
I wanna learn all about these linguist structures."

693
00:38:45,250 --> 00:38:47,830
Um, there's a universal dependency site, um,

694
00:38:47,830 --> 00:38:50,860
that you go and can go off and look at it and learn all about them.

695
00:38:50,860 --> 00:38:54,100
But, if you don't think that's fascinating, um,

696
00:38:54,100 --> 00:38:56,365
for what we're doing for this class,

697
00:38:56,365 --> 00:38:59,095
we're never gonna make use of these labels.

698
00:38:59,095 --> 00:39:02,620
All we're doing is making use of the arrows.

699
00:39:02,620 --> 00:39:04,165
And for the arrows,

700
00:39:04,165 --> 00:39:08,590
you should be able to interpret things like prepositional phrases as to what they're

701
00:39:08,590 --> 00:39:10,930
modifying just in terms of where

702
00:39:10,930 --> 00:39:15,430
the prepositional phrases are connected and whether that's right or wrong.

703
00:39:15,430 --> 00:39:18,070
Okay. Yes. So formally,

704
00:39:18,070 --> 00:39:20,695
when we have this kind of Dependency Grammar,

705
00:39:20,695 --> 00:39:24,310
we've sort of drawing these arrows and we sort of refer to

706
00:39:24,310 --> 00:39:28,390
the thing at this end as the head of a dependency.

707
00:39:28,390 --> 00:39:33,025
And the thing at this end as the dependent of the dependency.

708
00:39:33,025 --> 00:39:36,910
And as in these examples are normal expectation

709
00:39:36,910 --> 00:39:41,170
and what our policies are gonna do is the dependencies form a tree.

710
00:39:41,170 --> 00:39:44,274
So, it's a connected acyclic single,

711
00:39:44,274 --> 00:39:47,635
um, rooted graph at the end of the day.

712
00:39:47,635 --> 00:39:52,855
Okay. So, Dependency Grammar has an enormously long history.

713
00:39:52,855 --> 00:39:59,110
So, basically, the famous first linguists that human beings know about his Panini who,

714
00:39:59,110 --> 00:40:02,125
um, wrote in the fifth century before the Common Era

715
00:40:02,125 --> 00:40:05,470
and tried to describe the structure of Sanskrit.

716
00:40:05,470 --> 00:40:09,610
And a lot of what Panini did was working out things about all of

717
00:40:09,610 --> 00:40:14,035
the morphology of Sanskrit that I'm not gonna touch at the moment.

718
00:40:14,035 --> 00:40:19,330
But beyond that, he started trying to describe the structure of Sanskrit sentences.

719
00:40:19,330 --> 00:40:23,335
And, um, the notation was sort of different but, essentially,

720
00:40:23,335 --> 00:40:26,290
the mechanism he used for describing the structure of

721
00:40:26,290 --> 00:40:29,770
Sanskrit was dependencies of sort of working out these,

722
00:40:29,770 --> 00:40:35,740
um, what are arguments in modifies of what relationships like we've been looking at.

723
00:40:35,740 --> 00:40:40,840
And indeed, if you look at kind of the history of humankind, um,

724
00:40:40,840 --> 00:40:44,380
most of attempts to understand the structure of

725
00:40:44,380 --> 00:40:48,010
human languages are essentially Dependency Grammars.

726
00:40:48,010 --> 00:40:52,870
Um, so, sort of in the later parts of the first millennium,

727
00:40:52,870 --> 00:40:56,680
there was a ton of work by Arabic grammarians and essentially what

728
00:40:56,680 --> 00:41:00,670
they used is also kind of basically a Dependency Grammar.

729
00:41:00,670 --> 00:41:03,325
Um, so compared to that, you know,

730
00:41:03,325 --> 00:41:05,740
the idea of context-free grammars and

731
00:41:05,740 --> 00:41:10,120
phrase structure grammars is incredibly incredibly new.

732
00:41:10,120 --> 00:41:12,430
I mean, you can basically, um, totally date it.

733
00:41:12,430 --> 00:41:16,570
There was this guy Wells in 1947 who first proposed

734
00:41:16,570 --> 00:41:20,980
this idea of having these constituents and phrase structure grammars,

735
00:41:20,980 --> 00:41:25,510
and where it then became really famous is through the work of Chomsky, um,

736
00:41:25,510 --> 00:41:29,725
which love him or hate him is by far the most famous, um,

737
00:41:29,725 --> 00:41:34,015
linguist and also variously contributed to Computer Science.

738
00:41:34,015 --> 00:41:35,800
Who's head of the Chomsky hierarchy?

739
00:41:35,800 --> 00:41:37,615
Do people remember that 103?

740
00:41:37,615 --> 00:41:40,210
Yeah. Okay, the Chomsky hierarchy,

741
00:41:40,210 --> 00:41:46,375
the Chomsky hierarchy was not invented to torture beginning computer science students.

742
00:41:46,375 --> 00:41:51,265
The Chomsky hierarchy was invented because Chomsky wanted to make

743
00:41:51,265 --> 00:41:57,020
arguments as to what the complexity of human languages was, um.

744
00:41:57,020 --> 00:42:00,120
Okay. Yeah. So, in modern work,

745
00:42:00,120 --> 00:42:03,180
uh, there's this guy Lucie Tesniere.

746
00:42:03,180 --> 00:42:06,120
Um, and he sort of formalized

747
00:42:06,120 --> 00:42:09,755
the kind of version of dependency grammar that I've been showing you.

748
00:42:09,755 --> 00:42:13,375
So, um we sort of often talk about his work.

749
00:42:13,375 --> 00:42:18,250
And you know it's- it's long-term being influential and computational linguistics.

750
00:42:18,250 --> 00:42:20,315
Some of the earliest parsing work in

751
00:42:20,315 --> 00:42:23,435
US Computational Linguistics was dependency grammars.

752
00:42:23,435 --> 00:42:27,030
But I won't go on about that um more now.

753
00:42:27,030 --> 00:42:29,780
Okay. Um, just one,

754
00:42:29,780 --> 00:42:32,635
two little things um, to note.

755
00:42:32,635 --> 00:42:37,434
I mean, if you somehow start looking at other papers where their dependency grammars,

756
00:42:37,434 --> 00:42:42,230
people aren't consistent on which way to have the arrows point.

757
00:42:42,230 --> 00:42:46,115
There's sort of two ways of thinking about this um,

758
00:42:46,115 --> 00:42:49,090
that you can either think okay,

759
00:42:49,090 --> 00:42:53,575
I'm gonna start at the head and point to the dependent.

760
00:42:53,575 --> 00:42:57,660
Or you can say I'm going to start at the dependent and say what its head is,

761
00:42:57,660 --> 00:42:59,080
and you find both of them.

762
00:42:59,080 --> 00:43:04,425
Uh, the way we're gonna do it in this class is to do it the way Tesniere did it,

763
00:43:04,425 --> 00:43:08,490
which was she started the head and pointed to the dependent.

764
00:43:08,490 --> 00:43:11,360
Uh, sorry. I'm drawing that wrong.

765
00:43:11,360 --> 00:43:14,920
Whoops, um because discussion of the outstanding issues.

766
00:43:14,920 --> 00:43:19,495
So, really um, the dependent is sort of discussion.

767
00:43:19,495 --> 00:43:22,065
Um, okay. We go from heads to dependence.

768
00:43:22,065 --> 00:43:26,880
And usually, it's convenient to serve in addition to the sentence to

769
00:43:26,880 --> 00:43:31,790
sort of have a fake root node that points to the head of the whole sentence.

770
00:43:31,790 --> 00:43:34,250
So, we use that as well.

771
00:43:34,250 --> 00:43:42,825
Okay. Um, so to build a dependency pauses or to indeed build

772
00:43:42,825 --> 00:43:47,679
any kind of human language structure

773
00:43:47,679 --> 00:43:51,530
finders including kind of constituency grammar pauses,

774
00:43:51,530 --> 00:43:55,470
the central tool in recent work,

775
00:43:55,470 --> 00:44:03,185
where recent work kind of means the last 25 years has been this idea of tree banks.

776
00:44:03,185 --> 00:44:08,160
Um, and the idea of tree banks is to say we are going to get

777
00:44:08,160 --> 00:44:15,605
human beings to sit around and [NOISE] put grammatical structures over sentences.

778
00:44:15,605 --> 00:44:17,660
So, here are some examples I'm showing you from

779
00:44:17,660 --> 00:44:22,070
Universal Dependencies where here are some um, English sentences.

780
00:44:22,070 --> 00:44:25,445
I think Miramar was a famous goat trainer or something.

781
00:44:25,445 --> 00:44:28,530
And some human being has sat and put

782
00:44:28,530 --> 00:44:31,760
a dependency structure over this sentence and all the rest.

783
00:44:31,760 --> 00:44:34,854
Um, and with the name Universal Dependencies,

784
00:44:34,854 --> 00:44:36,385
this is just an aside.

785
00:44:36,385 --> 00:44:40,655
Um, Universal Dependencies is actually project I've been strongly involved with.

786
00:44:40,655 --> 00:44:43,735
But precisely what the goal of universal dependencies

787
00:44:43,735 --> 00:44:47,435
was is to say what we'd like to do is have

788
00:44:47,435 --> 00:44:50,090
a uniform parallel system of

789
00:44:50,090 --> 00:44:55,035
dependency description which could be used for any human language.

790
00:44:55,035 --> 00:44:58,490
So, if you go to the Universal Dependencies website,

791
00:44:58,490 --> 00:45:00,385
it's not only about English.

792
00:45:00,385 --> 00:45:05,290
You can find Universal Dependency analyses of you know, French,

793
00:45:05,290 --> 00:45:07,235
or German, or Finish,

794
00:45:07,235 --> 00:45:09,850
or Carsac, or Indonesian,

795
00:45:09,850 --> 00:45:11,440
um, lots of languages.

796
00:45:11,440 --> 00:45:14,070
Of course, there are um, even more languages

797
00:45:14,070 --> 00:45:16,800
which there aren't Universal Dependencies analyses of.

798
00:45:16,800 --> 00:45:19,835
So, if you have a- a big calling to say I'm gonna

799
00:45:19,835 --> 00:45:23,110
build a Swahili Universal Dependencies um,

800
00:45:23,110 --> 00:45:25,415
treebank, um, you can get in touch.

801
00:45:25,415 --> 00:45:27,190
Um, but anyway.

802
00:45:27,190 --> 00:45:29,580
So, this is the idea of treebank.

803
00:45:29,580 --> 00:45:37,230
You know, historically, tree banks wasn't something that people thought of immediately.

804
00:45:37,230 --> 00:45:40,960
This so- an idea that took quite a long time to develop, right?

805
00:45:40,960 --> 00:45:44,490
That um, people started thinking about grammars

806
00:45:44,490 --> 00:45:48,340
of languages even in modern times in the fifties,

807
00:45:48,340 --> 00:45:55,760
and people started building parses for languages in the 19, early 1960s.

808
00:45:55,760 --> 00:45:59,549
So, there was decades of work in the 60s,

809
00:45:59,549 --> 00:46:03,130
70s, 80s, and no one had tree banks.

810
00:46:03,130 --> 00:46:07,140
The way people did this work is that they wrote grammars,

811
00:46:07,140 --> 00:46:10,775
that they either wrote grammars like the one I did for constituency of

812
00:46:10,775 --> 00:46:14,630
noun phrase goes to determiner, optional adjective noun.

813
00:46:14,630 --> 00:46:16,995
Noun goes to goat um,

814
00:46:16,995 --> 00:46:21,350
or the equivalent kind of grammars and a dependency format,

815
00:46:21,350 --> 00:46:26,565
and they hand built these grammars and then train,

816
00:46:26,565 --> 00:46:29,930
had parsers that could parse these sentences.

817
00:46:29,930 --> 00:46:37,480
Going into things, having a human being write a grammar feels more efficient.

818
00:46:37,480 --> 00:46:39,275
Because if you write uh,

819
00:46:39,275 --> 00:46:43,590
a rule like noun phrase goes to determiner optional adjective noun.

820
00:46:43,590 --> 00:46:46,085
I mean, that- that describes

821
00:46:46,085 --> 00:46:49,570
a huge number of phrases or actually infinite number of phrases.

822
00:46:49,570 --> 00:46:50,920
Um, so that you know,

823
00:46:50,920 --> 00:46:53,200
this is the structure of you know, the cat, the dog,

824
00:46:53,200 --> 00:46:56,910
or cat or dog, or large dog all those things we saw at the beginning.

825
00:46:56,910 --> 00:47:01,160
So, it's really efficient you're capturing lots of stuff with one rule.

826
00:47:01,160 --> 00:47:07,475
Um, but it sort of turned out that in practice that wasn't such a good idea,

827
00:47:07,475 --> 00:47:10,440
and it turned out to be much better to have

828
00:47:10,440 --> 00:47:14,210
these kind of treebank supporting structures over sentences.

829
00:47:14,210 --> 00:47:17,135
It's often a bit more subtle was to why that

830
00:47:17,135 --> 00:47:20,320
is because it sounds like pretty menial work um,

831
00:47:20,320 --> 00:47:22,850
building tree banks, and in some sense it is.

832
00:47:22,850 --> 00:47:25,060
Um, but you know,

833
00:47:25,060 --> 00:47:27,815
it turns out to be much more useful.

834
00:47:27,815 --> 00:47:33,535
I mean, so one huge benefit is that treebanks are very reusable.

835
00:47:33,535 --> 00:47:36,190
That effectively what they was in 60s, 70s,

836
00:47:36,190 --> 00:47:39,450
and 80s was that every different you know,

837
00:47:39,450 --> 00:47:42,965
people who started about building a parser invented

838
00:47:42,965 --> 00:47:46,970
their own notation for grammar rules which got more and more complex,

839
00:47:46,970 --> 00:47:50,675
and it was only used by their parser and nobody else's parser.

840
00:47:50,675 --> 00:47:54,610
So, there was no sharing and reuse of the work those done by human beings.

841
00:47:54,610 --> 00:47:55,990
Well, once you have a treebank,

842
00:47:55,990 --> 00:48:01,510
it's reusable for all sorts of purposes that lots of people build parsers format.

843
00:48:01,510 --> 00:48:04,890
But also other people use it as well like linguists now often used

844
00:48:04,890 --> 00:48:08,650
tree banks to find examples of different constructions.

845
00:48:08,650 --> 00:48:10,400
Um, but beyond that,

846
00:48:10,400 --> 00:48:14,695
this sort of just became necessary once we wanted to do machine learning.

847
00:48:14,695 --> 00:48:17,405
So that if we want to do machine learning,

848
00:48:17,405 --> 00:48:20,240
we want to have data that we can build models on.

849
00:48:20,240 --> 00:48:21,730
In particular, a lot of what

850
00:48:21,730 --> 00:48:27,015
our machine learning models exploit is how common are different structures.

851
00:48:27,015 --> 00:48:30,645
So, we want to know about the commoners and the frequency of things.

852
00:48:30,645 --> 00:48:34,335
Um, but then treebanks gave us another big thing which is,

853
00:48:34,335 --> 00:48:37,365
well, lots of sentences are ambiguous,

854
00:48:37,365 --> 00:48:44,530
and what we want to do is build models that find the right structure for sentences.

855
00:48:44,530 --> 00:48:48,065
If all you do is have a grammar you have no way of

856
00:48:48,065 --> 00:48:51,805
telling what is the right structure for ambiguous sentences.

857
00:48:51,805 --> 00:48:54,620
All you can do is say hey that sentence with

858
00:48:54,620 --> 00:48:58,780
four prepositional phrases after it that I showed you earlier,

859
00:48:58,780 --> 00:49:00,430
it has 14 different parsers.

860
00:49:00,430 --> 00:49:02,075
Let me show you all of them.

861
00:49:02,075 --> 00:49:04,890
Um, but once you have um,

862
00:49:04,890 --> 00:49:12,185
treebank examples, you can say this is the right structure for this sentence in context.

863
00:49:12,185 --> 00:49:17,255
So, you should be building a machine learning model which will recover that structure,

864
00:49:17,255 --> 00:49:19,020
and if you don't that you're wrong.

865
00:49:19,020 --> 00:49:23,980
[NOISE]. Okay. Um, so that's treebanks.

866
00:49:23,980 --> 00:49:28,320
Um, so how are we gonna do build dependency parsers?

867
00:49:28,320 --> 00:49:34,790
Well, somehow we want models that can kind of capture what's the right parse.

868
00:49:34,790 --> 00:49:37,240
Just thinking about abstractly, you know,

869
00:49:37,240 --> 00:49:40,340
there's sort of different things that we can pay attention to.

870
00:49:40,340 --> 00:49:46,030
So, one thing that we can pay attention to is the sort of actual words, right?

871
00:49:46,030 --> 00:49:47,490
Discussion of issues.

872
00:49:47,490 --> 00:49:49,590
That's a reasonable thing.

873
00:49:49,590 --> 00:49:55,235
So, it's reasonable to have issues as dependent of discussion um,

874
00:49:55,235 --> 00:49:58,090
where you know, discussion of outstanding.

875
00:49:58,090 --> 00:49:59,105
That sounds weird.

876
00:49:59,105 --> 00:50:01,570
So, you probably don't want that dependency.

877
00:50:01,570 --> 00:50:05,045
Um, there's a question of how far apart words are.

878
00:50:05,045 --> 00:50:07,480
Most dependencies are fairly short distance.

879
00:50:07,480 --> 00:50:08,960
They not all of them are.

880
00:50:08,960 --> 00:50:11,385
There's a question of what's in between.

881
00:50:11,385 --> 00:50:13,385
Um, if there's a semicolon in between,

882
00:50:13,385 --> 00:50:15,335
there probably is an a dependency across that.

883
00:50:15,335 --> 00:50:20,190
Um, and the other issue is sort of how many arguments do things take?

884
00:50:20,190 --> 00:50:22,355
So, here we have was completed.

885
00:50:22,355 --> 00:50:24,590
If you see the words was completed,

886
00:50:24,590 --> 00:50:29,410
you sort of expect that there'll be a subject before of the something was completed,

887
00:50:29,410 --> 00:50:31,145
and it would be wrong if there wasn't.

888
00:50:31,145 --> 00:50:34,470
So, you're expecting an argument on that side.

889
00:50:34,470 --> 00:50:37,960
But on the other side, hand it won't have object after it.

890
00:50:37,960 --> 00:50:41,630
You won't say the discussion was completed the goat.

891
00:50:41,630 --> 00:50:44,080
Um, that's not a good sentence, right?

892
00:50:44,080 --> 00:50:47,135
So, you won't have ah, um, an object after it.

893
00:50:47,135 --> 00:50:49,060
So, there's sort of information of that sort,

894
00:50:49,060 --> 00:50:54,305
and we want to have our dependency parsers be able to make use of that structure.

895
00:50:54,305 --> 00:50:56,830
[NOISE] Okay.

896
00:50:56,830 --> 00:51:04,360
Um, so effectively what we do when we build a dependency parser is going to say,

897
00:51:04,360 --> 00:51:11,560
for each word is- is going to be the dependent of some other word or the root.

898
00:51:11,560 --> 00:51:15,600
So, this give here is actually the head of the sentence.

899
00:51:15,600 --> 00:51:17,570
So, it's a dependent of root,

900
00:51:17,570 --> 00:51:20,620
the talk is a dependent of give,

901
00:51:20,620 --> 00:51:24,040
'll is a dependent of talk.

902
00:51:24,040 --> 00:51:28,660
And so, for each word we want to choose what is

903
00:51:28,660 --> 00:51:34,600
the dependent of and we want to do it in such a way that the dependencies form a tree.

904
00:51:34,600 --> 00:51:39,565
So that means it would be a bad idea if we made a cycle.

905
00:51:39,565 --> 00:51:43,435
So, if we sort of said, Bootstrapping, um,

906
00:51:43,435 --> 00:51:47,860
was a dependent of, um, talk,

907
00:51:47,860 --> 00:51:52,420
um, but then we had things sort of move around.

908
00:51:52,420 --> 00:51:53,935
So,this goes to here,

909
00:51:53,935 --> 00:51:55,600
but then talk is a dependent that,

910
00:51:55,600 --> 00:51:57,430
and so I'm gonna cycle that's bad news,

911
00:51:57,430 --> 00:52:00,145
we don't want cycles, we want a tree.

912
00:52:00,145 --> 00:52:03,175
And there's one final issue,

913
00:52:03,175 --> 00:52:06,970
um, which is we don't want things that,

914
00:52:06,970 --> 00:52:11,680
um, is whether we want to allow dependencies to cross or not,

915
00:52:11,680 --> 00:52:14,035
um, and this is an example of this.

916
00:52:14,035 --> 00:52:16,405
So, most of the time, um,

917
00:52:16,405 --> 00:52:19,180
dependencies don't cross each other.

918
00:52:19,180 --> 00:52:22,180
Uh, but sometimes they do,

919
00:52:22,180 --> 00:52:26,770
and this example here is actually an instance for that.

920
00:52:26,770 --> 00:52:31,195
So, I'll give a talk tomorrow, um, on bootstrapping.

921
00:52:31,195 --> 00:52:35,710
So, we're giving a talk that's the object,

922
00:52:35,710 --> 00:52:39,025
and when it's being given is tomorrow,

923
00:52:39,025 --> 00:52:43,240
but this talk has a modifier that's on bootstrapping.

924
00:52:43,240 --> 00:52:50,905
So, we actually have another dependency here that crosses, um, that dependency.

925
00:52:50,905 --> 00:52:52,150
And that's sort of rare,

926
00:52:52,150 --> 00:52:53,890
that doesn't happen a ton in English,

927
00:52:53,890 --> 00:52:57,085
but it happens sometimes in some structures like that.

928
00:52:57,085 --> 00:52:59,770
And so, this is the question of whether, um,

929
00:52:59,770 --> 00:53:04,900
what we say is that the positive sentence is projective if there

930
00:53:04,900 --> 00:53:10,015
no crossing dependencies and it's non-projective if there are crossing dependencies,

931
00:53:10,015 --> 00:53:12,370
and most of the time, English's projective and it's

932
00:53:12,370 --> 00:53:15,130
parses of sentences, but occasionally not.

933
00:53:15,130 --> 00:53:16,780
And when it's not is when you kind of have

934
00:53:16,780 --> 00:53:20,740
these constituents that are delayed to the end of the sentence, right?

935
00:53:20,740 --> 00:53:24,055
You could've said, I'll give a talk on bootstrapping tomorrow,

936
00:53:24,055 --> 00:53:27,490
and then a [inaudible] have a projective parse, but if you want to,

937
00:53:27,490 --> 00:53:30,940
you can kind of delay that extra modifier and say I'll give a talk

938
00:53:30,940 --> 00:53:34,780
tomorrow on bootstrapping and then the parse becomes non-projective.

939
00:53:34,780 --> 00:53:38,410
Um, okay.

940
00:53:38,410 --> 00:53:40,450
So, that's that.

941
00:53:40,450 --> 00:53:43,285
Um, there are various ways of,

942
00:53:43,285 --> 00:53:46,435
um, doing dependency parsing,

943
00:53:46,435 --> 00:53:50,200
but basically what I am gonna tell you about today is this one called

944
00:53:50,200 --> 00:53:54,205
transition-based or deterministic dependency parsing,

945
00:53:54,205 --> 00:53:55,555
and this is, um,

946
00:53:55,555 --> 00:54:01,030
the one that's just been enormously influential in practical deployments of parsing.

947
00:54:01,030 --> 00:54:04,375
So, when Google goes off and parses every web page,

948
00:54:04,375 --> 00:54:07,690
what they're using is a transition based parser.

949
00:54:07,690 --> 00:54:12,040
Um, and so, this was a notion of parsing that, um,

950
00:54:12,040 --> 00:54:14,800
was mainly popularized by this guy,

951
00:54:14,800 --> 00:54:17,980
walk him Joakim Nivre, he is a Swedish computational linguists.

952
00:54:17,980 --> 00:54:25,075
Um, and what you do it's- it's sort of inspired by shift-reduce parsing.

953
00:54:25,075 --> 00:54:29,980
So, probably in- in our CS103 or compilers class or something,

954
00:54:29,980 --> 00:54:32,650
you saw a little bit of shift-reduce parsing.

955
00:54:32,650 --> 00:54:35,965
And this is sort of like a shift-reduce parser,

956
00:54:35,965 --> 00:54:38,710
apart from when we reduce,

957
00:54:38,710 --> 00:54:42,430
we build dependencies instead of constituent.

958
00:54:42,430 --> 00:54:46,270
Um, and this has a lot of very technical description that

959
00:54:46,270 --> 00:54:50,515
doesn't help you at all to look at in terms of understanding what,

960
00:54:50,515 --> 00:54:53,080
um, a shift-reduce parser does.

961
00:54:53,080 --> 00:54:55,570
And here's a formal description of a

962
00:54:55,570 --> 00:54:59,890
transition-based shift-reduce parser and which also doesn't help you at all.

963
00:54:59,890 --> 00:55:02,770
Um, so, instead we kinda look at this example,

964
00:55:02,770 --> 00:55:05,335
uh, [LAUGHTER] because that will hopefully help you.

965
00:55:05,335 --> 00:55:10,030
So, what I wanna to do is parse the sentence "I ate fish".

966
00:55:10,030 --> 00:55:14,530
And yet formally what I have is I have a why I start,

967
00:55:14,530 --> 00:55:17,500
there are three actions I can take and I have

968
00:55:17,500 --> 00:55:20,895
a finished condition for formal parse, parse.

969
00:55:20,895 --> 00:55:23,410
Um, and so here's what I do.

970
00:55:23,410 --> 00:55:29,080
So, I have a stack which is on this side and I have a buffer.

971
00:55:29,080 --> 00:55:32,455
Um, so, the stack is what I have built,

972
00:55:32,455 --> 00:55:36,055
and the buffer is all the words in the sentence I haven't dealt with yet.

973
00:55:36,055 --> 00:55:38,020
So, I stop the parse,

974
00:55:38,020 --> 00:55:41,575
and that's the sort of instruction here, by putting route,

975
00:55:41,575 --> 00:55:44,395
my root for my whole sentence onto my stack,

976
00:55:44,395 --> 00:55:47,200
and my buffer is the whole sentence,

977
00:55:47,200 --> 00:55:49,630
and I haven't found any dependencies yet.

978
00:55:49,630 --> 00:55:51,055
Okay, and so then,

979
00:55:51,055 --> 00:55:55,645
the actions I can take is to shift things onto the stack

980
00:55:55,645 --> 00:56:01,570
or to do the equivalent of a Reduce where I build dependencies.

981
00:56:01,570 --> 00:56:03,945
So, starting off, um,

982
00:56:03,945 --> 00:56:07,755
I can't build a dependency because I only have root on the stack,

983
00:56:07,755 --> 00:56:09,840
so the only thing I can do is shift,

984
00:56:09,840 --> 00:56:12,215
so I can shift I onto the stack.

985
00:56:12,215 --> 00:56:14,800
Um, now, I could at this point say,

986
00:56:14,800 --> 00:56:16,150
let's build a dependency,

987
00:56:16,150 --> 00:56:17,680
I is a dependent of root,

988
00:56:17,680 --> 00:56:19,660
but that would be the wrong analysis,

989
00:56:19,660 --> 00:56:23,080
because really the head of this sentence is I ate.

990
00:56:23,080 --> 00:56:26,065
So, I'm a clever boy and I shift again.

991
00:56:26,065 --> 00:56:30,205
And now I have root I ate on the stack.

992
00:56:30,205 --> 00:56:33,280
Okay, and so, at this point,

993
00:56:33,280 --> 00:56:34,720
I'm in a position where,

994
00:56:34,720 --> 00:56:40,105
hey, what I'm gonna do is reductions that build structure, because look,

995
00:56:40,105 --> 00:56:44,125
I have I ate here and I want to be able to say

996
00:56:44,125 --> 00:56:49,600
that I is the subject of dependency of ate,

997
00:56:49,600 --> 00:56:51,130
and I will do that by,

998
00:56:51,130 --> 00:56:54,595
um, by doing a reduction.

999
00:56:54,595 --> 00:57:00,730
And so, what I'm gonna do is the left-arc reduction, which says, look,

1000
00:57:00,730 --> 00:57:04,494
I'm gonna treat the second from top thing on the stack

1001
00:57:04,494 --> 00:57:08,605
as a dependent of the thing that's on top of the stack.

1002
00:57:08,605 --> 00:57:10,210
And so, I do that,

1003
00:57:10,210 --> 00:57:12,520
and so, when I do that,

1004
00:57:12,520 --> 00:57:17,575
I create the second from the head thing as a subject dependent of ate,

1005
00:57:17,575 --> 00:57:21,085
and I leave the head on the stack ate,

1006
00:57:21,085 --> 00:57:25,675
but I sort of add this dependencies as other dependencies I've built.

1007
00:57:25,675 --> 00:57:29,305
Okay, um, so, I do that.

1008
00:57:29,305 --> 00:57:34,720
Um, now, I could immediately reduce again and say ate is a dependent of root,

1009
00:57:34,720 --> 00:57:37,855
but my sentence's actually I ate fish.

1010
00:57:37,855 --> 00:57:40,990
So, what I want to do is say, "Oh,

1011
00:57:40,990 --> 00:57:45,610
if it's still fish on the buffer," so what I should first do is shift again,

1012
00:57:45,610 --> 00:57:48,265
have root ate fish in my sentence,

1013
00:57:48,265 --> 00:57:49,960
and then I'll be able to say, Look,

1014
00:57:49,960 --> 00:57:52,795
I want to now build, um,

1015
00:57:52,795 --> 00:57:55,705
the thing on the top of this stack as

1016
00:57:55,705 --> 00:57:59,905
a right dependent of the thing that's second from top of the stack,

1017
00:57:59,905 --> 00:58:02,664
and so that's referred to as a Right-Arc move,

1018
00:58:02,664 --> 00:58:05,680
and so, I say Right Arc, and so,

1019
00:58:05,680 --> 00:58:08,410
I do a reduction where I've generated

1020
00:58:08,410 --> 00:58:14,245
a new dependency and I take the two things that are on top of the stack and say,

1021
00:58:14,245 --> 00:58:17,245
um, fish is a dependent of ate,

1022
00:58:17,245 --> 00:58:20,575
and so therefore, I just keep the head.

1023
00:58:20,575 --> 00:58:25,915
I always just keep the hit on the stack and the- and I generate this new Arc.

1024
00:58:25,915 --> 00:58:27,640
And so, at this point,

1025
00:58:27,640 --> 00:58:33,685
I'm in the same position I want to say that this ate is a right dependent of my route,

1026
00:58:33,685 --> 00:58:36,985
and so, I'm again going to do Right Arc,

1027
00:58:36,985 --> 00:58:40,840
um, and make this extra dependency here.

1028
00:58:40,840 --> 00:58:43,450
Okay. So, then my finished condition of having

1029
00:58:43,450 --> 00:58:46,420
successfully parsed the sentence is my buffer is

1030
00:58:46,420 --> 00:58:52,600
empty and I just have root left on my stack because that's what I sort of said back here,

1031
00:58:52,600 --> 00:58:55,675
that was, buffer is empty as my finished condition.

1032
00:58:55,675 --> 00:58:59,230
Okay. So, I've parsed the sentence.

1033
00:58:59,230 --> 00:59:01,870
So that worked well but, you know,

1034
00:59:01,870 --> 00:59:07,870
I actually had different choices of when to pa- when to shift and when to reduce.

1035
00:59:07,870 --> 00:59:12,325
And I just miraculously made the right choice at each point.

1036
00:59:12,325 --> 00:59:16,630
And well, one thing you could do at this point is say, well,

1037
00:59:16,630 --> 00:59:20,155
you could have explored every choice and,

1038
00:59:20,155 --> 00:59:24,355
um, seen what happened and gone different parsers.

1039
00:59:24,355 --> 00:59:25,765
And I could have,

1040
00:59:25,765 --> 00:59:28,269
but if that's what I'd done,

1041
00:59:28,269 --> 00:59:35,680
I would've explored this exponential size tree of different possible parsers.

1042
00:59:35,680 --> 00:59:37,570
And if that was what I was doing,

1043
00:59:37,570 --> 00:59:39,610
I wouldn't be able to parse efficiently.

1044
00:59:39,610 --> 00:59:44,110
And indeed that's not what people did in the 60s, 70s and 80s.

1045
00:59:44,110 --> 00:59:47,305
Uh, clever people in the 60s said,

1046
00:59:47,305 --> 00:59:50,305
uh, rather than doing a crummy search here,

1047
00:59:50,305 --> 00:59:54,430
we can come up with clever dynamic programming algorithms and you

1048
00:59:54,430 --> 00:59:58,870
can relatively efficiently explore the space of all possible parsers.

1049
00:59:58,870 --> 01:00:03,295
Uh, and that was sort of the mainstay of parsing in those decades.

1050
01:00:03,295 --> 01:00:06,700
But when Joakim Nivre came along,

1051
01:00:06,700 --> 01:00:10,420
he said "Yeah, that's true, um, but hey,

1052
01:00:10,420 --> 01:00:12,595
I've got a clever idea, uh,

1053
01:00:12,595 --> 01:00:18,220
because now it's the 2000s and I know machine learning."

1054
01:00:18,220 --> 01:00:21,550
Um, so, what I could do instead,

1055
01:00:21,550 --> 01:00:26,890
is say I'm at a particular position in the parse and I'm gonna build

1056
01:00:26,890 --> 01:00:30,340
a machine learning classifier and that machine learning

1057
01:00:30,340 --> 01:00:33,970
classifier is gonna tell me the next thing to do.

1058
01:00:33,970 --> 01:00:36,250
It's gonna tell me whether to shift,

1059
01:00:36,250 --> 01:00:39,955
um, with left arc or right arc.

1060
01:00:39,955 --> 01:00:42,550
So, if we're only just so talking about, well,

1061
01:00:42,550 --> 01:00:43,750
how to build the arrows,

1062
01:00:43,750 --> 01:00:45,160
they're just three actions,

1063
01:00:45,160 --> 01:00:47,215
shift, left arc or right arc.

1064
01:00:47,215 --> 01:00:50,770
Um, if we also wanted to put labels on the dependencies,

1065
01:00:50,770 --> 01:00:53,140
and we have our different labels, um,

1066
01:00:53,140 --> 01:00:56,110
there are then sort of 2R plus actions because she is

1067
01:00:56,110 --> 01:01:00,790
sort of left arc subject or left arc object or something like that.

1068
01:01:00,790 --> 01:01:04,060
But anyway, there's a set of actions and so you gonna build

1069
01:01:04,060 --> 01:01:07,570
a classifier with machine learning somehow which will predict

1070
01:01:07,570 --> 01:01:14,685
the right action and Joakim Nivre showed the sort of slightly surprising fact

1071
01:01:14,685 --> 01:01:22,530
that actually you could predict the correct action to take with high accuracy.

1072
01:01:22,530 --> 01:01:27,265
So, um, in the simplest version of this,

1073
01:01:27,265 --> 01:01:29,440
um, there's absolutely no search.

1074
01:01:29,440 --> 01:01:31,720
You just run a classifier at each step and it

1075
01:01:31,720 --> 01:01:34,090
says "What you should do next is shift" and you shift,

1076
01:01:34,090 --> 01:01:36,820
and then it says "What you should do is left arc" and you left arc

1077
01:01:36,820 --> 01:01:39,685
and you run that through and he proved, no,

1078
01:01:39,685 --> 01:01:42,385
he showed empirically, that even doing that,

1079
01:01:42,385 --> 01:01:45,565
you could parse sentences with high accuracy.

1080
01:01:45,565 --> 01:01:47,380
Now if you wanna do some searching around,

1081
01:01:47,380 --> 01:01:48,505
you can do a bit better,

1082
01:01:48,505 --> 01:01:50,440
but it's not necessary.

1083
01:01:50,440 --> 01:01:54,700
Um, and we're not gonna do it for our, um, assignment.

1084
01:01:54,700 --> 01:01:58,480
But so if you're doing this just sort of run classify,

1085
01:01:58,480 --> 01:02:01,434
predict action, run classify, predict action,

1086
01:02:01,434 --> 01:02:04,030
we then get this wonderful result which

1087
01:02:04,030 --> 01:02:07,645
you're meant to explain a bit honest on your assignment 3,

1088
01:02:07,645 --> 01:02:11,275
is that what we've built is a linear time parser.

1089
01:02:11,275 --> 01:02:15,370
Right? That because we are gonna be sort of- as we chug through a sentence,

1090
01:02:15,370 --> 01:02:17,485
where we're only doing a linear amount of work for

1091
01:02:17,485 --> 01:02:21,220
each word and that was sort of an enormous breakthrough.

1092
01:02:21,220 --> 01:02:23,380
Because although people in the 60s hadn't come

1093
01:02:23,380 --> 01:02:25,840
up with these dynamic programming algorithms,

1094
01:02:25,840 --> 01:02:31,705
dynamic programming algorithms for sentences were always cubic or worse.

1095
01:02:31,705 --> 01:02:34,375
And that's not very good if you want to parse the whole web,

1096
01:02:34,375 --> 01:02:37,450
whereas if you have something that's linear time,

1097
01:02:37,450 --> 01:02:40,105
that's really getting you places.

1098
01:02:40,105 --> 01:02:45,085
Okay. So this is the conventional way in which this was done.

1099
01:02:45,085 --> 01:02:48,010
Was, you know, we have a stack,

1100
01:02:48,010 --> 01:02:50,750
we might have already built some structure if we

1101
01:02:50,750 --> 01:02:53,410
hadn't working out something's dependent of something.

1102
01:02:53,410 --> 01:02:57,790
We have a buffer of words that we don't deal with and we want to predict the next action.

1103
01:02:57,790 --> 01:03:00,910
So the conventional way to do this is to say well,

1104
01:03:00,910 --> 01:03:02,665
we want to have features.

1105
01:03:02,665 --> 01:03:06,100
And well, the kind of features you wanted was so

1106
01:03:06,100 --> 01:03:09,535
the usually some kind of conjunction or multiple things so

1107
01:03:09,535 --> 01:03:13,720
that if the top word of the stack is good,

1108
01:03:13,720 --> 01:03:18,760
um, and something else is true, right,

1109
01:03:18,760 --> 01:03:22,930
that the second top word of the stack it has,

1110
01:03:22,930 --> 01:03:25,120
and it's part of speech is verb,

1111
01:03:25,120 --> 01:03:27,580
then maybe that's an indicator of do some action.

1112
01:03:27,580 --> 01:03:31,705
So ha- had these very complex binary indicator features

1113
01:03:31,705 --> 01:03:35,710
and you'd build- you literally have millions of

1114
01:03:35,710 --> 01:03:39,130
these binary indicator features and you'd feed them into

1115
01:03:39,130 --> 01:03:41,530
some big logistic regression or

1116
01:03:41,530 --> 01:03:46,705
support vector machine or something like that and you would build parses.

1117
01:03:46,705 --> 01:03:48,775
And these parses worked pretty well.

1118
01:03:48,775 --> 01:03:55,600
Um, but you sort of had these sort of very complex hand engineered binary features.

1119
01:03:55,600 --> 01:04:00,520
Um, so in the last bit of lecture I want to show you what people have done in the,

1120
01:04:00,520 --> 01:04:02,980
um, neural dependency parsing world.

1121
01:04:02,980 --> 01:04:04,270
But before I do that,

1122
01:04:04,270 --> 01:04:05,890
let me just explain how you,

1123
01:04:05,890 --> 01:04:11,220
um, how you evaluate, um, dependency parses.

1124
01:04:11,220 --> 01:04:13,200
And that's actually very simple, right?

1125
01:04:13,200 --> 01:04:16,130
So, what you do is well,

1126
01:04:16,130 --> 01:04:18,880
you assume because the human wrote it down,

1127
01:04:18,880 --> 01:04:22,300
that there is a correct dependency parse for a sentence.

1128
01:04:22,300 --> 01:04:24,580
She saw the video lecture like this.

1129
01:04:24,580 --> 01:04:29,560
And so these are the correct arcs and to evaluate our dependency parser,

1130
01:04:29,560 --> 01:04:32,140
we're simply gonna say,

1131
01:04:32,140 --> 01:04:34,465
uh, which arcs are correct.

1132
01:04:34,465 --> 01:04:36,505
So, there are the gold arcs,

1133
01:04:36,505 --> 01:04:38,410
so there's a gold arc,

1134
01:04:38,410 --> 01:04:41,439
um, from two to one,

1135
01:04:41,439 --> 01:04:47,110
She saw subject, and there's a gold arc from zero to two,

1136
01:04:47,110 --> 01:04:48,190
the root of the sentence,

1137
01:04:48,190 --> 01:04:49,825
these the gold arcs.

1138
01:04:49,825 --> 01:04:52,480
Um, if we generate a parse,

1139
01:04:52,480 --> 01:04:56,935
we're gonna propose some arcs as to what is the head of each word.

1140
01:04:56,935 --> 01:05:00,685
And we're simply going to count up how many of them are correct,

1141
01:05:00,685 --> 01:05:02,785
treating each arc individually.

1142
01:05:02,785 --> 01:05:04,900
And there are two ways we can do that.

1143
01:05:04,900 --> 01:05:07,885
We can either, as we're going to do,

1144
01:05:07,885 --> 01:05:11,500
ignore the labels and that's then,

1145
01:05:11,500 --> 01:05:15,865
uh, referred to as the unlabeled attachment score.

1146
01:05:15,865 --> 01:05:19,000
So here in my example, my dependency paths,

1147
01:05:19,000 --> 01:05:23,860
I've got most of the arcs right but it got this one wrong.

1148
01:05:23,860 --> 01:05:28,690
So I say my unlabeled attachment score is 80 percent or we can also

1149
01:05:28,690 --> 01:05:33,820
look at the labels and then my parser wasn't very good at getting the labels rights,

1150
01:05:33,820 --> 01:05:35,380
so I'm only getting 40 percent.

1151
01:05:35,380 --> 01:05:40,810
And so we can just count up the number of dependencies and how many we get correct.

1152
01:05:40,810 --> 01:05:44,080
And that's in our accuracy and in the assignment,

1153
01:05:44,080 --> 01:05:49,225
you're meant to build a dependency parser with a certain accuracy.

1154
01:05:49,225 --> 01:05:51,265
I forget the number now is saying,

1155
01:05:51,265 --> 01:05:55,645
some number 80 something or something that you're meant to get to.

1156
01:05:55,645 --> 01:05:58,855
Okay. Um, maybe I'll skip that.

1157
01:05:58,855 --> 01:06:03,370
Okay. Um, so, now I wanted to sort of explain to you just a bit

1158
01:06:03,370 --> 01:06:07,780
about neural dependency parses and why they are motivated.

1159
01:06:07,780 --> 01:06:11,845
So I'd mentioned to you already that the conventional model, uh,

1160
01:06:11,845 --> 01:06:16,360
had these sort of indicated features of, um,

1161
01:06:16,360 --> 01:06:19,180
on the top of the stack is the word good and the second thing on

1162
01:06:19,180 --> 01:06:22,360
the stack is the verb has or on

1163
01:06:22,360 --> 01:06:28,720
the top of the stack is some other word and the second top is of some part of speech.

1164
01:06:28,720 --> 01:06:30,670
And that part of speech has already been

1165
01:06:30,670 --> 01:06:32,620
joined with the dependency of another part of speech.

1166
01:06:32,620 --> 01:06:35,500
People hand-engineer these features.

1167
01:06:35,500 --> 01:06:36,760
And the problems with that,

1168
01:06:36,760 --> 01:06:39,040
was these features were very sparse.

1169
01:06:39,040 --> 01:06:42,100
Each of these features matches very few things.

1170
01:06:42,100 --> 01:06:48,865
Um, they match some configurations but not others so the features tend to be incomplete.

1171
01:06:48,865 --> 01:06:51,760
Um, and there are a lot of them,

1172
01:06:51,760 --> 01:06:54,655
they're are commonly millions of features.

1173
01:06:54,655 --> 01:06:57,040
And so it turned out that actually computing

1174
01:06:57,040 --> 01:07:01,690
these features was just expensive so that you had some configuration on

1175
01:07:01,690 --> 01:07:05,260
your stack and the buffer and then you wanted to know which of

1176
01:07:05,260 --> 01:07:10,945
these features were active for that stack and buffer configuration.

1177
01:07:10,945 --> 01:07:13,315
And so you had to compute features format.

1178
01:07:13,315 --> 01:07:14,500
And it turned out that

1179
01:07:14,500 --> 01:07:19,795
conventional dependency parsers spent most of their time computing features,

1180
01:07:19,795 --> 01:07:24,640
then went into the machine learning model rather than doing the sort of shifting and,

1181
01:07:24,640 --> 01:07:28,810
which you're are seeing, are just a pure parser operation.

1182
01:07:28,810 --> 01:07:34,030
And so that seemed like it left open the possibility that, well,

1183
01:07:34,030 --> 01:07:38,110
what if we could get rid of all of this stuff and we could run

1184
01:07:38,110 --> 01:07:43,360
a neural network directly on the stack and buffer configuration,

1185
01:07:43,360 --> 01:07:48,550
then maybe that would allow us to build a dependency parser which was

1186
01:07:48,550 --> 01:07:55,705
faster and suffer less from issues of sparseness than the conventional dependency parser.

1187
01:07:55,705 --> 01:08:02,785
And so that was a project that Dan Chi Chen and me tried to do in 2014,

1188
01:08:02,785 --> 01:08:06,310
uh, we used to build a neural dependency parser.

1189
01:08:06,310 --> 01:08:09,565
And, you know, effectively what we found,

1190
01:08:09,565 --> 01:08:12,730
is that that's exactly what you could do.

1191
01:08:12,730 --> 01:08:15,940
So, here's sort of a few stats here.

1192
01:08:15,940 --> 01:08:18,940
So these are these same UAS and LAS.

1193
01:08:18,940 --> 01:08:24,430
Uh, so MaltParser was Joakim Nivre's Parser that I sort of,

1194
01:08:24,430 --> 01:08:27,490
uh, we started showing before.

1195
01:08:27,490 --> 01:08:28,735
And they've got, um,

1196
01:08:28,735 --> 01:08:33,625
a UAS on this data of 89,8.

1197
01:08:33,625 --> 01:08:35,500
But everybody loved that.

1198
01:08:35,500 --> 01:08:41,590
And the reason they loved it is it could parse at 469 sentences a second.

1199
01:08:41,590 --> 01:08:44,500
There had been other people that have worked out

1200
01:08:44,500 --> 01:08:47,350
different more complex ways

1201
01:08:47,350 --> 01:08:52,360
of doing parsing with so-called graph-based dependency parsers.

1202
01:08:52,360 --> 01:08:56,380
So this is another famous dependency parser from the 90s.

1203
01:08:56,380 --> 01:08:58,660
So it was actually, you know,

1204
01:08:58,660 --> 01:09:01,600
a bit more accurate but it was a bit more

1205
01:09:01,600 --> 01:09:05,680
accurate at the cost of being two orders of magnitude slower.

1206
01:09:05,680 --> 01:09:07,780
And, you know, people have worked on top of that.

1207
01:09:07,780 --> 01:09:11,680
So, here is an even more complex graph-based parser, uh,

1208
01:09:11,680 --> 01:09:14,350
from the 2000s and well, you know,

1209
01:09:14,350 --> 01:09:17,890
it's a little bit more accurate again but it's gotten even slower.

1210
01:09:17,890 --> 01:09:19,450
Um, okay.

1211
01:09:19,450 --> 01:09:25,210
So, what we were able to show is that using the idea of instead using

1212
01:09:25,210 --> 01:09:33,055
a neural network to make the decisions of Joakim Nivre Style shift-reduce parser,

1213
01:09:33,055 --> 01:09:37,180
we could produce something that was almost

1214
01:09:37,180 --> 01:09:41,380
as accurate as the very best parsers available at that time.

1215
01:09:41,380 --> 01:09:45,745
I mean, strictly we won over here and we are a fraction behind on UAS.

1216
01:09:45,745 --> 01:09:47,610
Um, but, you know,

1217
01:09:47,610 --> 01:09:51,840
it was not only just as fast as Nivre's parser,

1218
01:09:51,840 --> 01:09:54,795
it was actually faster than Nivre's parser,

1219
01:09:54,795 --> 01:09:59,520
because we didn't have to spend as much time on feature computation.

1220
01:09:59,520 --> 01:10:02,175
And that's actually almost a surprising result, right?

1221
01:10:02,175 --> 01:10:04,690
It's not that we didn't have to do anything.

1222
01:10:04,690 --> 01:10:08,050
We had to do matrix multiplies in our neural network,

1223
01:10:08,050 --> 01:10:09,805
but it turned out, um,

1224
01:10:09,805 --> 01:10:13,330
you could do the matrix multiplies more quickly than

1225
01:10:13,330 --> 01:10:17,350
the feature computation that he was doing even though at the end of the day,

1226
01:10:17,350 --> 01:10:21,235
it was sort of looking at weights that went into a support vector machine.

1227
01:10:21,235 --> 01:10:23,020
So that was kind of cool.

1228
01:10:23,020 --> 01:10:25,420
And so the secret was we're gonna make use of

1229
01:10:25,420 --> 01:10:31,025
distributed representations like we've already seen for words.

1230
01:10:31,025 --> 01:10:32,970
So for each word,

1231
01:10:32,970 --> 01:10:35,645
we're going to represent it as a word embedding,

1232
01:10:35,645 --> 01:10:38,005
like we've all what already seen.

1233
01:10:38,005 --> 01:10:40,175
And in particular, um,

1234
01:10:40,175 --> 01:10:44,260
we are gonna make use of word vectors

1235
01:10:44,260 --> 01:10:49,075
and use them as the represent- the starting representations of words in our Parser.

1236
01:10:49,075 --> 01:10:53,145
But well, if we're interested in distributed representations,

1237
01:10:53,145 --> 01:10:58,550
it seem to us like maybe you should only have distributed representations of words.

1238
01:10:58,550 --> 01:11:03,260
Um, maybe it also be good temp distributed representations of other things.

1239
01:11:03,260 --> 01:11:05,440
So we had parts of speech like,

1240
01:11:05,440 --> 01:11:08,085
you know, nouns and verbs and adjectives and so on.

1241
01:11:08,085 --> 01:11:13,230
Well some of those parts of speech have more to do with each other than others.

1242
01:11:13,230 --> 01:11:15,310
I mean, [NOISE] in particular, um,

1243
01:11:15,310 --> 01:11:20,320
most NLP work uses fine-grained parts of speech.

1244
01:11:20,320 --> 01:11:23,620
So you don't only have a part of speech like noun or verb,

1245
01:11:23,620 --> 01:11:26,890
you have parts of speech like singular noun versus

1246
01:11:26,890 --> 01:11:31,650
plural noun and you have different parts of speech for, you know,

1247
01:11:31,650 --> 01:11:36,070
work, works, working, kind of the different forms of

1248
01:11:36,070 --> 01:11:41,170
verbs are given different parts of speech, um, as well.

1249
01:11:41,170 --> 01:11:45,355
So there's sort of sets of parts of speech labels that kind of clusters.

1250
01:11:45,355 --> 01:11:47,940
So maybe we could have distributed representations,

1251
01:11:47,940 --> 01:11:50,955
a part of speech that represent their similarity.

1252
01:11:50,955 --> 01:11:53,670
Why not? Um, well if we're gonna do that,

1253
01:11:53,670 --> 01:11:57,140
why not just keep on going and say the dependency labels.

1254
01:11:57,140 --> 01:12:00,875
They also, um, have a distributed representation.

1255
01:12:00,875 --> 01:12:04,405
And so, we built a representation that did that.

1256
01:12:04,405 --> 01:12:10,290
So the idea is that we have in our stack,

1257
01:12:10,290 --> 01:12:13,185
the sort of the top positions of the stack,

1258
01:12:13,185 --> 01:12:17,695
the first positions of the buffer and for each of those positions,

1259
01:12:17,695 --> 01:12:23,275
we have a word and a part of speech and if we've already built structure as here,

1260
01:12:23,275 --> 01:12:27,525
we kind of know about a dependency that's already been built.

1261
01:12:27,525 --> 01:12:31,790
And so we've got a triple for each position and we're gonna convert

1262
01:12:31,790 --> 01:12:36,295
all of those into a distributed representation,

1263
01:12:36,295 --> 01:12:41,960
um, which we are learning and we're gonna use those distributed representations,

1264
01:12:41,960 --> 01:12:45,065
um, to build our parser.

1265
01:12:45,065 --> 01:12:47,750
Okay. Now for- so,

1266
01:12:47,750 --> 01:12:52,440
you know starting from- starting from the next lecture forward,

1267
01:12:52,440 --> 01:12:58,835
we're gonna sort of s- start using a more complex forms of neural models.

1268
01:12:58,835 --> 01:13:01,250
But for this model, um,

1269
01:13:01,250 --> 01:13:05,780
we did it in a sort of a very simple straightforward way.

1270
01:13:05,780 --> 01:13:10,960
We said, well, we could just use exactly the same model,

1271
01:13:10,960 --> 01:13:15,160
exactly the same parser structure that Nivre used, right?

1272
01:13:15,160 --> 01:13:18,620
Doing those shifts and left arcs and right arcs.

1273
01:13:18,620 --> 01:13:21,010
Um, the only part we're gonna turn into

1274
01:13:21,010 --> 01:13:25,590
a neural network is we're gonna have the decision of what to do next,

1275
01:13:25,590 --> 01:13:28,815
um, being controlled by our neural network.

1276
01:13:28,815 --> 01:13:31,070
So our neural network is

1277
01:13:31,070 --> 01:13:37,040
just a very simple classifier of the kind that we are talking about last week.

1278
01:13:37,040 --> 01:13:39,665
So based on the configuration,

1279
01:13:39,665 --> 01:13:44,400
we create an input layer which means we're sort

1280
01:13:44,400 --> 01:13:49,140
of taking the stuff in these boxers and turn- and looking up

1281
01:13:49,140 --> 01:13:54,580
a vector representation for each one and concatenating them together to produce

1282
01:13:54,580 --> 01:13:59,050
a input representation that's sort of similar to when we were making

1283
01:13:59,050 --> 01:14:03,935
those window classifiers and then we can concatenate a bunch of stuff together.

1284
01:14:03,935 --> 01:14:06,040
So that gives us in our input layer.

1285
01:14:06,040 --> 01:14:08,490
[NOISE] Um, so from there,

1286
01:14:08,490 --> 01:14:12,200
we put things through a hidden layer just like last week.

1287
01:14:12,200 --> 01:14:18,130
We do Wx plus b and then put it through a ReLU or a non-linearity to a hidden layer.

1288
01:14:18,130 --> 01:14:19,910
And then on top of that,

1289
01:14:19,910 --> 01:14:23,605
we're simply gonna stick a softmax output layer.

1290
01:14:23,605 --> 01:14:25,820
So multiplying by another matrix,

1291
01:14:25,820 --> 01:14:28,905
adding another, um, bias term,

1292
01:14:28,905 --> 01:14:32,000
and then that goes into the softmax which is gonna give

1293
01:14:32,000 --> 01:14:37,780
a probability over our actions as to whether it's shift left arc or right arc,

1294
01:14:37,780 --> 01:14:40,055
or the corresponding one with labels.

1295
01:14:40,055 --> 01:14:45,800
And then we're gonna use the same kind of cross entropy loss to say how good a job did we

1296
01:14:45,800 --> 01:14:48,440
do at guessing the action that we should have

1297
01:14:48,440 --> 01:14:52,050
taken according to the tree bank parse of the sentence.

1298
01:14:52,050 --> 01:14:56,490
And so each step of the shift-reduce parser,

1299
01:14:56,490 --> 01:15:01,120
we're making a decision as what to do next and we're doing it by this classifier

1300
01:15:01,120 --> 01:15:03,120
and we're getting a loss to

1301
01:15:03,120 --> 01:15:06,815
the extent that we don't give probability one to the right action.

1302
01:15:06,815 --> 01:15:11,380
Um, and so that's what we did using the tree bank.

1303
01:15:11,380 --> 01:15:14,145
We trained up our parser, um,

1304
01:15:14,145 --> 01:15:19,825
and it was then able to predict the sentences.

1305
01:15:19,825 --> 01:15:23,680
And the cool thing- the cool thing was,

1306
01:15:23,680 --> 01:15:26,410
um, that this, um,

1307
01:15:26,410 --> 01:15:30,160
had all the good things of Nivre's parser but, you know,

1308
01:15:30,160 --> 01:15:33,890
by having it use these dense representations,

1309
01:15:33,890 --> 01:15:36,280
it meant that we could get greater accuracy and

1310
01:15:36,280 --> 01:15:39,845
speed than Nivre's parser at the same time.

1311
01:15:39,845 --> 01:15:43,270
So here is sort of some results on that.

1312
01:15:43,270 --> 01:15:46,230
I mean, I already showed you some earlier results, right?

1313
01:15:46,230 --> 01:15:49,215
So this was showing, um, the fact, um,

1314
01:15:49,215 --> 01:15:53,310
that, you know, we're outperforming these earlier parsers basically.

1315
01:15:53,310 --> 01:15:56,445
But subsequent to us doing this work,

1316
01:15:56,445 --> 01:15:58,880
um, people at Google,

1317
01:15:58,880 --> 01:16:03,050
um, these papers here by Weiss and Andor,

1318
01:16:03,050 --> 01:16:05,625
um, they said, "Well, this is pretty cool.

1319
01:16:05,625 --> 01:16:11,460
Um, maybe we can get the numbers even better if we make our neural network,

1320
01:16:11,460 --> 01:16:17,705
um, bigger and deeper and we spend a lot more time tuning our hyper-parameters."

1321
01:16:17,705 --> 01:16:19,690
Um, sad but true.

1322
01:16:19,690 --> 01:16:21,900
All of these things help when you're building

1323
01:16:21,900 --> 01:16:25,015
neural networks and when you're doing your final project.

1324
01:16:25,015 --> 01:16:29,185
Sometimes the answer to making the results better is to make it bigger,

1325
01:16:29,185 --> 01:16:32,795
deeper and spend more time choosing the hyper-parameters.

1326
01:16:32,795 --> 01:16:36,205
Um, they put in Beam search as I sort of mentioned.

1327
01:16:36,205 --> 01:16:37,950
Um, Beam search can really help.

1328
01:16:37,950 --> 01:16:39,490
So in Beam search,

1329
01:16:39,490 --> 01:16:42,320
you know, rather than just saying,

1330
01:16:42,320 --> 01:16:44,850
"Let's work out what's the best next action,

1331
01:16:44,850 --> 01:16:46,530
do that one and repeat over",

1332
01:16:46,530 --> 01:16:49,300
you allow yourself to do a little bit of search.

1333
01:16:49,300 --> 01:16:53,520
You sort of say, "Well, let's consider two actions and explore what happens."

1334
01:16:53,520 --> 01:16:55,780
Um, quick question.

1335
01:16:55,780 --> 01:17:00,480
Do humans always agree on how to build this trees and if they don't,

1336
01:17:00,480 --> 01:17:05,525
what will be the [inaudible] or agreement of humans relative to [inaudible] [OVERLAPPING] [NOISE]

1337
01:17:05,525 --> 01:17:08,685
So that's a good question which I haven't addressed.

1338
01:17:08,685 --> 01:17:11,485
Um, humans don't always agree.

1339
01:17:11,485 --> 01:17:15,010
There are sort of two reasons they can't agree fundamentally.

1340
01:17:15,010 --> 01:17:16,980
One is that, uh, humans,

1341
01:17:16,980 --> 01:17:18,480
um, sort of mess up, right?

1342
01:17:18,480 --> 01:17:20,950
Because human work is doing this aren't perfect.

1343
01:17:20,950 --> 01:17:25,360
And the other one is they generally think that there should be different structures.

1344
01:17:25,360 --> 01:17:27,030
Um, so, you know,

1345
01:17:27,030 --> 01:17:30,455
it depend- varies depending on the circumstances and so on.

1346
01:17:30,455 --> 01:17:33,840
If you just get humans to parse sentences and say,

1347
01:17:33,840 --> 01:17:37,220
"Well, what is the agreement and what they produced?"

1348
01:17:37,220 --> 01:17:41,055
You know, maybe you're only getting something like 92 percent.

1349
01:17:41,055 --> 01:17:45,465
But, you know, if you then do an adjudication phase and you say, "Um,

1350
01:17:45,465 --> 01:17:47,955
look at these differences,

1351
01:17:47,955 --> 01:17:50,340
um, is one of them right or wrong?"

1352
01:17:50,340 --> 01:17:52,050
There are a lot of them where, you know,

1353
01:17:52,050 --> 01:17:53,830
one of the person is effectively saying,

1354
01:17:53,830 --> 01:17:55,000
"Oh yeah, I goofed.

1355
01:17:55,000 --> 01:17:57,570
Um, wasn't paying attention or whatever."

1356
01:17:57,570 --> 01:17:58,950
Um, and so then,

1357
01:17:58,950 --> 01:18:01,450
what's the residual rate in which,

1358
01:18:01,450 --> 01:18:05,350
um, people can actually disagree about possible parses?

1359
01:18:05,350 --> 01:18:07,760
I think that's sort of more around three percent.

1360
01:18:07,760 --> 01:18:09,400
Um, yeah.

1361
01:18:09,400 --> 01:18:11,790
But there certainly are cases and that includes

1362
01:18:11,790 --> 01:18:14,685
some of the prepositional phrase attachment ambiguities.

1363
01:18:14,685 --> 01:18:17,510
Sometimes there are multiple attachments

1364
01:18:17,510 --> 01:18:19,290
that sort of same clause although it's not really

1365
01:18:19,290 --> 01:18:21,600
clear which one is right even though there are lots of

1366
01:18:21,600 --> 01:18:24,710
other circumstances where one of them is very clearly wrong.

1367
01:18:24,710 --> 01:18:27,120
Um, yeah.

1368
01:18:27,120 --> 01:18:28,280
[inaudible].

1369
01:18:28,950 --> 01:18:32,210
There's- there's still room to do better.

1370
01:18:32,210 --> 01:18:34,400
I mean, at the unlabeled attachment score,

1371
01:18:34,400 --> 01:18:35,960
it's actually starting to get pretty good.

1372
01:18:35,960 --> 01:18:38,570
But there's still room to do better. Um, yeah.

1373
01:18:38,570 --> 01:18:40,460
Um, yeah.

1374
01:18:40,460 --> 01:18:41,910
So Beam search,

1375
01:18:41,910 --> 01:18:45,110
the final thing that they did was- that we're not gonna talk about here,

1376
01:18:45,110 --> 01:18:49,480
is the sort of more global inference to make sure, um, it's sensible.

1377
01:18:49,480 --> 01:18:51,610
Um, and so, um,

1378
01:18:51,610 --> 01:18:56,250
that then led to Google developing these models that they gave silly names to,

1379
01:18:56,250 --> 01:18:59,095
especially the Parsey McPa- parseFace,

1380
01:18:59,095 --> 01:19:01,355
um, model of parsing.

1381
01:19:01,355 --> 01:19:03,385
Um, and so, yeah.

1382
01:19:03,385 --> 01:19:08,395
So that then- that's sort of pushed up the numbers even further so that they were sort of

1383
01:19:08,395 --> 01:19:13,775
getting close to 95 percent unlabeled accuracy score from these models.

1384
01:19:13,775 --> 01:19:15,905
And actually, this work has kind of,

1385
01:19:15,905 --> 01:19:19,485
you know, deep learning people like to optimize.

1386
01:19:19,485 --> 01:19:21,730
Um, this work [LAUGHTER] has continued along

1387
01:19:21,730 --> 01:19:24,345
in the intervening two years and the numbers are sort of getting,

1388
01:19:24,345 --> 01:19:26,310
um, a bit higher again.

1389
01:19:26,310 --> 01:19:29,345
But, you know, so this actually, um,

1390
01:19:29,345 --> 01:19:37,440
led to ah sort of a new era of sort of better parsers because so effectively this was the

1391
01:19:37,440 --> 01:19:42,350
90's- the 90's era of parsers that was sort of where

1392
01:19:42,350 --> 01:19:48,320
around 90 percent and then going into this sort of new generation of,

1393
01:19:48,320 --> 01:19:51,580
um, neural transition based dependency parsers.

1394
01:19:51,580 --> 01:19:55,260
We sort of have gone down that we've halve that error- error rate.

1395
01:19:55,260 --> 01:19:59,120
And we're now down to sort of about a five percent error rate.

1396
01:19:59,120 --> 01:20:01,430
Yeah. I'm basically out of time now but, you know,

1397
01:20:01,430 --> 01:20:04,080
there is further work including, you know, at Stanford.

1398
01:20:04,080 --> 01:20:07,660
Um, another student, Tim Dossad has some sort of more recent work.

1399
01:20:07,660 --> 01:20:09,590
It's more accurate than 95 percent, right?

1400
01:20:09,590 --> 01:20:13,180
So we- we're still going on but I think I'd better stop here today,

1401
01:20:13,180 --> 01:20:16,310
um, and that's neural dependency parsing. [NOISE].

