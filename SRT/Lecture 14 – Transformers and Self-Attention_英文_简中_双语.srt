1
00:00:04,520 --> 00:00:08,670
Okay. So I'm delighted to introduce,
好的。所以我很高兴地介绍，

2
00:00:08,670 --> 00:00:11,355
um, our first lot of invited speakers.
嗯，我们的第一批受邀演讲者。

3
00:00:11,355 --> 00:00:14,460
And so we're gonna have two invited speakers, um, today.
所以我们今天要邀请两位发言者，嗯。

4
00:00:14,460 --> 00:00:16,260
So starting off, um,
首先，嗯，

5
00:00:16,260 --> 00:00:18,960
we go and have Ashish Vaswani who's gonna be
我们去和Ashish Vaswani一起去

6
00:00:18,960 --> 00:00:23,115
talking about self attention for generative models and in particular,
谈论生成模型的自我关注，特别是

7
00:00:23,115 --> 00:00:25,530
um, we'll introduce some of the work on
嗯，我们将介绍一些工作

8
00:00:25,530 --> 00:00:29,190
transformers that he is well-known for along with his colleagues.
变形金刚，他和他的同事一起出名。

9
00:00:29,190 --> 00:00:32,220
Um and then as a sort of, um,
嗯，然后作为一种，嗯，

10
00:00:32,220 --> 00:00:35,235
a special edition then we're also going to have
特别版然后我们也将有

11
00:00:35,235 --> 00:00:39,440
Anna Huang talking about some applications of this work.
Anna Huang谈到了这项工作的一些应用。

12
00:00:39,440 --> 00:00:41,540
There are actually at least a couple of people in the class who are
实际上班上至少有几个人

13
00:00:41,540 --> 00:00:43,790
actually interested in music applications.
实际上对音乐应用感兴趣。

14
00:00:43,790 --> 00:00:48,740
So this will be your one chance in the course to see music applications of deep learning.
因此，这将是您在课程中看到深度学习的音乐应用的一次机会。

15
00:00:48,740 --> 00:00:51,890
Okay, um, so I'll hand it over to Ashish.
好的，嗯，所以我会把它交给Ashish。

16
00:00:51,890 --> 00:00:53,360
Thanks, Chris and, uh, thanks, Evie.
谢谢，克里斯，呃，谢谢，伊维。

17
00:00:53,360 --> 00:00:55,940
Uh, Anna is actually here to make the class less dull.
呃，安娜实际上是为了让课堂变得不那么沉闷。

18
00:00:55,940 --> 00:00:57,830
So [LAUGHTER] she's the highlight on this one.
所以[笑声]她是这一个的亮点。

19
00:00:57,830 --> 00:01:00,845
So uh, so, uh, hi everyone.
所以，呃，大家好。

20
00:01:00,845 --> 00:01:03,395
Um, um, uh excited to be here.
嗯，嗯，很高兴能来到这里。

21
00:01:03,395 --> 00:01:06,205
This is a very large class.
这是一个非常大的课程。

22
00:01:06,205 --> 00:01:07,920
Uh, first invited speaker,
呃，首先邀请了演讲者，

23
00:01:07,920 --> 00:01:09,920
no pressure, so hopefully this will all go well.
没有压力，所以希望这一切都会顺利进行。

24
00:01:09,920 --> 00:01:14,975
Uh, so yes, so the talk is going to be about, uh, self attention.
呃，是的，所以谈论将是关于，呃，自我关注。

25
00:01:14,975 --> 00:01:18,345
Um, and so the purpose is,
嗯，所以目的是，

26
00:01:18,345 --> 00:01:22,685
is not going to be just to talk about a particular model, but, as,
不仅仅是谈论一个特定的模型，但是，作为，

27
00:01:22,685 --> 00:01:25,850
as, as, as empiricists and, and,
就像经验主义者一样，和

28
00:01:25,850 --> 00:01:27,830
like, well, I'm an empiricist and I
就像，嗯，我是一名经验主义者和我

29
00:01:27,830 --> 00:01:30,380
consume machine learning to apply it to various tasks.
消耗机器学习将其应用于各种任务。

30
00:01:30,380 --> 00:01:35,210
And, and, and, well, starting point always is to ask this question, you know,
而且，而且，好吧，起点总是提出这个问题，你知道，

31
00:01:35,210 --> 00:01:36,800
what are the- what's the structure in
什么是 - 结构是什么

32
00:01:36,800 --> 00:01:38,720
my dataset or what are the symmetries in my dataset,
我的数据集或我的数据集中的对称性是什么，

33
00:01:38,720 --> 00:01:41,880
and is there a model that exists that that's a very good- that,
是否存在一个非常好的模型 -

34
00:01:41,880 --> 00:01:46,010
that has the inductive biases to model these properties that exist in my dataset.
具有归纳偏差来模拟我的数据集中存在的这些属性。

35
00:01:46,010 --> 00:01:48,455
So hopefully, over the course of this, uh,
所以希望，在这个过程中，呃，

36
00:01:48,455 --> 00:01:51,680
this, this lecture Anna and I will convince you that, uh,
这个，安娜和我这个讲座会说服你，呃，

37
00:01:51,680 --> 00:01:54,410
self attention indeed does have some- has
自我注意确实有一些

38
00:01:54,410 --> 00:01:56,165
the ability models and inductive biases that
能力模型和归纳偏见

39
00:01:56,165 --> 00:01:58,685
potentially could be useful for the problems that you care about.
可能对您关心的问题有用。

40
00:01:58,685 --> 00:02:04,790
Um, so, um, this talk is going to be our learning representations primarily of,
嗯，所以，嗯，这次演讲将主要是我们的学习陈述，

41
00:02:04,790 --> 00:02:07,445
uh, variable length data where we have images but,
呃，我们有图像的可变长度数据，但是，

42
00:02:07,445 --> 00:02:10,190
uh, most of it is going to be variable length data.
呃，大部分都是可变长度的数据。

43
00:02:10,190 --> 00:02:11,960
And, uh, and, and,
而且，呃，和，和，

44
00:02:11,960 --> 00:02:14,975
and all of us care about this problem because we- in
我们所有人都关心这个问题，因为我们在

45
00:02:14,975 --> 00:02:17,990
deep learning, and deep learning is all about representation learning.
深度学习，深度学习就是表征学习。

46
00:02:17,990 --> 00:02:22,655
And if- and building the right tools for learning representations as,
如果 - 并建立正确的学习表示工具，

47
00:02:22,655 --> 00:02:24,830
as, as, as sort of- is an important factor in,
因为，作为一种重要因素，

48
00:02:24,830 --> 00:02:26,600
in achieving empirical success.
实现经验成功。

49
00:02:26,600 --> 00:02:29,810
Um, now, uh, the models of choice,
嗯，现在，呃，选择的模型，

50
00:02:29,810 --> 00:02:32,165
the primary workhorse for
主要的主力

51
00:02:32,165 --> 00:02:35,600
perhaps even now and or up to this point had been recurrent neural networks.
或许甚至现在和/或到目前为止都是反复出现的神经网络。

52
00:02:35,600 --> 00:02:40,730
Um, um, how, how many people here are familiar with RNNs?
嗯，嗯，怎么样，这里有多少人熟悉RNN？

53
00:02:40,730 --> 00:02:43,055
[LAUGHTER] Okay.
[大笑]好的。

54
00:02:43,055 --> 00:02:45,260
So definitely up to this point,
所以到目前为止，

55
00:02:45,260 --> 00:02:47,690
the primary workhorse have been recurrent neural networks,
主要的主力是反复神经网络，

56
00:02:47,690 --> 00:02:50,465
and some of the more, uh, some, uh,
还有一些，呃，一些，呃，

57
00:02:50,465 --> 00:02:54,540
some gated variants that explicitly add multiplicative interactions like LSTMs,
一些门控变体，明确添加乘法交互，如LSTMs，

58
00:02:54,540 --> 00:02:58,175
they also, they also have mechanisms that allow for better gradient transfer.
他们还有一些机制可以实现更好的梯度转移。

59
00:02:58,175 --> 00:03:00,620
And some recent variants like gated, uh,
最近的一些变种，如门控，呃，

60
00:03:00,620 --> 00:03:02,300
recurrent units that are simplification,
简化的经常性单位，

61
00:03:02,300 --> 00:03:06,860
they're kind of the- they're- they dominate this, this recurrent landscape.
他们是那种 - 他们 - 他们在这个经常性的景观中占主导地位。

62
00:03:06,860 --> 00:03:09,605
Um, and typically how did recurrent neural networks, uh,
嗯，通常神经网络怎么回事，呃，

63
00:03:09,605 --> 00:03:12,675
learn or, um, produce representations?
学习或者，嗯，制作陈述？

64
00:03:12,675 --> 00:03:15,765
They consume a string or a sentence, um,
他们消耗一串或一句话，嗯，

65
00:03:15,765 --> 00:03:17,625
even an image, imagine, you know,
即使是图像，想象一下，你知道，

66
00:03:17,625 --> 00:03:21,135
in a particular- in sequentially and, uh, at each,
在一个特定的顺序和呃，每个，

67
00:03:21,135 --> 00:03:22,530
at each, uh, position,
在每个，呃，位置，

68
00:03:22,530 --> 00:03:24,900
at each timestep they produce, they produce a,
在他们生产的每个时间步，他们生产，

69
00:03:24,900 --> 00:03:26,899
a continuous representation that's
一个连续的表示

70
00:03:26,899 --> 00:03:30,845
summarization of, of everything that they've actually crunched through.
他们实际上已经完成的所有事情的总结。

71
00:03:30,845 --> 00:03:36,960
Um, now, so in, in, in the,
嗯，现在，所以，在，在，

72
00:03:36,960 --> 00:03:39,480
in the realm of large data, uh,
在大数据领域，呃，

73
00:03:39,480 --> 00:03:41,310
par- having parallel models is,
平行模型是，

74
00:03:41,310 --> 00:03:42,890
is quite, is quite beneficial.
非常，非常有益。

75
00:03:42,890 --> 00:03:45,140
In fact, I was actually reading Oliver Selfridge.
事实上，我实际上正在读奥利弗塞尔弗里奇。

76
00:03:45,140 --> 00:03:46,370
Uh, he was a,
呃，他是，

77
00:03:46,370 --> 00:03:48,770
he was a professor at MIT and, uh, he had this,
他是麻省理工学院的教授，呃，他有这个，

78
00:03:48,770 --> 00:03:53,360
uh, sorry, he wrote the precursor to deep nets its it's called Pandemoniums.
呃，对不起，他写了深网的前兆，它叫做Pandemoniums。

79
00:03:53,360 --> 00:03:54,590
I would recommend everybody to read it.
我建议大家阅读。

80
00:03:54,590 --> 00:03:56,450
And he has this fascinating note that, you know,
他有这个引人入胜的说明，你知道，

81
00:03:56,450 --> 00:03:57,960
if you give me more parallel computation,
如果你给我更多的并行计算，

82
00:03:57,960 --> 00:03:59,900
I'll just add more data and make it slower.
我只会添加更多数据并使其变慢。

83
00:03:59,900 --> 00:04:02,180
So you can consume more data.
所以你可以消耗更多的数据。

84
00:04:02,180 --> 00:04:07,260
Um, and, and recurrence, uh, recurrence sort of just by construction, um,
嗯，又复发，呃，复发只是建筑，嗯，

85
00:04:07,260 --> 00:04:08,915
limits parallelization because you have to,
限制并行化，因为你必须，

86
00:04:08,915 --> 00:04:11,105
you have to wait until- your wait un-
你必须等到 - 等你没有 -

87
00:04:11,105 --> 00:04:14,030
for a particular time point to produce a representation.
在特定时间点产生表示。

88
00:04:14,030 --> 00:04:16,275
Um, but if there's any questions,
嗯，但如果有任何问题，

89
00:04:16,275 --> 00:04:17,325
please raise your hands, I'll
请举手，我会

90
00:04:17,325 --> 00:04:18,900
hopefully look around and, and,
希望环顾四周，并且，

91
00:04:18,900 --> 00:04:21,230
uh, be able to attend to your question.
呃，能够处理你的问题。

92
00:04:21,230 --> 00:04:24,920
Um, and again, and, and now because we're actually producing these representations,
嗯，又一次，而且，现在因为我们实际上正在制作这些表示，

93
00:04:24,920 --> 00:04:26,150
we're sort of summarizing,
我们总结一下，

94
00:04:26,150 --> 00:04:27,740
you know, if you want to pass information,
你知道，如果你想传递信息，

95
00:04:27,740 --> 00:04:29,765
if you want to pass co-reference information,
如果你想传递共同参考信息，

96
00:04:29,765 --> 00:04:32,350
then we kind of have to shove all of this inside
那么我们就必须把所有这些都推到里面

97
00:04:32,350 --> 00:04:36,110
this fixed size vector, so it could potentially be difficult to model.
这个固定大小的矢量，因此可能很难建模。

98
00:04:36,110 --> 00:04:39,635
And, uh, while they have been successful in language, uh,
而且，呃，虽然他们在语言上取得了成功，呃，

99
00:04:39,635 --> 00:04:42,530
explicit they don't have- the architecture
明确他们没有 - 建筑

100
00:04:42,530 --> 00:04:45,890
doesn't have a very clear explicit way to model hierarchy which is,
没有非常明确的模型层次结构的明确方式，

101
00:04:45,890 --> 00:04:48,155
which is something that's very important in language.
这在语言中非常重要。

102
00:04:48,155 --> 00:04:54,390
Um, now, um, so they have been devin- it has been excellent work of,
嗯，现在，嗯，所以他们一直在开发 - 这是一项出色的工作，

103
00:04:54,390 --> 00:04:58,640
a precursor to self attention that actually surmounted some of these difficulties.
实际上克服了其中一些困难的自我关注的先兆。

104
00:04:58,640 --> 00:05:01,550
And what were these difficulties basically is a convolutional sequence models
这些困难主要是卷积序列模型

105
00:05:01,550 --> 00:05:05,180
where you have these limited receptive field convolutions that,
在那里你有这些有限的接受场卷积，

106
00:05:05,180 --> 00:05:07,220
again, consumed the sentence now not,
再次，现在没有消耗这句话，

107
00:05:07,220 --> 00:05:09,590
not sequentially but in depth.
不是顺序而是深入。

108
00:05:09,590 --> 00:05:12,130
And they produce representations for every-
他们为每个人制作陈述 -

109
00:05:12,130 --> 00:05:14,720
they produce representations of your variable length sequences.
它们产生可变长度序列的表示。

110
00:05:14,720 --> 00:05:17,720
Um, and, uh, they're trivial to
嗯，呃，他们很琐碎

111
00:05:17,720 --> 00:05:21,110
parallelize because you can apply these convolutions simultaneously at every position.
并行化，因为您可以在每个位置同时应用这些卷积。

112
00:05:21,110 --> 00:05:23,030
Each layer is trivial to parallelize.
每层都很容易并行化。

113
00:05:23,030 --> 00:05:26,165
Uh, the, the, the serial dependencies are only in the number of layers.
呃，系列依赖关系仅在层数上。

114
00:05:26,165 --> 00:05:28,235
Um, you can get, uh,
嗯，你可以得到，呃，

115
00:05:28,235 --> 00:05:29,960
you can- you can get
你可以 - 你可以得到

116
00:05:29,960 --> 00:05:32,750
these local dependencies efficiently because that a single application of
这些本地依赖有效，因为单个应用程序

117
00:05:32,750 --> 00:05:37,475
a convolution can consume all the information inside its local receptive field.
卷积可以消耗其本地感受域内的所有信息。

118
00:05:37,475 --> 00:05:39,320
Um, now if you want to have
嗯，现在如果你想拥有

119
00:05:39,320 --> 00:05:42,170
these really long distance interactions while you
这些真正的长距离互动，而你

120
00:05:42,170 --> 00:05:45,020
don't have to pass through a linear number of steps,
不必通过线性数量的步骤，

121
00:05:45,020 --> 00:05:46,060
you still because these,
你还是因为这些，

122
00:05:46,060 --> 00:05:49,670
because these receptive fields are local you might need something like linear
因为这些感受野是本地的，你可能需要线性的东西

123
00:05:49,670 --> 00:05:53,525
and depth or logarithmic if you're doing something like dilated convolutions.
如果你正在做扩张卷积之类的东西，那就是深度或对数。

124
00:05:53,525 --> 00:05:56,030
So there's still need- the number of layers that are needed are
所以仍然需要 - 所需的层数

125
00:05:56,030 --> 00:05:59,215
still a function of the length of the of, of your string.
仍然是你的字符串的长度的函数。

126
00:05:59,215 --> 00:06:01,070
Uh, but they're a great development and they
呃，但他们是一个伟大的发展和他们

127
00:06:01,070 --> 00:06:03,320
actually pushed a lot of research like WaveRNN, for example,
实际上推动了很多像WaveRNN这样的研究，例如，

128
00:06:03,320 --> 00:06:05,225
is a classic sort of success story of
是一个经典的成功故事

129
00:06:05,225 --> 00:06:08,825
convolutio- convolutional sequence models even by net.
卷积 - 卷积序列模型甚至网络。

130
00:06:08,825 --> 00:06:15,085
Um, now, so far attention has been like one of the most important components,
嗯，现在，到目前为止，注意力一直是最重要的组成部分之一，

131
00:06:15,085 --> 00:06:16,810
the sort of content-based,
基于内容的那种，

132
00:06:16,810 --> 00:06:19,060
you know, memory retrieval mechanism.
你知道，记忆检索机制。

133
00:06:19,060 --> 00:06:23,560
And it's content-based because you have your decoder that attends to all this content,
它是基于内容的，因为你的解码器可以满足所有这些内容，

134
00:06:23,560 --> 00:06:26,625
that's your encoder and then just sort of decides what to wha- what,
这是你的编码器然后只是决定什么，什么，

135
00:06:26,625 --> 00:06:28,580
what information to absorb based on how similar
根据相似程度吸收哪些信息

136
00:06:28,580 --> 00:06:30,980
this content is to every position in the memory.
这个内容是记忆中的每个位置。

137
00:06:30,980 --> 00:06:33,440
So this has been a very critical mechanism in,
所以这是一个非常关键的机制，

138
00:06:33,440 --> 00:06:34,955
uh, in neural machine translation.
呃，在神经机器翻译中。

139
00:06:34,955 --> 00:06:36,950
So now the question that we asked was, like, why,
所以现在我们问的问题是，为什么，

140
00:06:36,950 --> 00:06:40,460
why not just use attention for representations and, uh,
为什么不把注意力用于表达，呃，

141
00:06:40,460 --> 00:06:43,790
now here's what sort of a rough framework of this,
现在这是一个粗略的框架，

142
00:06:43,790 --> 00:06:46,445
this representation mechanism would look like, uh,
这种表示机制看起来像，呃，

143
00:06:46,445 --> 00:06:49,635
the way- just sort of repeating what attention is essentially.
方式 - 只是重复注意力本质上。

144
00:06:49,635 --> 00:06:52,360
Now imagine you have- you want to represent the word,
现在想象你有 - 你想代表这个词，

145
00:06:52,360 --> 00:06:55,730
re-represent the word representing, you want to construct its new representation.
重新表示单词表示，你想构建它的新表示。

146
00:06:55,730 --> 00:06:58,610
And then first, uh, you, you attend or you,
然后首先，呃，你，你参加或者你，

147
00:06:58,610 --> 00:07:00,710
you compare yourself, you compare your content,
你比较自己，比较你的内容，

148
00:07:00,710 --> 00:07:02,765
and in the beginning it could just be a word embedding.
而在一开始它可能只是一个嵌入的单词。

149
00:07:02,765 --> 00:07:05,540
Your compare content with all your words, and with all,
您与所有单词以及所有单词的比较内容，

150
00:07:05,540 --> 00:07:07,340
with all the embeddings and based on these,
所有的嵌入和基于这些，

151
00:07:07,340 --> 00:07:09,905
based on these compatibilities or these comparisons,
基于这些兼容性或这些比较，

152
00:07:09,905 --> 00:07:14,180
you produce, uh, you produce a weighted combination of your entire neighborhood,
你生产，呃，你产生了整个社区的加权组合，

153
00:07:14,180 --> 00:07:16,180
and based on that weighted combination you,
并根据加权组合你，

154
00:07:16,180 --> 00:07:17,870
you summarize all that information.
你总结了所有这些信息。

155
00:07:17,870 --> 00:07:20,150
So it's, like, you're re-expressing yourself in certain terms
所以，就像你在某些方面重新表达自己一样

156
00:07:20,150 --> 00:07:22,730
of a weighted combination of your entire neighborhood.
整个社区的加权组合。

157
00:07:22,730 --> 00:07:23,930
That's what attention does,
这就是注意力，

158
00:07:23,930 --> 00:07:28,955
and you can add feed-forward layers to basically sort of compute new features for you.
并且您可以添加前馈层，以便为您计算新功能。

159
00:07:28,955 --> 00:07:34,700
Um, now, um so the first part is going to be about how, like,
嗯，现在，嗯，所以第一部分将是关于如何，如，

160
00:07:34,700 --> 00:07:37,760
some of the properties of self attention actually help us in text generation, like,
自我关注的一些属性实际上帮助我们生成文本，比如

161
00:07:37,760 --> 00:07:39,320
what inductive biases are actually useful,
什么归纳偏差实际上有用，

162
00:07:39,320 --> 00:07:40,950
and we empirically showed that indeed they,
我们凭经验表明他们确实

163
00:07:40,950 --> 00:07:43,055
they move the needle in text generation.
他们在文本生成中移动针。

164
00:07:43,055 --> 00:07:44,990
And this is going to be about machine translation,
这将是关于机器翻译，

165
00:07:44,990 --> 00:07:47,420
but there were other work also that we'll talk about later.
但还有其他工作我们稍后会讨论。

166
00:07:47,420 --> 00:07:49,880
So [NOISE] now with this, uh,
所以[NOISE]现在用这个，呃，

167
00:07:49,880 --> 00:07:51,885
with this sort of, uh,
有这种，呃，

168
00:07:51,885 --> 00:07:55,470
with this attention mechanism you get this- we get a constant path length.
通过这种注意机制，你得到了这个 - 我们得到一个恒定的路径长度。

169
00:07:55,470 --> 00:07:58,000
So all pairs or a word can in-
所以所有对或一个词都可以 -

170
00:07:58,000 --> 00:08:01,100
position can interact with any position, every position simultaneously.
位置可以同时与任何位置，每个位置相互作用。

171
00:08:01,100 --> 00:08:04,250
Um, hopefully if the number of positions is not too many.
嗯，希望如果职位数量不是太多。

172
00:08:04,250 --> 00:08:06,410
Uh, attention just by virtue of, like,
呃，注意力就像，就像，

173
00:08:06,410 --> 00:08:08,060
it's a construction, you have a softmax,
它是一种结构，你有一个softmax，

174
00:08:08,060 --> 00:08:10,205
you have these gating and multiplicative interactions.
你有这些门控和乘法互动。

175
00:08:10,205 --> 00:08:12,680
And again, I'm not gonna be able to explain why,
而且，我不能解释为什么，

176
00:08:12,680 --> 00:08:14,195
but it's, it's interesting, like,
但是，它很有趣，就像，

177
00:08:14,195 --> 00:08:15,290
you've seen these models, like,
你见过这些模特，比如

178
00:08:15,290 --> 00:08:16,400
even, even the, uh,
甚至，甚至，呃，

179
00:08:16,400 --> 00:08:19,980
even Pixel, PixelCNN, uh, or, um,
甚至Pixel，PixelCNN，呃，或者，嗯，

180
00:08:19,980 --> 00:08:21,660
when it was actually modeling images,
当它实际建模图像时，

181
00:08:21,660 --> 00:08:24,965
they explicitly had to add these multiplicative interactions inside the model to,
他们明确地必须在模型中添加这些乘法交互，

182
00:08:24,965 --> 00:08:26,885
to basically beat RNNs,
基本上击败了RNN，

183
00:08:26,885 --> 00:08:29,390
and attention just by construction gets this because you're,
建筑的关注得到了这个，因为你，

184
00:08:29,390 --> 00:08:33,035
you're multiplying the attention probabilities with your, with your activations.
你的注意概率与你的激活相乘。

185
00:08:33,035 --> 00:08:34,580
It's trivial to parallelize, why?
并行化很简单，为什么？

186
00:08:34,580 --> 00:08:39,440
Because you can just do attention with matmuls, especially the variant that we use in our paper,
因为你可以用matmuls来关注，特别是我们在论文中使用的变体，

187
00:08:39,440 --> 00:08:40,865
uh, in our work.
呃，在我们的工作中。

188
00:08:40,865 --> 00:08:43,895
And, uh, so now the question is
而且，呃，现在的问题是

189
00:08:43,895 --> 00:08:49,160
convolutional sequence to- convolutional sequence models have been very successful in,
卷积序列到卷积序列模型已经非常成功，

190
00:08:49,160 --> 00:08:52,325
in, in, in ge- generative tasks for text.
在文本的生成任务中。

191
00:08:52,325 --> 00:08:54,830
Can we actually do the same or achieved the same with, uh,
我们可以实际做同样的事情或者实现同样的目标，呃，

192
00:08:54,830 --> 00:08:58,580
with, uh, attention as our primary workhorse for representation learning.
呃，注意力是我们代表学习的主要工具。

193
00:08:58,580 --> 00:09:03,485
Um, so just to sort of add some context and there's been some,
嗯，所以只是为了添加一些上下文而且有一些，

194
00:09:03,485 --> 00:09:07,430
there's been some- up to- up to the transformer there have been a lot of
有一些变压器已经有很多了

195
00:09:07,430 --> 00:09:12,025
great work on using self attention primarily for classification within.
使用自我注意力的主要工作主要是用于分类。

196
00:09:12,025 --> 00:09:15,290
There was, there was work on self attention within the confines of,
有，在范围内有自我关注的工作，

197
00:09:15,290 --> 00:09:16,610
like, recurrent neural networks.
比如，递归神经网络。

198
00:09:16,610 --> 00:09:19,370
Um, perhaps the closest to us is the,
嗯，也许离我们最近的是，

199
00:09:19,370 --> 00:09:20,915
is the memory networks,
是内存网络，

200
00:09:20,915 --> 00:09:22,820
uh, by Weston, Sukhbaatar,
呃，由Weston，Sukhbaatar，

201
00:09:22,820 --> 00:09:25,715
where they actually had a version of recurrent attention,
他们实际上有一个经常关注的版本，

202
00:09:25,715 --> 00:09:27,290
but they didn't have, uh,
但他们没有，呃，

203
00:09:27,290 --> 00:09:30,705
but they didn't actually- empirically,
但他们实际上没有 - 经验，

204
00:09:30,705 --> 00:09:33,500
they didn't show it to work on sort of conditional modeling, like,
他们没有表明它可以用于某种条件建模，比如，

205
00:09:33,500 --> 00:09:37,370
uh, translation and their mechanism was, uh, like,
呃，翻译和他们的机制是，呃，喜欢，

206
00:09:37,370 --> 00:09:41,555
they were using sort of a fixed- they were using a fixed query at every step.
他们使用的是固定的 - 他们在每一步都使用固定的查询。

207
00:09:41,555 --> 00:09:43,495
So there's- it, it leaves something to be desired.
所以，它有一些不足之处。

208
00:09:43,495 --> 00:09:47,060
They still had this question, is it actually going to work, um, on,
他们还有这个问题，它真的会起作用吗，嗯，上，

209
00:09:47,060 --> 00:09:50,870
on, on large scale machine translation systems or large-scale text generation systems.
在大型机器翻译系统或大型文本生成系统上。

210
00:09:50,870 --> 00:09:54,100
So this is sort of the, the culmination of, um,
所以这就是嗯的高潮，嗯，

211
00:09:54,100 --> 00:09:57,435
of the, the self attention, our self attention work.
自我关注，自我关注工作。

212
00:09:57,435 --> 00:10:00,495
This is the tran- the- and we put it together in the transformer model.
这是转换 - 我们将它们放在变压器模型中。

213
00:10:00,495 --> 00:10:03,195
And, uh, so how does this look like?
而且，呃，这看起来怎么样？

214
00:10:03,195 --> 00:10:05,975
So we're going to use attention pri- we're going to use
所以我们将使用注意力 - 我们将要使用

215
00:10:05,975 --> 00:10:09,395
attention primarily for computing representations so- of your input.
主要关注计算表示的输入。

216
00:10:09,395 --> 00:10:11,480
Imagine you're doing English to German translation.
想象一下，你正在做英语到德语的翻译。

217
00:10:11,480 --> 00:10:14,030
So you have your words, and notice that,
所以你有你的话，并注意到，

218
00:10:14,030 --> 00:10:16,610
uh, attention is, uh, permutation invariant.
呃，注意力是，呃，排列不变。

219
00:10:16,610 --> 00:10:19,220
So you just change the order of your positions.
所以你只需改变你的职位顺序。

220
00:10:19,220 --> 00:10:20,910
You change the order of your words and, and,
你改变了你的单词的顺序，和，

221
00:10:20,910 --> 00:10:23,315
uh, it's not going to affect the actual output.
呃，它不会影响实际输出。

222
00:10:23,315 --> 00:10:25,340
So in ord- in order to maintain order we add,
所以在ord-为了维持我们添加的订单，

223
00:10:25,340 --> 00:10:26,985
we add position representations.
我们添加位置表示。

224
00:10:26,985 --> 00:10:29,710
And, uh, there's two kinds that we tried in the paper,
而且，呃，我们在论文中试过两种，

225
00:10:29,710 --> 00:10:33,185
these, these fantastic sinusoids with no entropy invented.
这些，这些奇妙的正弦曲线没有发明熵。

226
00:10:33,185 --> 00:10:35,625
And we also use learned representations which are
我们还使用了学到的表示

227
00:10:35,625 --> 00:10:38,090
very plain vanilla both of them work equally well.
非常普通的香草，它们都同样有效。

228
00:10:38,090 --> 00:10:40,420
Um, and, uh, so,
嗯，呃，所以，

229
00:10:40,420 --> 00:10:42,895
so first we have- so the encoder looks as follows, right?
所以首先我们有 - 所以编码器看起来如下，对吗？

230
00:10:42,895 --> 00:10:46,970
So we have a self attention layer that just recomputes the representation, uh,
所以我们有一个自我关注层，只是重新计算表示，呃，

231
00:10:46,970 --> 00:10:50,090
for every position simultaneously using attention,
对于每个位置同时使用注意力，

232
00:10:50,090 --> 00:10:51,545
then we have a feed-forward layer.
然后我们有一个前馈层。

233
00:10:51,545 --> 00:10:52,820
And we also have residual,
我们也有残余，

234
00:10:52,820 --> 00:10:54,380
residual connections and I'll,
残余连接，我会，

235
00:10:54,380 --> 00:10:56,600
I'll sort of give you a glimpse of what these residual connections
我会给你一些这些残余连接的一瞥

236
00:10:56,600 --> 00:10:59,090
might be bringing that is between every,
可能会带来每一个，

237
00:10:59,090 --> 00:11:02,990
every layer, and the input we have a skip connection that just adds the activations.
每一层，输入我们有一个跳过连接，只是添加激活。

238
00:11:02,990 --> 00:11:05,330
Uh, and then this tuple of, uh,
呃，然后这个元组，呃，

239
00:11:05,330 --> 00:11:08,135
self attention and feed-forward layer just essentially repeats.
自我关注和前馈层基本上重复。

240
00:11:08,135 --> 00:11:10,215
Now, on the decoder side, uh,
现在，在解码器方面，呃，

241
00:11:10,215 --> 00:11:13,925
we've- we, we have a sort of standard encoder decoder architecture.
我们 - 我们有一种标准的编码器解码器架构。

242
00:11:13,925 --> 00:11:17,500
On the decoder side, we mimic a language model using self attention,
在解码器方面，我们使用自我注意来模仿语言模型，

243
00:11:17,500 --> 00:11:20,300
and the way to mimic a language model using self attention is to impose
并且使用自我注意来模仿语言模型的方式是强加

244
00:11:20,300 --> 00:11:23,540
causality by just masking out the positions that you can look at.
通过掩盖你可以看到的位置的因果关系。

245
00:11:23,540 --> 00:11:25,660
So basically, uh,
所以基本上，呃，

246
00:11:25,660 --> 00:11:29,285
the first position it's- it can't look forward, it's illegal to look forward.
第一个位置 - 它不能向前看，向前看是违法的。

247
00:11:29,285 --> 00:11:32,075
It can look at itself because we actually shift the input.
它可以看自己因为我们实际上改变了输入。

248
00:11:32,075 --> 00:11:34,750
Um, so it's not copying, uh.
嗯，所以不是复制，呃。

249
00:11:34,750 --> 00:11:37,240
It's kind of surprising that parti- with these models,
与这些模型分开是令人惊讶的，

250
00:11:37,240 --> 00:11:38,790
it's very easy to copy at one point,
一次复制很容易，

251
00:11:38,790 --> 00:11:41,585
when early on it was even harder to ge- you know,
什么时候开始就更难以了解你，

252
00:11:41,585 --> 00:11:43,355
do copying with recurrent models.
使用循环模型进行复制。

253
00:11:43,355 --> 00:11:44,860
But now, at least, you can copy really well,
但现在，至少，你可以复制得很好，

254
00:11:44,860 --> 00:11:46,850
which is a positive sign, I think overall.
这是一个积极的迹象，我认为总的来说。

255
00:11:46,850 --> 00:11:49,830
Um, but, uh, so now on the decoder side, uh,
嗯，但是，呃，现在在解码器方面，呃，

256
00:11:49,830 --> 00:11:51,150
we have, uh, we have
我们有，呃，我们有

257
00:11:51,150 --> 00:11:54,380
this causal self attention layer followed by encoder-decoder attention,
这个因果自我关注层接着是编码器 - 解码器关注，

258
00:11:54,380 --> 00:11:56,180
where we actually attend to the, uh,
我们实际上在哪里，呃，

259
00:11:56,180 --> 00:11:59,450
last layer of the encoder and a feed-forward layer, and this tripled,
编码器的最后一层和一个前馈层，这个三倍，

260
00:11:59,450 --> 00:12:00,670
repeats a mul- a few times,
重复多次，

261
00:12:00,670 --> 00:12:02,945
and at the end we have the standard cross-entropy loss.
最后我们有标准的交叉熵损失。

262
00:12:02,945 --> 00:12:08,465
Um, and, um, so, um, sort of,
嗯，嗯，所以，嗯，有点像，

263
00:12:08,465 --> 00:12:10,655
staring at the- at,
盯着这里，

264
00:12:10,655 --> 00:12:12,740
at our parti- at the particular variant of the self-
在我们自己的特定变体的自我

265
00:12:12,740 --> 00:12:15,205
of the attention mechanis- mechanism that we use,
我们使用的注意力机制，

266
00:12:15,205 --> 00:12:17,965
we went for both- we went for simplicity and speed.
我们去了两个 - 我们去了简单和速度。

267
00:12:17,965 --> 00:12:21,635
So, um, so how do you actually compute attention?
那么，嗯，你怎么实际计算注意力呢？

268
00:12:21,635 --> 00:12:24,470
So imagine you want to re-represent the position e2.
所以想象你想重新代表e2的位置。

269
00:12:24,470 --> 00:12:26,930
And, uh, we're going to first linearly,
而且，呃，我们首先是线性的，

270
00:12:26,930 --> 00:12:30,220
linearly transform it into, uh, a query,
将其线性转换为呃查询，

271
00:12:30,220 --> 00:12:32,150
and then we're gonna linearly transform
然后我们将线性转换

272
00:12:32,150 --> 00:12:34,520
every position in your neighborhood
您附近的每个位置

273
00:12:34,520 --> 00:12:36,510
or let's say every position at the input because this is the,
或者让我们说输入的每个位置，因为这是，

274
00:12:36,510 --> 00:12:37,805
uh, uh, the encoder side,
呃，编码器方面，

275
00:12:37,805 --> 00:12:39,175
to, uh, a key.
呃，一把钥匙。

276
00:12:39,175 --> 00:12:41,680
And these linear transformations can actually be thought as features,
这些线性变换实际上可以被认为是特征，

277
00:12:41,680 --> 00:12:43,100
and I'll talk more about it later on.
我稍后会谈到它。

278
00:12:43,100 --> 00:12:45,500
So it's like- it's, it's basically a bilinear form.
所以它就像 - 它，它基本上是双线性形式。

279
00:12:45,500 --> 00:12:48,355
You're projecting these vectors into a space where dot product is
您将这些向量投影到点积的空间中

280
00:12:48,355 --> 00:12:51,655
a good- where just a dot product is a good proxy for similarity.
好的 - 只是一个点积是相似性的良好代理。

281
00:12:51,655 --> 00:12:53,200
Okay? So now, you have your logit,
好的？那么现在，你有你的logit，

282
00:12:53,200 --> 00:12:55,810
so you just do a so- softmax computer convex combination.
所以你只需要做一个这样的softmax计算机凸组合。

283
00:12:55,810 --> 00:12:57,930
And now based on this convex combination,
现在基于这个凸组合，

284
00:12:57,930 --> 00:13:01,475
you're going to then re-express e2 or in
你要重新表达e2或者

285
00:13:01,475 --> 00:13:05,380
terms of this convex combination of all the vectors of all these positions.
所有这些位置的所有向量的这种凸组合的术语。

286
00:13:05,380 --> 00:13:08,105
And before doing- before doing the convex combination,
在做之前 - 做凸组合之前，

287
00:13:08,105 --> 00:13:10,505
we again do a linear transformation to produce values.
我们再次进行线性转换以产生价值。

288
00:13:10,505 --> 00:13:13,940
And then we do a second linear transformation just to
然后我们进行第二次线性转换

289
00:13:13,940 --> 00:13:17,620
mix this information and pass it through a- pass it through a feedforward layer.
混合这些信息并传递给它 - 通过前馈层。

290
00:13:17,620 --> 00:13:19,075
And this is- um,
这就是，

291
00:13:19,075 --> 00:13:21,915
and all of this can be expressed basically
所有这些都可以基本表达出来

292
00:13:21,915 --> 00:13:24,900
in two- in two- in two-matrix multiplications,
在两个双矩阵乘法中，

293
00:13:24,900 --> 00:13:27,620
and the square root factor is just to make sure that these,
平方根因子只是为了确保这些，

294
00:13:27,620 --> 00:13:29,080
these dot products don't blow up.
这些点产品不会爆炸。

295
00:13:29,080 --> 00:13:30,425
It's just a scaling factor.
这只是一个缩放因子。

296
00:13:30,425 --> 00:13:32,145
And, uh, and, and,
而且，呃，和，和，

297
00:13:32,145 --> 00:13:33,605
wha- why is this particular- why is
哇 - 为什么这个特别 - 为什么

298
00:13:33,605 --> 00:13:35,735
this mechanism attractive? Well, it's just really fast.
这种机制吸引人？嗯，它真的很快。

299
00:13:35,735 --> 00:13:37,340
You can do this very quickly on a GPU,
你可以在GPU上快速完成这项工作，

300
00:13:37,340 --> 00:13:39,010
and simul- you can do it simultaneously for
和同时 - 你可以同时做到

301
00:13:39,010 --> 00:13:43,045
all positions with just two matmuls and a softmax.
只有两个matmuls和一个softmax的所有位置。

302
00:13:43,045 --> 00:13:45,320
Um, on the decoder side it's,
嗯，在解码器方面，

303
00:13:45,320 --> 00:13:46,640
it's exactly the same,
它完全一样，

304
00:13:46,640 --> 00:13:54,585
except we impose causality by just adding 10 e- minus 10 e9 to the logits.
除了我们通过在logits中添加10 e-minus 10 e9来强加因果关系。

305
00:13:54,585 --> 00:13:58,135
So it basi- it's just- you just get zero probabilities on those positions.
所以它只是 - 你只是在这些位置上获得零概率。

306
00:13:58,135 --> 00:14:00,820
So we just impose causality by, by adding these,
所以我们只是通过添加这些因素来强加因果关系，

307
00:14:00,820 --> 00:14:04,410
uh, highly negative values on the attention- on the attention logits.
呃，关注注意力的注意力非常负面的价值观。

308
00:14:04,410 --> 00:14:06,745
Um, is, is everything-
嗯，是，一切 -

309
00:14:06,745 --> 00:14:07,410
[LAUGHTER]
[笑声]

310
00:14:07,410 --> 00:14:13,600
I thought that was a question.
我认为这是一个问题。

311
00:14:13,600 --> 00:14:18,455
So, um, [LAUGHTER] okay so attention is really, uh, attention is cheap.
所以，嗯，[笑声]好的，所以关注真的是，呃，注意力很便宜。

312
00:14:18,455 --> 00:14:20,890
So because it's- because this variant of
所以因为它 - 因为这个变种

313
00:14:20,890 --> 00:14:23,905
attention just involve two- involves two matrix multiplications,
注意只涉及两个 - 涉及两个矩阵乘法，

314
00:14:23,905 --> 00:14:26,510
it's quadratic in the length of your sequence.
它是你序列长度的二次方。

315
00:14:26,510 --> 00:14:30,815
And now what's the computational profile of RNNs or convolutions?
现在RNN或卷积的计算轮廓是什么？

316
00:14:30,815 --> 00:14:32,370
They're quadratic in the dimension.
它们在维度上是二次的。

317
00:14:32,370 --> 00:14:35,045
Because, basically, you can just think of a convolution just flattening
因为，基本上，你可以想到卷积只是扁平化

318
00:14:35,045 --> 00:14:38,170
your input or just applying a linear transformation on top of it, right?
你的输入或只是在它上面应用线性变换，对吧？

319
00:14:38,170 --> 00:14:40,835
So- and when does this actually become very attractive?
那么 - 这什么时候真的变得非常有吸引力？

320
00:14:40,835 --> 00:14:44,140
This becomes very, very attractive when your dimension is,
当你的尺寸是，这变得非常非常有吸引力，

321
00:14:44,140 --> 00:14:46,635
uh, much larger than your length.
呃，比你的长度大得多。

322
00:14:46,635 --> 00:14:48,455
Which is the case for machine translation.
机器翻译的情况如何。

323
00:14:48,455 --> 00:14:51,335
Now, we will talk about cases when there's- when the- when this is not true,
现在，我们将讨论有何情况 - 何时 - 何时不成立，

324
00:14:51,335 --> 00:14:54,280
and we have to- we have to do a- we have to make other model developments.
我们必须 - 我们必须做 - 我们必须进行其他模型开发。

325
00:14:54,280 --> 00:14:56,440
Um, but, uh, but for
嗯，但是，呃，但是

326
00:14:56,440 --> 00:14:58,020
short sequences or sequences where
短序列或序列

327
00:14:58,020 --> 00:15:00,020
your length does- where your dimension dominates length,
你的长度确实 - 你的尺寸在哪里占主导地位，

328
00:15:00,020 --> 00:15:02,890
attention is a very- has a very favorable computation profile.
注意力是非常有利的计算特征。

329
00:15:02,890 --> 00:15:06,355
And as you can see, it's about four times faster than an RNN.
正如您所看到的，它比RNN快四倍。

330
00:15:06,355 --> 00:15:08,920
Um, um, and, and faster than
嗯，嗯，而且比

331
00:15:08,920 --> 00:15:12,995
a convolutional model where the- you have a kernel of- like filter with, uh, three.
一个卷积模型，你有一个类似过滤器的内核，呃，三个。

332
00:15:12,995 --> 00:15:19,320
So, so there's still one problem.
所以，还有一个问题。

333
00:15:19,320 --> 00:15:21,455
Now, here's something- so in language,
现在，这里有一些东西 - 所以语言，

334
00:15:21,455 --> 00:15:22,595
typically, we want to know, like,
通常，我们想知道，像，

335
00:15:22,595 --> 00:15:23,900
who did what to whom, right?
谁做了什么对谁，对吧？

336
00:15:23,900 --> 00:15:25,770
So now, imagine you applied a convolutional filter.
所以现在，想象一下你应用了一个卷积滤波器。

337
00:15:25,770 --> 00:15:26,825
Because you actually have
因为你真的有

338
00:15:26,825 --> 00:15:30,445
different linear transformations based on let- relative distances,
基于let-relative距离的不同线性变换，

339
00:15:30,445 --> 00:15:31,770
like this, this, this, this,
像这样，这个，这个，这个，

340
00:15:31,770 --> 00:15:35,320
linear transformation on the word who, uh, o- o- on the concept,
关于这个词的线性变换，呃，o- o-关于概念，

341
00:15:35,320 --> 00:15:37,690
we can have- can learn this concept of who and, and, and,
我们可以 - 可以学习谁和和的概念，和

342
00:15:37,690 --> 00:15:40,355
pick out different information from this embedding of the word I.
从这个单词的嵌入中挑选出不同的信息。

343
00:15:40,355 --> 00:15:41,930
And this linear transformation,
而这个线性变换，

344
00:15:41,930 --> 00:15:44,530
the lre- the red linear transformation can pick out different information
lre-红色线性变换可以选出不同的信息

345
00:15:44,530 --> 00:15:47,765
from kicked and the blue linear transformation can pick out different,
从踢和蓝色线性转换可以挑出不同的，

346
00:15:47,765 --> 00:15:49,445
different information from ball.
来自球的不同信息。

347
00:15:49,445 --> 00:15:53,230
Now, when you have a single attention layer, this is difficult.
现在，当你有一个关注层时，这很难。

348
00:15:53,230 --> 00:15:55,330
Because all- because they're just a convex combination
因为所有 - 因为它们只是一个凸起的组合

349
00:15:55,330 --> 00:15:57,320
where you have the same linear transformation everywhere.
你到处都有相同的线性变换。

350
00:15:57,320 --> 00:16:00,215
All that's available to you is just a- is just mixing proportions.
所有可用的只是a-只是混合比例。

351
00:16:00,215 --> 00:16:03,670
So you can't pick out different pieces of information from different places.
所以你不能从不同的地方挑选出不同的信息。

352
00:16:03,670 --> 00:16:10,270
Well, what if we had one attention layer for who?
那么，如果我们有一个关注层为谁呢？

353
00:16:10,270 --> 00:16:13,595
So you can think of an attention layer as something like a feature detector almost,
所以你可以把注意力层看作几乎像特征探测器的东西，

354
00:16:13,595 --> 00:16:15,040
like, because a particular- it,
喜欢，因为特定的，

355
00:16:15,040 --> 00:16:18,340
it might try to- it might- because it carries with it a linear transformation,
它可能会尝试 - 它可能 - 因为它带有线性变换，

356
00:16:18,340 --> 00:16:21,700
so it's projecting them in a space that- which starts caring maybe about syntax,
所以它将它们投射到一个空间中 - 这开始关心语法，

357
00:16:21,700 --> 00:16:24,485
or it's projecting in this space which starts caring about who or what.
或者它正在这个开始关心谁或什么的空间中投射。

358
00:16:24,485 --> 00:16:28,940
Uh, then we can have another attention layer for or attention head for what,
呃，那么我们可以有另一个关注层或注意力为什么，

359
00:16:28,940 --> 00:16:31,490
did what, and other- another attention head for,
做了什么，和其他 - 另一个注意力，

360
00:16:31,490 --> 00:16:34,115
for, for whom- to whom.
为谁而为谁。

361
00:16:34,115 --> 00:16:37,300
And all of this can actually be done in parallel,
所有这一切实际上可以并行完成，

362
00:16:37,300 --> 00:16:39,210
and that's actually- and that's exactly what we do.
而这实际上 - 这正是我们所做的。

363
00:16:39,210 --> 00:16:41,255
And for efficiency, instead of actually
为了效率，而不是实际

364
00:16:41,255 --> 00:16:44,230
having these dimensions operating in a large space,
这些尺寸在大空间内运行，

365
00:16:44,230 --> 00:16:46,990
we just- we just reduce the dimensionality of all these heads
我们只是 - 我们只是减少所有这些头的维度

366
00:16:46,990 --> 00:16:50,225
and we operate these attention layers in parallel, sort of bridging the gap.
我们并行操作这些注意力层，弥补了差距。

367
00:16:50,225 --> 00:16:51,670
Now, here's a, uh,
现在，这是一个，呃，

368
00:16:51,670 --> 00:16:53,660
perhaps, well, here's a little quiz.
或许，好吧，这是一个小小的测验。

369
00:16:53,660 --> 00:16:56,400
I mean, can you actually- is there
我的意思是，你真的可以吗？

370
00:16:56,400 --> 00:17:01,105
a combination of heads or is there a configuration in which you can,
头部的组合或是否有可以配置的配置，

371
00:17:01,105 --> 00:17:04,260
actually, exactly simulate a convolution probably with more parameters?
实际上，可能使用更多参数来精确模拟卷积？

372
00:17:04,260 --> 00:17:06,390
I think there should be a simple way to show that if you
我想应该有一个简单的方法来表明，如果你

373
00:17:06,390 --> 00:17:09,650
had mo- more heads or heads are a function of positions,
有更多的头或头是位置的函数，

374
00:17:09,650 --> 00:17:11,875
you could probably just simulate a convolution,
你可能只是模拟一个卷积，

375
00:17:11,875 --> 00:17:13,375
but- although with a lot of parameters.
但是 - 尽管有很多参数。

376
00:17:13,375 --> 00:17:15,150
Uh, so it can- in, in,
呃，所以它可以进去，

377
00:17:15,150 --> 00:17:17,140
in the limit, it can actually simulate a convolution.
在极限中，它实际上可以模拟卷积。

378
00:17:17,140 --> 00:17:21,280
Uh, and it also- we can al- we can continue to enjoy the benefits of parallelism,
呃，它也 - 我们可以继续享受并行的好处，

379
00:17:21,280 --> 00:17:23,045
but we did increase the number of softmaxes
但我们确实增加了softmax的数量

380
00:17:23,045 --> 00:17:24,820
because each head then carries with it a softmax.
因为每个头随身携带一个softmax。

381
00:17:24,820 --> 00:17:27,190
But the amount of FLOPS didn't change because we-
但FLOPS的数量没有改变，因为我们 -

382
00:17:27,190 --> 00:17:30,010
instead of actually having these heads operating in very large dimensions,
而不是实际上这些头在非常大的尺寸上操作，

383
00:17:30,010 --> 00:17:32,220
they're operating in very small dimensions.
它们的运行范围非常小。

384
00:17:32,220 --> 00:17:35,105
Um, so, uh, when we applied this on, on,
嗯，呃，当我们把它应用于，

385
00:17:35,105 --> 00:17:37,535
on machine translation, um,
机器翻译，嗯，

386
00:17:37,535 --> 00:17:40,295
we were able to drama- uh, dramatically outperform,
我们能够戏剧性地表现出色，表现出色，

387
00:17:40,295 --> 00:17:43,640
uh, previous results on English-German and English-French translation.
呃，以前的英语 - 德语和英语 - 法语翻译结果。

388
00:17:43,640 --> 00:17:47,075
So we had a pretty standard setup: 32,000-word vocabularies,
所以我们有一个非常标准的设置：32,000个单词的词汇，

389
00:17:47,075 --> 00:17:50,315
WordPiece encodings, WMT14-, uh,
WordPiece编码，WMT14-，呃，

390
00:17:50,315 --> 00:17:52,540
WMT 2014, uh, was our test set,
WMT 2014，呃，是我们的测试集，

391
00:17:52,540 --> 00:17:53,970
2013 did the dev set.
2013年开发了设定。

392
00:17:53,970 --> 00:17:59,120
And, uh, and some of these results were much stronger than even our previous ensemble models.
而且，呃，这些结果中的一些甚至比我们之前的合奏模型强得多。

393
00:17:59,120 --> 00:18:02,690
And, um, and on English-French also,
而且，嗯，还有英语 - 法语，

394
00:18:02,690 --> 00:18:05,400
we had some- we had some very favorabl- favorable results.
我们有一些 - 我们有一些非常有利的结果。

395
00:18:05,400 --> 00:18:06,630
Uh, and we- and we are,
呃，我们 - 我们是，

396
00:18:06,630 --> 00:18:08,425
we, we, we achieved state of the art.
我们，我们，我们取得了最先进的技术。

397
00:18:08,425 --> 00:18:11,260
Now, ste- stepping back a bit, uh,
现在，退一步，呃，

398
00:18:11,260 --> 00:18:13,905
I- I'm not claiming that we,
我 - 我没有声称我们，

399
00:18:13,905 --> 00:18:17,105
we arrived at an architecture that has better expressivity than an LSTM.
我们得到的结构比LSTM具有更好的表现力。

400
00:18:17,105 --> 00:18:18,600
I mean, there's, there's, there's,
我的意思是，有，有，有，

401
00:18:18,600 --> 00:18:22,430
there's theorems that are- that say that LSTMs can model any function.
有定理 - 说LSTM可以模拟任何函数。

402
00:18:22,880 --> 00:18:27,870
Um, perhaps, all we did was just build an architecture that was good for SGD.
嗯，或许，我们所做的只是建立一个对SGD有利的架构。

403
00:18:27,870 --> 00:18:30,895
Because stochastic gradient descent could just train this architecture really well,
因为随机梯度下降可以很好地训练这个架构，

404
00:18:30,895 --> 00:18:33,400
because the gradient dynamics and attention are very simple attentions,
因为梯度动力学和注意力都非常简单，

405
00:18:33,400 --> 00:18:34,615
just a linear combination.
只是一个线性组合。

406
00:18:34,615 --> 00:18:37,820
And, uh, um, I think that's- I,
而且，恩，嗯，我想 - 我，

407
00:18:37,820 --> 00:18:39,560
I think that's actually favorable.
我认为这实际上是有利的。

408
00:18:39,560 --> 00:18:42,235
But hopefully, uh, as we- as we go on,
但希望，呃，就像我们一样，我们继续

409
00:18:42,235 --> 00:18:43,480
but the- well, I'd,
但是，好吧，我，

410
00:18:43,480 --> 00:18:44,860
I'd also like to point out that, you know,
我还要指出，你知道，

411
00:18:44,860 --> 00:18:47,770
we do explicit mo- we do explicitly model all,
我们做明确的莫 - 我们明确地模仿所有，

412
00:18:47,770 --> 00:18:49,440
all path connection, all, all,
所有路径连接，全部，全部，

413
00:18:49,440 --> 00:18:54,065
all pairwise connections and it has its adva- advantage of a very clear modeling,
所有成对连接，它具有非常清晰的建模的优势，

414
00:18:54,065 --> 00:18:56,575
very clear relationships directly between, between any two words.
任何两个词之间直接关系非常明确。

415
00:18:56,575 --> 00:19:00,640
Um, and, like, hopefully we'll be able to also
嗯，希望我们也能够

416
00:19:00,640 --> 00:19:02,260
show that there are other inductive biases.
表明还有其他归纳偏见。

417
00:19:02,260 --> 00:19:05,605
That it's not just like building more architectures that,
这不仅仅是建立更多的架构，

418
00:19:05,605 --> 00:19:08,720
that are good for- that are good inductive biases for SGD.
这对SGD来说是好的诱导偏见。

419
00:19:08,720 --> 00:19:13,000
So frameworks, a lot of our work was initially pushed out in tensor2tensor.
所以框架，我们的很多工作最初是在tensor2tensor中推出的。

420
00:19:13,000 --> 00:19:15,985
Maybe that might change in the future with the arrival of JAX.
随着JAX的到来，未来可能会发生变化。

421
00:19:15,985 --> 00:19:18,790
There's ano- there's a framework also from Amazon called Sockeye.
还有一个来自亚马逊的框架称为Sockeye。

422
00:19:18,790 --> 00:19:20,810
There's also Fairseq, uh, the se- the
还有Fairseq，呃，这个

423
00:19:20,810 --> 00:19:23,640
convolutional sequence-to-sequence toolkit from Facebook that the,
来自Facebook的卷积序列到序列工具包，

424
00:19:23,640 --> 00:19:26,290
they prob- I'm actually not sure if it has a transformer implementation,
他们有问题 - 我实际上不确定它是否有变压器实现，

425
00:19:26,290 --> 00:19:29,480
but they have some really good sequence-to-sequence models as well.
但它们也有一些非常好的序列到序列模型。

426
00:19:29,480 --> 00:19:31,700
Um, okay.
嗯，好的。

427
00:19:31,700 --> 00:19:32,845
So the importance of residuals.
所以残差的重要性。

428
00:19:32,845 --> 00:19:37,875
So, uh, we have these resil- residual connections, uh, between, um,
那么，呃，我们有这些弹性残差连接，呃，介于...之间，嗯，

429
00:19:37,875 --> 00:19:41,795
so we have these residual connections that go from here to- here to here,
所以我们有这些剩余的连接，从这里到这里，

430
00:19:41,795 --> 00:19:45,240
here to here, like between every pair of layers, and it's interesting.
在这里，就像在每对图层之间，这很有趣。

431
00:19:45,240 --> 00:19:47,895
So we, um, we- so what we do is we just
所以我们，嗯，我们 - 我们所做的就是我们

432
00:19:47,895 --> 00:19:51,025
add the position informations at the input to the model.
在模型的输入处添加位置信息。

433
00:19:51,025 --> 00:19:53,525
And, uh, we don't infuse- we don't infuse
而且，呃，我们没有注入 - 我们没有注入

434
00:19:53,525 --> 00:19:56,150
or we don't inject position information at every layer.
或者我们不会在每一层注入位置信息。

435
00:19:56,150 --> 00:20:02,185
So when, uh, we severed these residual connections and we loo- stared at these,
所以当呃，我们切断了这些剩余的连接，我们就这样关注，

436
00:20:02,185 --> 00:20:04,805
uh, stared at these attention distributions, this is the center or,
呃，盯着这些注意力分布，这是中心或者，

437
00:20:04,805 --> 00:20:07,545
sort of, the middle map is this attention distribution.
中间地图就是这种注意力分布。

438
00:20:07,545 --> 00:20:10,750
You actually- basically, it- it's been unable to pick this diagonal.
你实际上 - 基本上，它 - 它无法选择这个对角线。

439
00:20:10,750 --> 00:20:13,370
It should have a very strong diagonal focus.
它应该具有非常强的对角焦点。

440
00:20:13,370 --> 00:20:15,330
And so what has happened was these residuals
所以发生的事情就是这些残差

441
00:20:15,330 --> 00:20:18,155
were carrying this position information to every layer.
把这个位置信息带到每一层。

442
00:20:18,155 --> 00:20:20,820
And because these subsequent layers had no notion of position,
而且因为这些后续层没有位置概念，

443
00:20:20,820 --> 00:20:22,900
they were fi- finding it hard to actually attend.
他们发现很难真正参加。

444
00:20:22,900 --> 00:20:25,875
This is the encoder-decoder attention which typically ends up being diagonal.
这是编码器 - 解码器的注意力，通常最终是对角线。

445
00:20:25,875 --> 00:20:27,380
Now, so then we, uh, we said okay.
现在，那么我们，呃，我们说好了。

446
00:20:27,380 --> 00:20:30,700
So then we actually continued with- continued to sever the residuals,
那么我们实际上继续 - 继续切断残差，

447
00:20:30,700 --> 00:20:32,950
but we added position information back in at every layer.
但我们在每一层都添加了位置信息。

448
00:20:32,950 --> 00:20:34,835
We injected position information back in.
我们重新注入了位置信息。

449
00:20:34,835 --> 00:20:36,390
And we didn't recover the accuracy,
我们没有恢复准确性，

450
00:20:36,390 --> 00:20:37,790
but we did get some of this,
但我们确实得到了一些，

451
00:20:37,790 --> 00:20:39,300
sort of, diagonal focus back in.
一种对角线焦点。

452
00:20:39,300 --> 00:20:41,400
So the residuals are doing more, but they're certainly,
所以残差做得更多，但他们肯定是，

453
00:20:41,400 --> 00:20:44,160
definitely moving this position information to the model there.
肯定将这个位置信息移动到那里的模型。

454
00:20:44,160 --> 00:20:46,805
They're pumping this position information through the model.
他们通过模型抽取这个位置信息。

455
00:20:46,805 --> 00:20:49,070
Um, okay.
嗯，好的。

456
00:20:49,070 --> 00:20:51,365
So, so that was- that was- so, so now we saw that,
那么，那就是 - 那么，所以现在我们看到了，

457
00:20:51,365 --> 00:20:52,445
you know, being able to, sort of,
你知道，能够，有点，

458
00:20:52,445 --> 00:20:53,895
model both long- and short-,
长短模型，

459
00:20:53,895 --> 00:20:56,510
short-term relationships, uh, sh- uh, long and,
短暂的关系，呃，长，和，

460
00:20:56,510 --> 00:20:58,435
long- and short-distance relationships with,
长距离和短距离的关系，

461
00:20:58,435 --> 00:21:01,745
with attention is beneficial for, for text generation.
注意对于文本生成是有益的。

462
00:21:01,745 --> 00:21:03,525
Um, what kind of inductive,
嗯，什么样的归纳，

463
00:21:03,525 --> 00:21:06,780
inductive biases lay- actually, uh, appear, or what,
归纳偏见 - 实际上，呃，出现或是什么，

464
00:21:06,780 --> 00:21:10,860
what kind of phenomena appear in images and something that we constantly see- constantly
什么样的现象出现在图像和我们经常看到的东西 - 不断

465
00:21:10,860 --> 00:21:12,745
see in images and music is this notion of
看到图像和音乐是这个概念

466
00:21:12,745 --> 00:21:15,180
repeating structure that's very similar to each other?
重复彼此非常相似的结构？

467
00:21:15,180 --> 00:21:18,055
You have these motifs that repeat in, in different scales.
你有不同尺度的重复这些图案。

468
00:21:18,055 --> 00:21:21,420
So, for example, there's a b- it's another artificial but beautiful example of
所以，例如，有一个b-它是另一个人为但美丽的例子

469
00:21:21,420 --> 00:21:24,900
self-similarity where you have this Van Gogh painting where this texture or these,
自我相似，你有这个梵高画这里的纹理或这些，

470
00:21:24,900 --> 00:21:26,410
these little objects just repeat.
这些小物件只是重复一遍。

471
00:21:26,410 --> 00:21:30,280
These images are- these different pieces of the image are very sa- similar to each other,
这些图像是 - 这些不同的图像彼此非常相似，

472
00:21:30,280 --> 00:21:31,595
but they might have different scales.
但他们可能有不同的规模。

473
00:21:31,595 --> 00:21:32,950
Uh, again in music,
呃，又是音乐，

474
00:21:32,950 --> 00:21:34,615
here's a motif that repeats, uh,
这是一个重复的主题，呃，

475
00:21:34,615 --> 00:21:36,605
that could have- it could have, like,
可能有 - 可能有，像，

476
00:21:36,605 --> 00:21:40,115
di- various, like, spans of time between in, in, between it.
各种各样的，例如，在它之间，之间，之间的时间跨度。

477
00:21:40,115 --> 00:21:43,250
So, um, so, so this,
所以，嗯，所以，这个，

478
00:21:43,250 --> 00:21:44,440
so we, we, we,
所以我们，我们，我们，

479
00:21:44,440 --> 00:21:45,775
we attempted after this to see, well,
我们试图在此之后看到，好吧，

480
00:21:45,775 --> 00:21:49,720
to ask this question: can self-attention help us in modeling other objects like images?
问这个问题：自我关注可以帮助我们建模像图像这样的其他对象吗？

481
00:21:49,720 --> 00:21:51,715
So the, the path we took was, sort of,
那么，我们采取的路径是，

482
00:21:51,715 --> 00:21:57,450
standard auto-regressive image modeling the- or probabilistic image modeling, not GANs.
标准自回归图像建模概率或概率图像建模，而不是GAN。

483
00:21:57,450 --> 00:21:58,910
Because it was- well, one, it was very easy.
因为它很好，一个，很容易。

484
00:21:58,910 --> 00:22:00,085
We had a language model almost.
我们几乎有一个语言模型。

485
00:22:00,085 --> 00:22:02,245
So this is just like language modeling on images.
所以这就像图像上的语言建模一样。

486
00:22:02,245 --> 00:22:03,910
Uh, and also training at maximum,
呃，还有最大的训练，

487
00:22:03,910 --> 00:22:04,930
likely, it allows you to, sort of,
可能，它允许你，有点，

488
00:22:04,930 --> 00:22:06,720
measure, measure how well you're doing on,
衡量，衡量你做得多好，

489
00:22:06,720 --> 00:22:08,780
uh, on, on your held-out set.
呃，在你举行的集合上。

490
00:22:08,780 --> 00:22:10,840
Uh, and it also gives you diversity,
呃，它也给你多样性，

491
00:22:10,840 --> 00:22:12,785
so you hopefully are covering all possible, uh,
所以你希望覆盖所有可能的，呃，

492
00:22:12,785 --> 00:22:15,900
different kinds of images you- So, um,
各种各样的图像 - 所以，嗯，

493
00:22:15,900 --> 00:22:17,290
and to this point there's al- we had
到目前为止，我们已经拥有了

494
00:22:17,290 --> 00:22:18,880
an advantage that's also been- there are- there've been
这种优势也一直存在

495
00:22:18,880 --> 00:22:22,425
good work on using recurrent models like PixelRNN and PixelCNN,
使用像PixelRNN和PixelCNN这样的周期性模型的好工作，

496
00:22:22,425 --> 00:22:26,330
that, that we're actually getting some very good compression rates. Um-
那，我们实际上得到了一些非常好的压缩率。 UM-

497
00:22:26,330 --> 00:22:31,805
And, um, again here,
而且，嗯，再来一次，

498
00:22:31,805 --> 00:22:35,610
originally the argument was that, well, you know,
最初的论点是，嗯，你知道，

499
00:22:35,610 --> 00:22:37,920
in images because there- because you want symmetry,
在图像中因为你想要对称，

500
00:22:37,920 --> 00:22:39,300
because you want like if you have a face,
因为如果你有脸，你想要

501
00:22:39,300 --> 00:22:41,580
you want, you want one ear to sort of match with the other.
你想要的，你想要一只耳朵与另一只耳朵匹配。

502
00:22:41,580 --> 00:22:43,575
If you had a large receptive field,
如果你有一个大的感受野，

503
00:22:43,575 --> 00:22:47,130
which you could potentially get with attention at a lower computational cost,
您可以以较低的计算成本获得关注，

504
00:22:47,130 --> 00:22:50,820
then it should benefit- then it should be quite beneficial for, for images,
然后它应该受益 - 那么对于图像，它应该是非常有益的

505
00:22:50,820 --> 00:22:53,640
for images and you wouldn't need many layers like you do in
对于图像而言，你不需要像你那样需要很多层

506
00:22:53,640 --> 00:22:57,955
convolutions to actually get dependencies between these far away pixels.
卷积实际上获得这些遥远像素之间的依赖关系。

507
00:22:57,955 --> 00:23:00,670
So it seem like self-attention would have been a- what, what,
所以看起来自我关注会是什么，什么，

508
00:23:00,670 --> 00:23:03,745
what was already a good computational mechanism, right?
什么是一个很好的计算机制，对吧？

509
00:23:03,745 --> 00:23:06,580
But this sort of- but it was actually interesting to see
但是这种 - 但实际上很有趣

510
00:23:06,580 --> 00:23:09,700
how it even modeled- naturally modeled self-similarity,
它是如何建模的 - 自然地建模自相似性，

511
00:23:09,700 --> 00:23:12,460
and people have used self-similarity in image generation like, you know, uh,
人们在图像生成中使用了自相似性，就像你知道的那样，呃，

512
00:23:12,460 --> 00:23:15,760
there's this really cool work by Efros where they actually see, okay,
Efros真的很酷，他们实际上看到了，好吧，

513
00:23:15,760 --> 00:23:18,670
in the training set, what are those patches that are really,
在训练集中，那些真正的补丁是什么，

514
00:23:18,670 --> 00:23:19,810
that are really similar to me?
那真的和我相似吗？

515
00:23:19,810 --> 00:23:21,640
And based on the patches that are really similar to me,
基于与我非常相似的补丁，

516
00:23:21,640 --> 00:23:23,035
I'm going to fill up the information.
我要填写这些信息。

517
00:23:23,035 --> 00:23:25,495
So it's like actually doing image generation.
所以它就像实际上做图像生成一样。

518
00:23:25,495 --> 00:23:27,430
Uh, there is this really classic work called
呃，有这个非常经典的作品叫做

519
00:23:27,430 --> 00:23:29,980
non-local means where they do image denoising,
非本地意味着它们进行图像去噪，

520
00:23:29,980 --> 00:23:31,915
where they want to denoise this sort of,
他们想要在哪里去噪，

521
00:23:31,915 --> 00:23:34,450
this patch P. And they say,
这个补丁P.他们说，

522
00:23:34,450 --> 00:23:38,290
I'm going to- based on my similarity between all other patches in my image,
我将基于我的图像中所有其他补丁之间的相似性，

523
00:23:38,290 --> 00:23:41,125
I'm going to compute some function of content-based similarity,
我要计算基于内容的相似性的一些功能，

524
00:23:41,125 --> 00:23:43,525
and based on the similarity I'm going to pull information.
并根据相似性我将提取信息。

525
00:23:43,525 --> 00:23:46,645
So as- and exploiting this fact that images are very self-similar.
因此，并利用这一事实，即图像非常相似。

526
00:23:46,645 --> 00:23:50,440
And, uh, uh, this has also been sort of,
而且，呃，这也是一种，

527
00:23:50,440 --> 00:23:52,390
uh, applied in some recent work.
呃，适用于最近的一些工作。

528
00:23:52,390 --> 00:23:55,030
Now if you just took this encoder self-attention mechanism
现在，如果你只是采取这种编码器自我关注机制

529
00:23:55,030 --> 00:23:57,175
and just replace these word embeddings with patches,
并用补丁替换这些单词嵌入，

530
00:23:57,175 --> 00:23:58,765
and that's kind of exactly what it's doing.
这就是它正在做的事情。

531
00:23:58,765 --> 00:24:01,330
It's, it's computing this notion of content-based similarity
它是，它正在计算这种基于内容的相似性的概念

532
00:24:01,330 --> 00:24:04,120
between these elements and then based on this content-based similarity,
在这些元素之间，然后基于这种基于内容的相似性，

533
00:24:04,120 --> 00:24:07,510
it constructs a convex combination that essentially brings these things together.
它构造了一个凸起的组合，基本上将这些东西结合在一起。

534
00:24:07,510 --> 00:24:09,385
So it's, it's a very ni- it was,
所以，它是一个非常非常的，

535
00:24:09,385 --> 00:24:11,545
it was quite- it was very pleasant to see that,
这真是太令人愉快了，

536
00:24:11,545 --> 00:24:13,975
oh, this is a differentiable way of doing non-local means.
哦，这是一种做到非本地手段的可区分方式。

537
00:24:13,975 --> 00:24:22,030
And, uh, and we took the transformer architecture and replaced words with pixels.
而且，呃，我们采用变压器架构并用像素替换了单词。

538
00:24:22,030 --> 00:24:26,005
Uh, there was some- there were some architecture adjustments to do.
呃，有一些 - 有一些架构调整要做。

539
00:24:26,005 --> 00:24:28,300
And, uh, so this was but- this was
而且，呃，所以这是 - 但是 - 这是

540
00:24:28,300 --> 00:24:31,090
basically the kind of- it was very similar to the original work,
基本上那种 - 它与原作非常相似，

541
00:24:31,090 --> 00:24:34,360
and here the position representations instead of being, you know,
这里是位置表示，而不是，你知道，

542
00:24:34,360 --> 00:24:36,760
one-dimensional, they were- because we are not dealing with sequences,
一维，他们是 - 因为我们没有处理序列，

543
00:24:36,760 --> 00:24:38,350
we have two-dimensional position representations.
我们有二维位置表示。

544
00:24:38,350 --> 00:24:40,365
Um, okay.
嗯，好的。

545
00:24:40,365 --> 00:24:42,070
So I pointed out before,
所以我之前指出过，

546
00:24:42,070 --> 00:24:45,775
attention is a very com- very favorable computational profile
注意力是非常有利的计算特征

547
00:24:45,775 --> 00:24:49,270
if your length- if your dimension dominates length,
如果你的长度 - 如果你的尺寸占主导地位，

548
00:24:49,270 --> 00:24:51,250
which if- which is absolutely untrue for,
如果 - 这绝对是不真实的，

549
00:24:51,250 --> 00:24:52,540
absolutely untrue for images.
绝对不真实的图像。

550
00:24:52,540 --> 00:24:56,170
Uh, because even for like 32 by- even for 32 by 32 images,
呃，因为即使是32比32的图像，

551
00:24:56,170 --> 00:24:59,260
when you flatten them and you- and you flatten them, you have 30- you get 30,
当你把它们弄平而你 - 然后你把它们弄平，你有30-你得到30，

552
00:24:59,260 --> 00:25:02,960
72 positions, uh, so it's your standard CFIR image.
72个位置，呃，所以这是你的标准CFIR图像。

553
00:25:02,960 --> 00:25:06,400
Um, so simple solution, uh,
嗯，这么简单的解决方案，呃，

554
00:25:06,400 --> 00:25:09,220
because like convolutions of- I mean,
因为喜欢卷积 - 我的意思是，

555
00:25:09,220 --> 00:25:11,140
you get- convolutions are basically looked
你得到了 - 基本上看了卷积

556
00:25:11,140 --> 00:25:13,345
at local windows and you get translational equivariance.
在本地窗口，你得到转换等价。

557
00:25:13,345 --> 00:25:16,660
We said, "Okay. Let's adopt the same strategy."
我们说：“好的。让我们采用相同的策略。”

558
00:25:16,660 --> 00:25:19,225
And also there's a lot of spatial locality and images.
而且还有很多空间局部性和图像。

559
00:25:19,225 --> 00:25:24,265
Uh, but now, we will still have a better computational profile.
呃，但现在，我们仍然会有更好的计算资料。

560
00:25:24,265 --> 00:25:27,340
If your- if your receptive field is still smaller than your dimension,
如果您 - 如果您的感受野仍然小于您的尺寸，

561
00:25:27,340 --> 00:25:29,485
you can afford- you can actually still do
你买得起 - 你实际上还可以做到

562
00:25:29,485 --> 00:25:34,600
much more long distance computation than a standard convolution because you're,
比标准卷积更远的长距离计算，因为你，

563
00:25:34,600 --> 00:25:37,615
uh, because you're quadratic in length.
呃，因为你的长度是二次方的。

564
00:25:37,615 --> 00:25:40,390
So as long as we didn't increase our length beyond the dimension,
所以只要我们不增加超出尺寸的长度，

565
00:25:40,390 --> 00:25:42,415
we still had a favorable computational profile.
我们仍然有一个有利的计算资料。

566
00:25:42,415 --> 00:25:44,440
And so the way we did it was, uh,
所以我们这样做的方式是，呃，

567
00:25:44,440 --> 00:25:46,195
we essentially had, uh,
我们基本上有，呃，

568
00:25:46,195 --> 00:25:47,950
two kinds of rasterizations.
两种光栅化。

569
00:25:47,950 --> 00:25:52,210
So we had a one-dimensional rasterization where you had a sort of single query block,
所以我们有一个单维光栅化，你有一个单一的查询块，

570
00:25:52,210 --> 00:25:54,790
uh, which was, uh,
呃，这是，呃，

571
00:25:54,790 --> 00:25:58,660
which was then attending or to the- into a larger memory block,
然后参加或进入更大的内存块，

572
00:25:58,660 --> 00:26:02,680
uh, in this rasterized fashion along the- along, along the rows.
呃，沿着这条光栅化的方式沿着行。

573
00:26:02,680 --> 00:26:05,320
Um, then we tried another form of rasterization,
嗯，然后我们尝试了另一种形式的光栅化，

574
00:26:05,320 --> 00:26:07,780
falling standard two-dimensional locality,
下降的标准二维位置，

575
00:26:07,780 --> 00:26:10,360
where you had- where we actually produced the image in,
你在哪里 - 我们实际生产图像的地方，

576
00:26:10,360 --> 00:26:13,300
uh, in blocks and within each block we had a rasterization scheme.
呃，在块中和每个块内我们有一个光栅化方案。

577
00:26:13,300 --> 00:26:18,640
Um, again, these- the image transformer layer was very similar.
嗯，再次，这些 - 图像变换器层非常相似。

578
00:26:18,640 --> 00:26:21,280
We had two-dimensional position representations along
我们有二维位置表示

579
00:26:21,280 --> 00:26:24,670
with query- with the same- with a very similar attention mechanism.
与查询相同 - 具有非常相似的注意机制。

580
00:26:24,670 --> 00:26:27,220
Um, and we tried
嗯，我们试过了

581
00:26:27,220 --> 00:26:30,550
both super-resolution and unconditional and conditional image generation.
超分辨率和无条件和条件图像生成。

582
00:26:30,550 --> 00:26:34,074
Uh, this is- this is Ne- Niki Parmar,
呃，这是 - 这是Ne-Niki Parmar，

583
00:26:34,074 --> 00:26:37,255
I and a co- and a few other authors from Brain,
我和其他一些来自Brain的作者，

584
00:26:37,255 --> 00:26:39,580
um, and we presented it at ICML.
嗯，我们在ICML展示了它。

585
00:26:39,580 --> 00:26:44,815
And, uh, we were able to achieve better perplexity than existing models.
而且，呃，我们能够比现有的模型更加困惑。

586
00:26:44,815 --> 00:26:47,650
So PixelSNAIL is actually another model that used- mixed
所以PixelSNAIL实际上是另一种混合使用的模型

587
00:26:47,650 --> 00:26:50,695
both convolutions and self-attention and they- they outperformed us on,
无论是革命和自我关注还是他们 - 他们都胜过我们，

588
00:26:50,695 --> 00:26:52,675
on, on, on, on, bits per dimension.
on，on，on，on，bits per dimension。

589
00:26:52,675 --> 00:26:54,310
So we were measuring perplexity because these are
所以我们正在测量困惑，因为这些是

590
00:26:54,310 --> 00:26:56,560
probabilistic- these are probabilistic models.
概率 - 这些是概率模型。

591
00:26:56,560 --> 00:26:58,675
It's like basically a language model of images and,
这就像基本上是图像的语言模型，

592
00:26:58,675 --> 00:27:01,120
and it just- and your- and the factorization
它只是 - 和你 - 以及因子分解

593
00:27:01,120 --> 00:27:03,580
of your language model just depends on how you rasterize.
你的语言模型只取决于你如何栅格化。

594
00:27:03,580 --> 00:27:05,620
In the- in this- in the one-D rasterization,
在这里 - 在一维光栅化中，

595
00:27:05,620 --> 00:27:07,000
we went first rows and then columns.
我们先行，然后是列。

596
00:27:07,000 --> 00:27:08,185
In the two-D rasterization,
在二维光栅化中，

597
00:27:08,185 --> 00:27:11,155
we went blockwise and inside each block we rasterized.
我们走向块状，在每个块内部进行栅格化。

598
00:27:11,155 --> 00:27:14,650
On ImageNet, we achieved better perplexities, and,
在ImageNet上，我们实现了更好的困惑，并且，

599
00:27:14,650 --> 00:27:18,775
uh, so yeah, I mean we're at a GAN level, right?
呃，是的，我的意思是我们处于GAN水平，对吧？

600
00:27:18,775 --> 00:27:23,694
I mean this weird- this is- I think probabilist auto-regressive Image generation,
我的意思是这很奇怪 - 这是 - 我认为概率论自动回归图像生成，

601
00:27:23,694 --> 00:27:26,725
uh, by this point had not reached GANs.
呃，到目前为止还没有达到GAN。

602
00:27:26,725 --> 00:27:31,090
At ICLR 2019, there's a paper by Nal that actually uses self-attention and gets very,
在ICLR 2019年，纳尔的一篇论文实际上使用了自我关注并得到了非常的，

603
00:27:31,090 --> 00:27:32,575
very good quality images.
质量非常好的图像。

604
00:27:32,575 --> 00:27:34,705
But what we, what we observed was,
但我们所观察到的是，

605
00:27:34,705 --> 00:27:36,670
we were getting structured objects fairly well.
我们得到的结构化对象相当不错。

606
00:27:36,670 --> 00:27:39,930
Like can people recognize what the second row is?
人们可以认识到第二排是什么吗？

607
00:27:39,930 --> 00:27:43,770
Cars. [OVERLAPPING]
汽车。 [重叠]

608
00:27:43,770 --> 00:27:46,050
I heard- I said- most- almost everyone said cars.
我听说 - 我说 - 大多数 - 几乎每个人都说汽车。

609
00:27:46,050 --> 00:27:48,720
I'm not going to ask who said something else, but yes, they're cars.
我不打算问谁说了什么，但是，是的，他们是汽车。

610
00:27:48,720 --> 00:27:53,350
yeah. And, uh, so the- and the last row is another vehicles like,
是的。而且，呃，所以 - 和最后一排是另一种车辆，如，

611
00:27:53,350 --> 00:27:58,330
uh, so essentially when structured jo- structured objects were easy to capture.
呃，基本上当结构化的jo-structured对象很容易被捕获时。

612
00:27:58,330 --> 00:28:01,165
Um, like frogs and sort of,
嗯，像青蛙一样，

613
00:28:01,165 --> 00:28:04,150
you know, objects that were camouflaged just turned into this mush.
你知道，被伪装的物体变成了这种糊状物。

614
00:28:04,150 --> 00:28:07,090
Um, and- but on super resolution,
嗯，而且 - 但是超级分辨率，

615
00:28:07,090 --> 00:28:08,650
now super-resolution is interesting because
现在超级分辨率很有意思，因为

616
00:28:08,650 --> 00:28:10,375
there's a lot of conditioning information, right?
有很多条件信息，对吧？

617
00:28:10,375 --> 00:28:13,525
And, uh, when you have a lot of conditioning information, the,
而且，呃，当你有很多调理信息时，

618
00:28:13,525 --> 00:28:15,520
the sort of possible- you break- you,
那种可能 - 你打破了你，

619
00:28:15,520 --> 00:28:17,905
you actually lock quite a few of the modes.
你实际上锁定了很多模式。

620
00:28:17,905 --> 00:28:20,020
So there's only a few options you can have at the output.
因此，输出中只有几个选项。

621
00:28:20,020 --> 00:28:22,390
And super- our super resolution results are much better.
超级 - 我们的超分辨率结果要好得多。

622
00:28:22,390 --> 00:28:26,770
We were able to get better facial orientation and structure than previous work.
我们能够比以前的工作获得更好的面部定位和结构。

623
00:28:26,770 --> 00:28:31,390
And these are samples at different temperatures and, uh, and, uh,
这些是不同温度下的样品，呃，呃，

624
00:28:31,390 --> 00:28:34,690
and we wou- when we quantify this with actual human evaluators,
当我们用实际的人类评估者量化这个时，我们

625
00:28:34,690 --> 00:28:36,160
we- like we flash an image and said,
我们 - 就像我们闪现一个图像说，

626
00:28:36,160 --> 00:28:37,345
is this real, is this false?
这是真的吗，这是假的吗？

627
00:28:37,345 --> 00:28:38,630
And we were able to, uh,
我们能够，呃，

628
00:28:38,630 --> 00:28:40,750
we were able to fool humans like four
我们能像四个人一样愚弄人类

629
00:28:40,750 --> 00:28:43,285
times better than previous results in super resolution.
比以前的超分辨率结果更好。

630
00:28:43,285 --> 00:28:46,990
Again, these are not- these results like I, I guess the,
再次，这些不是 - 这些结果像我，我想，

631
00:28:46,990 --> 00:28:50,470
the latest GAN result from Nvidia makes us look like a joke.
来自Nvidia的最新GAN结果让我们看起来像个笑话。

632
00:28:50,470 --> 00:28:51,715
But, I mean this is,
但是，我的意思是，

633
00:28:51,715 --> 00:28:53,050
I mean, we're starting later than GAN.
我的意思是，我们的起步晚于GAN。

634
00:28:53,050 --> 00:28:54,130
So hopefully we'll catch up.
所以希望我们能赶上来。

635
00:28:54,130 --> 00:28:57,250
But, but the point here is that this is an interesting inductive bias for images,
但是，这里的重点是，这是图像的一个有趣的归纳偏见，

636
00:28:57,250 --> 00:28:59,500
so very natural inductive bias for images.
对图像非常自然的归纳偏差。

637
00:28:59,500 --> 00:29:01,375
Um, and, uh, and,
嗯，呃，和，

638
00:29:01,375 --> 00:29:05,650
and there is hope to apply it- for applying in classification and other such tasks also.
并且有希望将其应用于分类和其他此类任务。

639
00:29:05,650 --> 00:29:07,450
Um, so one interesting thing,
嗯，这是一件有趣的事，

640
00:29:07,450 --> 00:29:09,640
just to sort of both out of curiosity and
只是出于好奇和好奇

641
00:29:09,640 --> 00:29:12,745
asking how good is maximum or like does maximum likelihood.
询问最大可能性有多好或最大可能性。

642
00:29:12,745 --> 00:29:16,180
Well, one, does the model actually capture some interesting structure in the role?
嗯，其中一个，模型实际上是否捕获了角色中的一些有趣结构？

643
00:29:16,180 --> 00:29:17,650
Second, do you get diversity?
第二，你有多样性吗？

644
00:29:17,650 --> 00:29:19,540
Well, maximum likelihood should get diversity,
那么，最大可能性应该是多样性，

645
00:29:19,540 --> 00:29:21,955
by, by virtue, by virtue of what it does.
通过，凭借它所做的一切。

646
00:29:21,955 --> 00:29:23,860
Uh, so then we just- we did image completion.
呃，那么我们只是 - 我们做了图像完成。

647
00:29:23,860 --> 00:29:25,870
And why is- why image completion because as soon as you
为什么 - 为什么图像完成，因为只要你

648
00:29:25,870 --> 00:29:28,000
lock down half the image to the goal truth,
将图像的一半锁定到目标真相，

649
00:29:28,000 --> 00:29:30,610
you're actually shaving off a lot of the possible modes.
你实际上正在削减很多可能的模式。

650
00:29:30,610 --> 00:29:32,230
So you have a much easier time sampling.
因此，您可以更轻松地抽样。

651
00:29:32,230 --> 00:29:34,090
So, uh, so the first is,
所以，呃，首先是，

652
00:29:34,090 --> 00:29:35,935
uh, first is what we supply to the model.
呃，首先是我们为模型提供的东西。

653
00:29:35,935 --> 00:29:38,785
The, the, the right row- the right most column is,
右边的行 - 最右边的列是，

654
00:29:38,785 --> 00:29:41,155
is gold, and we were able to generate different samples.
是黄金，我们能够生成不同的样本。

655
00:29:41,155 --> 00:29:43,270
But what was really interesting is the third row.
但真正有趣的是第三排。

656
00:29:43,270 --> 00:29:46,180
Uh, so the rightmost column is- the rightmost column is gold.
呃，所以最右边的列是 - 最右边的列是金。

657
00:29:46,180 --> 00:29:48,655
Uh, now if you look at the third row, this horse.
呃，现在如果你看第三排，这匹马。

658
00:29:48,655 --> 00:29:52,135
So actually there's this sort of glimpse or a suggestion of a pull,
所以实际上有这种瞥见或建议拉，

659
00:29:52,135 --> 00:29:55,045
but the model hallucinated a human in some of these,
但这些模特在其中一些人中产生了幻觉，

660
00:29:55,045 --> 00:29:56,170
in some of these images,
在其中一些图像中，

661
00:29:56,170 --> 00:29:58,450
which is interesting like in- it does capture at least
这很有意思，因为它至少可以捕获它

662
00:29:58,450 --> 00:30:02,230
the data teaches it to capture some structure about the world.
数据教会它捕捉一些关于世界的结构。

663
00:30:02,230 --> 00:30:06,190
Um, the dog is just cute and I guess it also shows that, you know,
嗯，狗很可爱，我猜它也表明，你知道，

664
00:30:06,190 --> 00:30:07,480
there was this entire object,
有这整个对象，

665
00:30:07,480 --> 00:30:10,660
this chair, that the model just completely refused to imagine.
这把椅子，模型完全拒绝想象。

666
00:30:10,660 --> 00:30:12,835
So there's a lot of difficulty.
所以有很多困难。

667
00:30:12,835 --> 00:30:15,070
And I guess Anna is gonna talk about
而且我想安娜会谈论

668
00:30:15,070 --> 00:30:19,465
[NOISE] the another way to exploit self- self-similarity.
[NOISE]利用自我相似性的另一种方式。

669
00:30:19,465 --> 00:30:20,080
Thank you.
谢谢。

670
00:30:20,080 --> 00:30:31,600
[APPLAUSE]
[掌声]

671
00:30:31,600 --> 00:30:34,060
So thank you Ashish for the introduction.
谢谢Ashish的介绍。

672
00:30:34,060 --> 00:30:37,105
Uh, so there's a lot of self-similarity in images.
呃，所以图像中有很多自相似之处。

673
00:30:37,105 --> 00:30:39,460
There's also a lot of self-similarity in, in music.
在音乐方面也有很多自相似之处。

674
00:30:39,460 --> 00:30:43,180
So we can imagine, transformer being a, a good model for it.
所以我们可以想象，变压器是一个很好的模型。

675
00:30:43,180 --> 00:30:46,060
Uh, we- we're going to show how,
呃，我们 - 我们将展示如何，

676
00:30:46,060 --> 00:30:48,100
uh, we can add more to,
呃，我们可以添加更多，

677
00:30:48,100 --> 00:30:50,350
to the self attention, to think more about kind of
要自我关注，要多考虑一下

678
00:30:50,350 --> 00:30:54,220
relational information and how that could help, uh, music generation.
关系信息以及它如何帮助，呃，音乐的产生。

679
00:30:54,220 --> 00:30:57,160
[NOISE] So, uh, first I want to
[NOISE]所以，呃，首先我想

680
00:30:57,160 --> 00:31:01,225
clarify what is the raw representation that we're working with right now.
澄清我们现在正在使用的原始表示形式。

681
00:31:01,225 --> 00:31:03,280
So analogous to language,
所以类似于语言，

682
00:31:03,280 --> 00:31:07,060
you can think about there's text and somebody is reading out a text,
你可以考虑有文字，有人正在读出文字，

683
00:31:07,060 --> 00:31:09,430
so they add their kind of own intonations to it,
所以他们为它添加了自己的语调，

684
00:31:09,430 --> 00:31:12,385
and then you have sound waves coming out of that speech.
然后你就会发出声音。

685
00:31:12,385 --> 00:31:16,100
So for music there's a va- very similar kind of, uh,
所以对于音乐来说，有一种非常类似的，呃，

686
00:31:16,100 --> 00:31:21,270
line of a generation where you say the composer has an idea,
你说作曲家有想法的一代人的路线，

687
00:31:21,270 --> 00:31:23,355
uh, writes down the score and then,
呃，写下分数，然后，

688
00:31:23,355 --> 00:31:25,575
a performer performs it and then you get sound.
表演者执行它然后你得到声音。

689
00:31:25,575 --> 00:31:29,535
So what we're going to focus on today is mostly, uh,
那么我们今天要关注的主要是，呃，

690
00:31:29,535 --> 00:31:31,410
you can think of the score but it's actually,
你可以想到得分，但事实上，

691
00:31:31,410 --> 00:31:34,075
er, a performance, um,
呃，表演，嗯，

692
00:31:34,075 --> 00:31:41,545
in that it's a symbolic representation where MIDI pianos were used and,
因为它是使用MIDI钢琴的符号表示，

693
00:31:41,545 --> 00:31:44,065
uh, um, professional amateur, uh,
呃，呃，专业的业余爱好者，呃，

694
00:31:44,065 --> 00:31:46,645
musicians were performing on the pianos.
音乐家们正在钢琴上表演。

695
00:31:46,645 --> 00:31:47,890
So we have the recorded,
所以我们有记录，

696
00:31:47,890 --> 00:31:49,660
uh, information of their playing.
呃，他们演奏的信息。

697
00:31:49,660 --> 00:31:51,295
So in particular, um,
特别是，嗯，

698
00:31:51,295 --> 00:31:55,810
at each time se- step modeling music as this sequential, uh,
每次将音乐建模为顺序，呃，

699
00:31:55,810 --> 00:31:58,720
process, what is being output are, okay,
过程，输出的是什么，好吧，

700
00:31:58,720 --> 00:32:00,145
turn this note on, ah,
转过这张便条啊，

701
00:32:00,145 --> 00:32:01,960
advance the clock by this much,
这么多推进时钟，

702
00:32:01,960 --> 00:32:03,220
and then turn this note off.
然后关闭此笔记。

703
00:32:03,220 --> 00:32:05,965
And also there is, uh, dynamics information,
还有，呃，动态信息，

704
00:32:05,965 --> 00:32:07,660
so when you turn the note on, you first say like,
所以当你打开音符时，首先要说的是，

705
00:32:07,660 --> 00:32:09,985
how loud it's going to be.
会有多大声。

706
00:32:09,985 --> 00:32:13,090
Uh, so traditionally, uh, modeling, uh,
呃，传统上，呃，造型，呃，

707
00:32:13,090 --> 00:32:15,085
music as kind of a language,
音乐作为一种语言，

708
00:32:15,085 --> 00:32:18,130
we've been using, uh, recurrent neural networks.
我们一直在使用，呃，递归神经网络。

709
00:32:18,130 --> 00:32:23,350
And, um, because as Ashish introduced and, and talked about,
而且，嗯，因为正如Ashish介绍的那样，并且谈到了，

710
00:32:23,350 --> 00:32:25,510
there is a lot of compression that needs to happen,
需要进行大量压缩，

711
00:32:25,510 --> 00:32:29,830
like a long sequence has to be embedded into like a fixed length vector.
像长序列一样必须嵌入到固定长度的矢量中。

712
00:32:29,830 --> 00:32:32,200
And that becomes hard when, uh,
当，呃，这变得很难

713
00:32:32,200 --> 00:32:35,200
in music you have- you have repetition coming,
在你的音乐中 - 你有重复的到来，

714
00:32:35,200 --> 00:32:37,150
um, at a distance.
嗯，远处。

715
00:32:37,150 --> 00:32:39,490
So, uh, I'm first going to show you,
所以，呃，我首先要告诉你，

716
00:32:39,490 --> 00:32:43,270
um, samples from, from the RNNs,
嗯，来自RNN的样本，

717
00:32:43,270 --> 00:32:46,450
from a transformer and then from a music transformer that has
从一个变压器，然后从一个音乐变压器

718
00:32:46,450 --> 00:32:48,580
the relative attention and kind of let you hear
让你听到的相对关注和善意

719
00:32:48,580 --> 00:32:51,970
the differences and then I'll go into how we,
差异然后我会进入我们的方式，

720
00:32:51,970 --> 00:32:54,580
uh, what are, what are the, uh,
呃，什么，有什么，呃，

721
00:32:54,580 --> 00:32:58,660
modifications we needed to do on top of the, uh, transformer model.
我们需要在变压器模型上进行修改。

722
00:32:58,660 --> 00:33:00,745
Uh, so here, uh,
呃，所以在这里，呃，

723
00:33:00,745 --> 00:33:03,295
this task is kind of the image completion task.
此任务是一种图像完成任务。

724
00:33:03,295 --> 00:33:08,335
So we give it an initial motif and then we ask the model to do continuations.
所以我们给它一个初始主题，然后我们要求模型做延续。

725
00:33:08,335 --> 00:33:10,660
So this is the motif that we fed.
所以这就是我们喂养的主题。

726
00:33:10,660 --> 00:33:16,225
[MUSIC] How many people recognize that?
[音乐]有多少人认识到了这一点？

727
00:33:16,225 --> 00:33:19,090
Awesome. Okay. [LAUGHTER] Yeah,
真棒。好的。 [大笑]是的，

728
00:33:19,090 --> 00:33:20,380
so this is a, uh,
所以这是一个，呃，

729
00:33:20,380 --> 00:33:22,900
kind of a fragment from a Chopin Etude piece.
肖邦练习曲片中的片段。

730
00:33:22,900 --> 00:33:24,910
And we're going to ask, uh,
我们要问，呃，

731
00:33:24,910 --> 00:33:26,680
the RNN to do a continuation.
RNN继续做下去。

732
00:33:26,680 --> 00:33:34,990
[NOISE]
[噪声]

733
00:33:34,990 --> 00:33:48,325
[MUSIC]
[音乐]

734
00:33:48,325 --> 00:33:50,950
So in here, like in the beginning, it was trying to repeat it.
所以在这里，就像在开始时一样，它试图重复它。

735
00:33:50,950 --> 00:33:52,330
But very fast, it, er,
但是，非常快，呃，

736
00:33:52,330 --> 00:33:55,870
wandered off into, its other different ideas.
徘徊，其他不同的想法。

737
00:33:55,870 --> 00:33:58,120
So that's one challenge because it's, uh,
所以这是一个挑战，因为它是，呃，

738
00:33:58,120 --> 00:34:01,705
not able to directly look back to what happened in the past, uh, and,
不能直接回顾过去发生的事情，呃，和

739
00:34:01,705 --> 00:34:04,060
and can just look at kind of a blu- blurry version,
并且可以看一下蓝色模糊的版本，

740
00:34:04,060 --> 00:34:06,400
and that blurry version becomes more and more blurry.
而模糊的版本变得越来越模糊。

741
00:34:06,400 --> 00:34:08,455
Uh, so this is what the transformer does.
呃，这就是变压器所做的。

742
00:34:08,455 --> 00:34:10,990
Uh, so so, uh, a detail is, uh,
呃，是这样，呃，细节是，呃，

743
00:34:10,990 --> 00:34:14,455
these models are trained on half the length that you're hearing.
这些模型的训练长度是你听到的一半。

744
00:34:14,455 --> 00:34:18,760
So we're kinda asking the model to generalize beyond the length that it's trained on.
因此，我们有点要求模型概括超出它训练的长度。

745
00:34:18,760 --> 00:34:20,170
And you can see for this transformer,
你可以看到这个变压器，

746
00:34:20,170 --> 00:34:22,285
it, it deteriorates beyond that.
它，它已经恶化了。

747
00:34:22,285 --> 00:34:25,150
But it can hold the motif pretty consistent.
但它可以保持这个主题非常一致。

748
00:34:25,150 --> 00:34:34,690
[MUSIC] Okay. You, you,
[音乐]好的。你，你，

749
00:34:34,690 --> 00:34:35,770
you ge- you get the idea.
你知道了 - 你明白了。

750
00:34:35,770 --> 00:34:40,690
[LAUGHTER] So initially, it was able to do this repetition really well.
[笑声]所以最初，它能够很好地完成这个重复。

751
00:34:40,690 --> 00:34:42,400
Uh, so it was able to copy it very well.
呃，所以能够很好地复制它。

752
00:34:42,400 --> 00:34:44,170
But beyond the length that was trained on,
但超出训练的长度，

753
00:34:44,170 --> 00:34:47,440
it kinda didn't know how to cope with, like longer contexts.
它有点不知道如何处理，像更长的背景。

754
00:34:47,440 --> 00:34:48,880
And, uh, what you see,
而且，呃，你看到的，

755
00:34:48,880 --> 00:34:51,325
uh, the, the last one is from the music transformer.
呃，最后一个来自音乐变换器。

756
00:34:51,325 --> 00:34:53,350
I think so that kind of [NOISE] the relational information.
我认为那种[NOISE]关系信息。

757
00:34:53,350 --> 00:34:56,470
And you can just see visually how it's very consistent and kinda
你可以直观地看到它是如何非常一致和有点

758
00:34:56,470 --> 00:34:59,940
repeating these [NOISE] these larger, uh, arcs.
重复这些[噪音]这些更大的呃弧线。

759
00:34:59,940 --> 00:35:21,190
[MUSIC]
[音乐]

760
00:35:21,190 --> 00:35:23,815
Yeah. So that was, uh, music transformer.
是啊。那就是，呃，音乐变换器。

761
00:35:23,815 --> 00:35:27,070
And so in music,
在音乐中，

762
00:35:27,070 --> 00:35:30,415
the, the self similarity that we talked about, uh,
我们谈到的自相似性，呃，

763
00:35:30,415 --> 00:35:31,765
so we see, uh,
所以我们看到了，呃，

764
00:35:31,765 --> 00:35:32,950
the motif here, and so,
这里的主题，等等，

765
00:35:32,950 --> 00:35:35,005
so there we primed the model with a motif,
所以我们用一个图案引导模型，

766
00:35:35,005 --> 00:35:36,445
and this is actually a sample,
这实际上是一个样本，

767
00:35:36,445 --> 00:35:37,870
unconditioned sample from the model.
来自模型的无条件样本。

768
00:35:37,870 --> 00:35:40,690
So nothing, er, there was no priming that the, uh,
没什么，呃，没有启动，呃，

769
00:35:40,690 --> 00:35:42,880
model kinda had to create its own motif and then,
模特有点必须创造自己的主题，然后，

770
00:35:42,880 --> 00:35:45,115
uh, do, uh, continuations from there.
呃，做，呃，那里的延续。

771
00:35:45,115 --> 00:35:49,210
And here, uh, if we kinda look at it and analyze it a bit, you see,
在这里，呃，如果我们看一下它并稍微分析一下，你看，

772
00:35:49,210 --> 00:35:51,805
uh, a lot of repetition,
呃，很多重复，

773
00:35:51,805 --> 00:35:54,040
uh, with gaps in between.
呃，两者之间存在差距。

774
00:35:54,040 --> 00:35:56,635
And if you look at the self attention structure,
如果你看看自我关注结构，

775
00:35:56,635 --> 00:35:58,870
we actually do see the model,
我们确实看到了模型，

776
00:35:58,870 --> 00:36:00,625
uh, looking at the relevant parts.
呃，看看相关部分。

777
00:36:00,625 --> 00:36:04,075
Even if, if it was not immediately, uh, preceding it.
即使，如果它不是立即，呃，在它之前。

778
00:36:04,075 --> 00:36:05,500
So, so here, uh,
所以，在这里，呃，

779
00:36:05,500 --> 00:36:09,970
what I colored shaded out is where the motif, um, occurs.
我涂上阴影的是主题，嗯，发生的地方。

780
00:36:09,970 --> 00:36:11,830
Uh, and you can, uh, see the different colors,
呃，你可以，呃，看到不同的颜色，

781
00:36:11,830 --> 00:36:14,710
there's a different attention heads and they're kinda focusing,
有一个不同的注意力头，他们有点专注，

782
00:36:14,710 --> 00:36:16,810
uh, among those, uh, grayed out sections.
呃，其中，呃，灰色的部分。

783
00:36:16,810 --> 00:36:19,750
[NOISE] So I'll play the sample and we also have
[NOISE]所以我会播放样本，我们也有

784
00:36:19,750 --> 00:36:23,695
a visualization that kind of shows you as the music is pa- uh,
一种可视化，可以将您视为音乐，

785
00:36:23,695 --> 00:36:28,930
is being played or what notes it was attending to as it was predicting that note.
正在播放或正在播放的音符，因为它正在预测该音符。

786
00:36:28,930 --> 00:36:31,150
And, uh, this was generated from scratch.
而且，呃，这是从头开始生成的。

787
00:36:31,150 --> 00:36:33,880
And, uh, so the self attention is, um,
而且，呃，所以自我关注是，嗯，

788
00:36:33,880 --> 00:36:37,270
from, from kind of note to note level or event to event level.
从，从注意级别或事件到事件级别。

789
00:36:37,270 --> 00:36:39,325
So it's, it's quite low level.
所以它是，它的水平相当低。

790
00:36:39,325 --> 00:36:40,975
Uh, so when you look at it, it's,
呃，所以当你看着它时，它是

791
00:36:40,975 --> 00:36:42,655
it's ki- a little bit overwhelming.
这有点压倒性的。

792
00:36:42,655 --> 00:36:44,350
It has like multiple heads and,
它有多个头，

793
00:36:44,350 --> 00:36:45,925
er, a lot of things moving.
呃，很多东西在动。

794
00:36:45,925 --> 00:36:47,950
Uh, but there's kind of these structural moments
呃，但是有一些结构性的时刻

795
00:36:47,950 --> 00:36:50,275
where you would kind of see more of this, uh,
在哪里你会看到更多这个，呃，

796
00:36:50,275 --> 00:36:52,795
clean, uh, kind of,
干净，呃，有点，

797
00:36:52,795 --> 00:36:55,270
uh, sections where it's attending to.
呃，它所关注的部分。

798
00:36:55,270 --> 00:37:52,390
[MUSIC]
[音乐]

799
00:37:52,390 --> 00:37:53,710
VOkay. So, um,
VOkay。那么，嗯，

800
00:37:53,710 --> 00:37:55,690
how, how did we do that?
怎么样，我们是怎么做到的？

801
00:37:55,690 --> 00:37:59,440
And so starting from kind of the the regular attention mechanism,
从一般的注意机制开始，

802
00:37:59,440 --> 00:38:02,695
we know it's, uh, a weighted average of the past history.
我们知道，呃，过去历史的加权平均值。

803
00:38:02,695 --> 00:38:04,690
Uh, and the nice thing is, uh,
呃，好的是，呃，

804
00:38:04,690 --> 00:38:07,165
however far it is, we have direct access to it.
无论如何，我们可以直接访问它。

805
00:38:07,165 --> 00:38:08,845
So if we know, uh,
如果我们知道，呃，

806
00:38:08,845 --> 00:38:10,870
there are kind of motifs that occurred,
发生了一些图案，

807
00:38:10,870 --> 00:38:13,000
uh, in in early on in the piece,
呃，早在片中，

808
00:38:13,000 --> 00:38:15,385
we're still able to based on, uh,
我们仍然可以基于，呃，

809
00:38:15,385 --> 00:38:17,080
the fact that things that are similar,
事情是相似的，

810
00:38:17,080 --> 00:38:19,240
uh, to be able to retrieve those.
呃，能够找回那些。

811
00:38:19,240 --> 00:38:22,915
Um, but, uh, it also becomes,
嗯，但是，呃，它也变成了，

812
00:38:22,915 --> 00:38:25,030
all the past becomes kind of a bag of words,
所有的过去都成了一堆文字，

813
00:38:25,030 --> 00:38:27,310
like there is no structure of which came,
就像没有结构，

814
00:38:27,310 --> 00:38:28,570
uh, before or after.
呃，之前或之后。

815
00:38:28,570 --> 00:38:31,195
So there's the positional sinusoids that Ashish talked about.
所以Ashish谈到的是位置正弦曲线。

816
00:38:31,195 --> 00:38:33,595
That, uh, basically in this, uh,
那个，呃，基本上就是这个，呃，

817
00:38:33,595 --> 00:38:38,395
indices indexes into a sinusoids that are moving at different speeds.
指数指向以不同速度移动的正弦曲线。

818
00:38:38,395 --> 00:38:40,645
And so close-by positions would have, uh,
所以附近的职位会有，呃，

819
00:38:40,645 --> 00:38:42,160
a very similar kind of, uh,
一种非常相似的，呃，

820
00:38:42,160 --> 00:38:45,680
cross section into those multiple sinusoids.
横截面成多个正弦曲线。

821
00:38:46,320 --> 00:38:48,805
Uh, in contrast for, er,
呃，相比之下，呃，

822
00:38:48,805 --> 00:38:50,920
for convolutions, you kinda have this, uh,
对于卷积，你有点这个，呃，

823
00:38:50,920 --> 00:38:54,940
fixed filter that's moving around that captures the relative distance.
移动的固定过滤器捕获相对距离。

824
00:38:54,940 --> 00:38:56,875
Like 1B4, 2B4.
像1B4,2B4。

825
00:38:56,875 --> 00:38:59,185
And these are kind of, uh,
这些都是，呃，

826
00:38:59,185 --> 00:39:02,935
in some ways like a rigid structure that allows you to be, uh,
在某些方面，像一个刚性的结构，让你成为，呃，

827
00:39:02,935 --> 00:39:04,925
a kind of, uh, bring in the,
一种，呃，带来的，

828
00:39:04,925 --> 00:39:07,440
the distance information very explicitly.
距离信息非常明确。

829
00:39:07,440 --> 00:39:10,770
Um, you can imagine relative attention, um,
嗯，你可以想象相对的关注，嗯，

830
00:39:10,770 --> 00:39:13,080
with the multiple heads, uh, at play,
多头，呃，在玩耍，

831
00:39:13,080 --> 00:39:15,395
uh, to be some combination of these.
呃，成为这些的组合。

832
00:39:15,395 --> 00:39:17,170
So, uh, on one hand,
所以，呃，一方面，

833
00:39:17,170 --> 00:39:18,580
you can access, uh,
你可以访问，呃，

834
00:39:18,580 --> 00:39:20,485
the the history very directly.
历史非常直接。

835
00:39:20,485 --> 00:39:22,510
On the other hand, you also know, er,
另一方面，你也知道，呃，

836
00:39:22,510 --> 00:39:25,210
how you rel- relate to this history.
你如何与这段历史联系起来。

837
00:39:25,210 --> 00:39:26,860
Uh, capturing for example,
呃，捕捉，例如，

838
00:39:26,860 --> 00:39:29,575
like translational invariance and, er,
像翻译不变性，呃，

839
00:39:29,575 --> 00:39:32,440
and we, uh, and for example,
而我们，呃，等等，

840
00:39:32,440 --> 00:39:35,455
we think one of the reasons why in the beginning, uh,
我们认为一开始的原因之一，呃，

841
00:39:35,455 --> 00:39:38,830
priming samples that you heard that the, uh,
启动样品你听说过，呃，

842
00:39:38,830 --> 00:39:40,945
music transformer was able to generate
音乐变压器能够产生

843
00:39:40,945 --> 00:39:43,735
beyond the length that it was trained on at a very coherent way,
超出它以非常连贯的方式训练的长度，

844
00:39:43,735 --> 00:39:47,830
is that it's able to kind of rely on this translational invariance to to carry,
它是否能够依赖这种平移不变性来携带，

845
00:39:47,830 --> 00:39:50,785
uh, the relational information forward.
呃，关系信息向前发展。

846
00:39:50,785 --> 00:39:55,000
So, if we take a closer look at how how how the,
所以，如果我们仔细看看如何如何，

847
00:39:55,000 --> 00:39:56,545
how this works is, uh,
这是如何工作的，呃，

848
00:39:56,545 --> 00:39:58,540
the regular transformer you have,
你有常规变压器，

849
00:39:58,540 --> 00:40:00,250
you compare all the queries and keys,
你比较所有的查询和密钥，

850
00:40:00,250 --> 00:40:02,260
so you get kind of this, uh, square matrix.
所以你得到了这个，呃，方阵。

851
00:40:02,260 --> 00:40:04,390
You can think of it as like a self similarity,
你可以把它想象成一种自相似性，

852
00:40:04,390 --> 00:40:06,010
uh, matrix, so it's, uh, a square.
呃，矩阵，所以它是，呃，一个正方形。

853
00:40:06,010 --> 00:40:08,890
Uh, what relative attention does is,
呃，相对注意力是什么，

854
00:40:08,890 --> 00:40:12,355
to add an additional term that thinks, uh,
添加一个认为的额外术语，呃，

855
00:40:12,355 --> 00:40:14,530
that thinks about whenever you're comparing two things,
每当你比较两件事时都会想到

856
00:40:14,530 --> 00:40:16,210
how far are you apart?
你有多远？

857
00:40:16,210 --> 00:40:18,820
And also based on the content, do I,
而且还根据内容，我，

858
00:40:18,820 --> 00:40:21,340
do I care about things that are two steps away or
我是否关心两步之遥的事情

859
00:40:21,340 --> 00:40:24,175
three steps away or I maybe care about things that are recurring,
三步走了或者我可能关心经常发生的事情，

860
00:40:24,175 --> 00:40:26,275
at kind of a periodical distance.
在某种周期性的距离。

861
00:40:26,275 --> 00:40:29,305
And, uh, with that information gathered,
而且，呃，收集到的信息，

862
00:40:29,305 --> 00:40:33,835
that influences, uh, the the similarity between positions.
这影响，呃，位置之间的相似性。

863
00:40:33,835 --> 00:40:35,815
And in particular, uh,
特别是，呃，

864
00:40:35,815 --> 00:40:39,460
this extra term is based on, um, the distance.
这个额外的术语是基于，嗯，距离。

865
00:40:39,460 --> 00:40:40,510
So you wanna, uh,
所以你想，呃，

866
00:40:40,510 --> 00:40:41,950
gather the embeddings, uh,
收集嵌入物，呃，

867
00:40:41,950 --> 00:40:44,500
that's irrelevant to the, uh,
这与呃无关，呃，

868
00:40:44,500 --> 00:40:46,180
the query key distances,
查询关键距离，

869
00:40:46,180 --> 00:40:49,285
uh, on the [NOISE] on the logits.
呃，在logits上的[NOISE]上。

870
00:40:49,285 --> 00:40:51,715
So, in translation, this,
所以，在翻译中，这个，

871
00:40:51,715 --> 00:40:53,230
uh, has shown, uh,
呃，已经表明，呃，

872
00:40:53,230 --> 00:40:55,015
a lot of improvement in,
很多改进，

873
00:40:55,015 --> 00:40:57,730
um, for example English to to German translation.
嗯，例如英语到德语翻译。

874
00:40:57,730 --> 00:41:00,010
Uh, but in translation,
呃，但在翻译中，

875
00:41:00,010 --> 00:41:01,765
the sequences are usually quite short.
序列通常很短。

876
00:41:01,765 --> 00:41:03,415
It's only a sentence to sentence.
这只是判刑的句子。

877
00:41:03,415 --> 00:41:05,110
Uh, a translation for example,
呃，翻译，例如，

878
00:41:05,110 --> 00:41:07,210
maybe 50 words or 100 words.
也许50个单词或100个单词。

879
00:41:07,210 --> 00:41:12,010
But the music, er, samples that you've heard are in the range of 2,000 time-steps.
但是，您听过的音乐呃样本的时间步长为2,000。

880
00:41:12,010 --> 00:41:16,015
So it's like 2,000 tokens need to be able to fit in memory.
所以它就像2,000个令牌需要能够适应内存。

881
00:41:16,015 --> 00:41:17,500
So this was a problem, uh,
所以这是一个问题，呃，

882
00:41:17,500 --> 00:41:23,350
because the original formulation relied on building this 3D tensor that's,
因为原来的配方依赖于构建这个3D张量，

883
00:41:23,350 --> 00:41:25,795
uh, that's very large in memory.
呃，记忆力非常大。

884
00:41:25,795 --> 00:41:27,715
Um, and and why this is the case?
嗯，为什么会这样呢？

885
00:41:27,715 --> 00:41:30,055
It's because for every pair,
这是因为对于每一对，

886
00:41:30,055 --> 00:41:32,710
uh, you look up what the,
呃，你抬头看看，

887
00:41:32,710 --> 00:41:35,200
what the re- so you can compute what the relative distance is,
什么，你可以计算相对距离是什么，

888
00:41:35,200 --> 00:41:38,320
and then you look up an embedding that corresponds to that distance.
然后你查找一个与该距离相对应的嵌入。

889
00:41:38,320 --> 00:41:43,540
So, um, for like this there's a length by length, like L by L, uh, matrix.
所以，嗯，因为这样的长度有长度，比如L by L，呃，矩阵。

890
00:41:43,540 --> 00:41:44,815
You need like, uh,
你需要，呃，

891
00:41:44,815 --> 00:41:47,635
to collect embeddings for each of the positions and that's, uh,
收集每个职位的嵌入，那是，呃，

892
00:41:47,635 --> 00:41:51,070
depth D. So that gives us the 3D.
深度D.这样就给了我们3D。

893
00:41:51,070 --> 00:41:52,900
What we realized is,
我们意识到的是，

894
00:41:52,900 --> 00:41:58,480
you can actually just directly multiply the queries and the embedding distances.
实际上你可以直接乘以查询和嵌入距离。

895
00:41:58,480 --> 00:42:00,670
[NOISE] And they, uh,
[NOISE]他们，呃，

896
00:42:00,670 --> 00:42:02,080
come out kind of in a different order,
出来的有点不同，

897
00:42:02,080 --> 00:42:04,630
because now you have the queries ordered by a relative distance,
因为现在你有相对距离排序的查询，

898
00:42:04,630 --> 00:42:07,930
but you need the queries ordered by keys, uh,
但你需要按键排序的查询，呃，

899
00:42:07,930 --> 00:42:11,440
which is kind of a absolute by absolute, uh, configuration.
绝对的，呃，配置是绝对的。

900
00:42:11,440 --> 00:42:13,360
So what we could do is just, uh,
所以我们能做的就是，呃，

901
00:42:13,360 --> 00:42:16,705
do a series of skewing, uh,
做一系列的歪斜，呃，

902
00:42:16,705 --> 00:42:20,515
to to put it into the right, uh, configuration.
把它放到右边，呃，配置。

903
00:42:20,515 --> 00:42:23,875
And this is, uh, yeah.
这是，呃，是的。

904
00:42:23,875 --> 00:42:25,570
Just a, just a quick contrast to,
只是一个，只是一个快速对比，

905
00:42:25,570 --> 00:42:28,480
to show, um, the difference in memory requirements.
显示，嗯，内存要求的差异。

906
00:42:28,480 --> 00:42:31,705
So, er, a lot of the times the challenge is in, uh,
所以，呃，挑战的次数很多，呃，

907
00:42:31,705 --> 00:42:33,820
being able to scale, uh, you know,
能够扩展，呃，你知道，

908
00:42:33,820 --> 00:42:37,660
being able to be more memory efficient so that [NOISE] you can model longer sequences.
能够提高内存效率，以便[NOISE]可以模拟更长的序列。

909
00:42:37,660 --> 00:42:40,420
So with that, uh, this is,
那么，呃，这是，

910
00:42:40,420 --> 00:42:42,850
um, I can play you one more example if we have time.
嗯，如果我们有时间，我可以再给你一个例子。

911
00:42:42,850 --> 00:42:45,125
But if we don't have time, we can, go ahead.
但如果我们没有时间，我们可以继续。

912
00:42:45,125 --> 00:42:46,175
We'll see more of that.
我们会看到更多。

913
00:42:46,175 --> 00:42:47,980
Okay. [LAUGHTER] So this is,
好的。 [大笑]所以这是，

914
00:42:47,980 --> 00:42:49,930
this is, uh, maybe a one, uh,
这是，呃，也许是一个，呃，

915
00:42:49,930 --> 00:42:54,480
about a one-minute sample and I- I hope you like it.
大约一分钟的样品和我 - 我希望你喜欢它。

916
00:42:54,480 --> 00:44:06,385
Thanks. [MUSIC]
谢谢。 [音乐]

917
00:44:06,385 --> 00:44:07,720
Thank you for listening.
谢谢你的收听。

918
00:44:07,720 --> 00:44:18,610
[APPLAUSE].
[掌声]。

919
00:44:18,610 --> 00:44:23,830
[LAUGHTER] Thanks, Anna. Um, um, great.
[大笑]谢谢，安娜。恩，嗯，太棒了。

920
00:44:23,830 --> 00:44:26,930
Um, so to sort to, um,
嗯，好吧，嗯，

921
00:44:26,970 --> 00:44:31,615
so relative attention has been a powerful mechanism for,
所以相对注意力是一种强大的机制，

922
00:44:31,615 --> 00:44:35,185
um, a very powerful mechanism for music.
嗯，一个非常强大的音乐机制。

923
00:44:35,185 --> 00:44:37,285
It's also helped in machine translation.
它也有助于机器翻译。

924
00:44:37,285 --> 00:44:39,355
Um, one really interesting, uh,
嗯，一个非常有趣，呃，

925
00:44:39,355 --> 00:44:41,545
consequences of, uh, of, um,
嗯，嗯，嗯，

926
00:44:41,545 --> 00:44:44,395
one really interesting consequence of relative attention in,
相对关注的一个非常有趣的结果，

927
00:44:44,395 --> 00:44:46,030
uh, images, is that,
呃，图像，是的，

928
00:44:46,030 --> 00:44:48,370
um, like convolutions achieve,
嗯，就像卷积实现一样，

929
00:44:48,370 --> 00:44:50,740
uh, convolutions achieve translational equivariance.
呃，卷积实现平移等价。

930
00:44:50,740 --> 00:44:51,970
So if you have,
所以，如果你有，

931
00:44:51,970 --> 00:44:54,640
let's say, you wa- uh, you have this,
让我们说，你好，你有这个，

932
00:44:54,640 --> 00:44:58,345
this red dot or this feature that you're computing at this red dot,
这个红点或你在这个红点上计算的这个特征，

933
00:44:58,345 --> 00:45:01,465
it doesn't depend on where the image of the dog is in the image,
它不取决于狗的图像在图像中的位置，

934
00:45:01,465 --> 00:45:04,720
is in the the larger image. It just doesn't depend on its absolute location.
是在更大的图像。它只是不依赖于它的绝对位置。

935
00:45:04,720 --> 00:45:07,000
It's going to, it's going to produce the same activation.
它会发生，它将产生相同的激活。

936
00:45:07,000 --> 00:45:10,915
So you have- convolutions have this nice, uh, translation equivariance.
所以你有 - 卷积有这个很好的，呃，翻译等价。

937
00:45:10,915 --> 00:45:13,135
Now, with, with relative,
现在，和亲戚在一起

938
00:45:13,135 --> 00:45:15,220
uh, positions or relative attention,
呃，职位或相对关注，

939
00:45:15,220 --> 00:45:18,550
you get exactly the same effect because you don't have any- once you just
你会得到完全相同的效果，因为你没有任何 - 只要你一次

940
00:45:18,550 --> 00:45:22,495
remove this notion of absolute position that you are injecting [NOISE] into the model,
删除你将[NOISE]注入模型的绝对位置概念，

941
00:45:22,495 --> 00:45:24,280
uh, once you've, once you've removed that,
呃，一旦你去了，一旦你删除了，

942
00:45:24,280 --> 00:45:26,470
then your attention computation,
然后你的注意力计算，

943
00:45:26,470 --> 00:45:28,840
because it actually includes I mean, we've,
因为它实际上包括我的意思，我们已经，

944
00:45:28,840 --> 00:45:32,215
we've- Niki and I couple of others have actually,
我们 - 尼基和我其他几个人实际上，

945
00:45:32,215 --> 00:45:34,870
and Anna were actually working on images and seems-
和安娜实际上正在研究图像，似乎 -

946
00:45:34,870 --> 00:45:37,480
and it seems to actually show, uh, better results.
它似乎实际上表明，呃，更好的结果。

947
00:45:37,480 --> 00:45:42,040
Um, this actio- this now satisfies this,
嗯，这个行动 - 这现在满足了这个，

948
00:45:42,040 --> 00:45:44,440
uh, uh, the- I mean, it,
呃，呃，我的意思是，它，

949
00:45:44,440 --> 00:45:47,470
it can achieve translation equivariance which is a great property for images.
它可以实现平移等价，这是图像的一个很好的属性。

950
00:45:47,470 --> 00:45:49,300
So there's a lot of- it seems like this might be
所以有很多 - 似乎这可能是

951
00:45:49,300 --> 00:45:51,250
an interesting direction to pursue if you want to push,
如果你想推动一个有趣的方向，

952
00:45:51,250 --> 00:45:55,090
uh, Self-Attention in images for a self-supervised learning.
呃，自我注意图像中的自我监督学习。

953
00:45:55,090 --> 00:45:59,785
Um, I guess on, on self-supervised learning so the geni- generative modeling work that,
嗯，我猜，关于自我监督的学习，所以生成建模工作，

954
00:45:59,785 --> 00:46:01,450
that I talked about before in,
我之前谈过的，

955
00:46:01,450 --> 00:46:05,320
in itself just having probabilistic models of images is, I mean,
我的意思是，本身只有图像的概率模型

956
00:46:05,320 --> 00:46:06,895
I guess the best model of an image is I,
我想图像的最佳模型是我，

957
00:46:06,895 --> 00:46:09,580
I go to Google search and I pick up an image and I just give it to you,
我去谷歌搜索，我拿起一张图片，我就把它给你，

958
00:46:09,580 --> 00:46:12,325
but I guess generative models of images are useful because,
但我猜图像的生成模型是有用的，因为，

959
00:46:12,325 --> 00:46:14,470
if you want to do something like semis-, uh, uh,
如果你想做一些像semis-，呃，呃，

960
00:46:14,470 --> 00:46:16,810
self supervised learning where you just pre-train a model on
自我监督学习，你只是预先培训模型

961
00:46:16,810 --> 00:46:19,375
a lot of- on a lot of unlabeled data then you transfer it.
很多未标记的数据然后你转移它。

962
00:46:19,375 --> 00:46:22,765
So hopefully, this is gonna help and this is gonna be a part of that machinery.
所以希望，这会有所帮助，这将成为该机制的一部分。

963
00:46:22,765 --> 00:46:26,890
Um, another interesting, uh,
嗯，另一个有趣的，呃，

964
00:46:26,890 --> 00:46:30,520
another indus-interesting structure that relative attention allows you to model,
另一个行业有趣的结构，相对关注允许你建模，

965
00:46:30,520 --> 00:46:31,960
is, uh, is, is kind of a graph.
呃，是，是一种图形。

966
00:46:31,960 --> 00:46:33,520
So imagine you have this, uh,
所以想象你有这个，呃，

967
00:46:33,520 --> 00:46:36,265
you have this similarity graph where these red edges are,
你有这个红色边缘的相似图，

968
00:46:36,265 --> 00:46:37,600
are this notion of companies,
这是公司的概念，

969
00:46:37,600 --> 00:46:40,180
and the blue edge is a notion of a fruit, uh,
蓝色的边缘是水果的概念，呃，

970
00:46:40,180 --> 00:46:44,500
and um, an apple takes these two forms.
而嗯，苹果采用这两种形式。

971
00:46:44,500 --> 00:46:47,140
And, uh, and you could just imagine
而且，呃，你可以想象

972
00:46:47,140 --> 00:46:50,650
relative attention just modeling this- just being able to model,
相对注意只是建模这个 - 只是能够建模，

973
00:46:50,650 --> 00:46:52,285
or being able to- you, you,
或者能够 - 你，你，

974
00:46:52,285 --> 00:46:56,170
yourself being able to impose these different notions of similarity uh,
你自己能够强加这些不同的相似概念呃，

975
00:46:56,170 --> 00:46:58,375
between, uh, between, uh, different elements.
之间，呃，之间，呃，不同的元素。

976
00:46:58,375 --> 00:47:00,715
Uh, so if you have like, if you have graph problems, um,
呃，如果你有，如果你有图形问题，嗯，

977
00:47:00,715 --> 00:47:03,925
then relative self-attention might be a good fit for you.
那么相对的自我关注可能非常适合你。

978
00:47:03,925 --> 00:47:08,530
Um, there's also, there's also a simi- quite a position paper by Battaglia et al from
嗯，还有，Battaglia等人也提供了一份类似的立场文件

979
00:47:08,530 --> 00:47:13,930
Deep Mind that talks about relative attention and how it can be used, um, within graphs.
深入思考，谈论相对关注以及如何在图表中使用它。

980
00:47:13,930 --> 00:47:15,580
So while we're on graphs,
所以当我们在图上时，

981
00:47:15,580 --> 00:47:18,685
I just wanted to- perhaps might be interesting to connect,
我只是想 - 也许可能有趣的连接，

982
00:47:18,685 --> 00:47:21,490
um, uh, of- some, uh,
嗯，呃，有些，呃，

983
00:47:21,490 --> 00:47:22,810
excellent work that was done on, uh,
做得很好的工作，呃，

984
00:47:22,810 --> 00:47:25,030
on graphs called Message Passing Neural Networks.
在称为消息传递神经网络的图上。

985
00:47:25,030 --> 00:47:27,265
And it's quite funny, so if you look at,
这很有趣，所以如果你看一下，

986
00:47:27,265 --> 00:47:30,730
if you look at the message passing function, um,
如果你看一下消息传递函数，嗯，

987
00:47:30,730 --> 00:47:34,480
what it's saying is you're actually just passing messages between pairs of nodes.
它的含义是你实际上只是在节点对之间传递消息。

988
00:47:34,480 --> 00:47:37,090
So you can just think of self attention as imposing a fully connect- it's
因此，您可以将自我关注视为强加完全连接

989
00:47:37,090 --> 00:47:39,970
like a bipe- a full, a complete bipartite graph,
像一个完整的，完整的二分图，

990
00:47:39,970 --> 00:47:42,250
and, uh, you're, you're passing messages between,
而且，呃，你是，你在之间传递信息，

991
00:47:42,250 --> 00:47:43,750
you're passing messages between nodes.
你在节点之间传递消息。

992
00:47:43,750 --> 00:47:46,540
Now message passing, message passing neural networks did exactly that.
现在消息传递，消息传递神经网络正是这样做的。

993
00:47:46,540 --> 00:47:49,420
They were passing messages between nodes as well. And how are they different?
他们也在节点之间传递消息。它们有何不同？

994
00:47:49,420 --> 00:47:51,580
Well, the only way that when- well, mathematically,
嗯，这是唯一的方式 - 在数学上，

995
00:47:51,580 --> 00:47:53,965
they were only different in that message passing was,
他们只是在传递信息方面不同​​，

996
00:47:53,965 --> 00:47:57,370
was, uh, forcing the messages to be between pairs of nodes,
呃，迫使消息在节点对之间，

997
00:47:57,370 --> 00:48:00,790
but just because of the Softmax function where you get interaction between all the nodes,
但正因为Softmax功能，您可以在所有节点之间进行交互，

998
00:48:00,790 --> 00:48:03,175
self attention is like a message passing mechanism,
自我关注就像一个消息传递机制，

999
00:48:03,175 --> 00:48:05,470
where the interactions are between all, all nodes.
所有节点之间的交互。

1000
00:48:05,470 --> 00:48:07,315
So, uh, they're, they're like,
那么，呃，他们是，他们就像，

1001
00:48:07,315 --> 00:48:08,800
they're not too far mathematically,
他们在数学上并不太远，

1002
00:48:08,800 --> 00:48:11,320
and also the me- the Message Passing Paper introduces
还有我 - 消息传递论文介绍

1003
00:48:11,320 --> 00:48:14,620
an interesting concept called Multiple Towers that are similar to multi-head attention,
一个名为Multiple Towers的有趣概念，类似于多头注意，

1004
00:48:14,620 --> 00:48:16,585
uh, that, that Norman invented.
呃，诺曼发明的那个。

1005
00:48:16,585 --> 00:48:21,160
And, uh, it's like you run k copies of these message passing neural networks in parallel.
而且，呃，就像你运行这些消息的k个副本并行通过神经网络。

1006
00:48:21,160 --> 00:48:23,590
So there's a lot of similarity between existing, you know,
所以，现有的，你知道，有很多相似之处，

1007
00:48:23,590 --> 00:48:27,805
this connects to work that existed before but these connections sort of came in later.
这连接到之前存在的工作，但这些连接后来出现了。

1008
00:48:27,805 --> 00:48:31,930
Um, we have a graph library where we kind of connected these both,
嗯，我们有一个图库，我们将它们连接起来，

1009
00:48:31,930 --> 00:48:34,150
both these strands message passing and, uh, we,
这两股消息传递，呃，我们，

1010
00:48:34,150 --> 00:48:37,495
uh, we put it out in tensor2tensor.
呃，我们把它放在tensor2tensor中。

1011
00:48:37,495 --> 00:48:40,705
Um, so to sort of summarize, um,
嗯，总结一下，嗯，

1012
00:48:40,705 --> 00:48:43,510
the properties that Self-Attention has been able to help
自我关注能够提供帮助的属性

1013
00:48:43,510 --> 00:48:46,240
us model is this constant path length between any two,
我们的模型是任何两个之间的恒定路径长度，

1014
00:48:46,240 --> 00:48:47,870
any two positions, and it's been,
任何两个职位，它一直是，

1015
00:48:47,870 --> 00:48:49,600
it's been shown to be quite useful in,
它被证明是非常有用的，

1016
00:48:49,600 --> 00:48:52,165
in, in, uh, in sequence modeling.
in，in，呃，在序列建模中。

1017
00:48:52,165 --> 00:48:56,200
This advantage of having unbounded memory not having to pack information in finite,
这种无限内存的优点是不必在有限的情况下打包信息，

1018
00:48:56,200 --> 00:48:58,360
in, in sort of a finite amount of- in a,
in，在某种有限数量的中，

1019
00:48:58,360 --> 00:48:59,575
in a fixed amount of space,
在固定的空间内，

1020
00:48:59,575 --> 00:49:03,625
uh, where in, in our case our memory essentially grows with the sequences is,
呃，在我们的情况下，我们的记忆基本上随着序列而增长，

1021
00:49:03,625 --> 00:49:07,180
is helps you computationally, uh, it's trivial to parallelize.
是帮助你计算，呃，并行化是微不足道的。

1022
00:49:07,180 --> 00:49:09,110
You can, you can crunch a lot of data, it's uh,
你可以，你可以处理很多数据，呃，

1023
00:49:09,110 --> 00:49:12,040
which is useful if you wanna have your large data sets.
如果您想拥有大型数据集，这非常有用。

1024
00:49:12,040 --> 00:49:14,275
We found that it can model Self-Similarity.
我们发现它可以模拟自相似性。

1025
00:49:14,275 --> 00:49:16,330
Uh, It seems to be a very natural thing, uh,
呃，这似乎很自然，呃，

1026
00:49:16,330 --> 00:49:20,350
a very, a very natural phenomenon if you're dealing with images or music.
如果你正在处理图像或音乐，这是一种非常自然的现象。

1027
00:49:20,350 --> 00:49:23,200
Also, relative attention allows you to sort of, gives you this added dimension
此外，相对关注允许您排序，给你这个增加的维度

1028
00:49:23,200 --> 00:49:26,080
of being able to model expressive timing and music,
能够模仿表达时间和音乐，

1029
00:49:26,080 --> 00:49:27,925
well, this translational equivariance,
好吧，这个平移等价，

1030
00:49:27,925 --> 00:49:30,475
uh, it extends naturally to graphs.
呃，它自然地延伸到图表。

1031
00:49:30,475 --> 00:49:37,030
Um, so this part or everything that I talked so far was about sort of parallel training.
嗯，所以到目前为止我谈到的这部分或者所有内容都是关于平行训练的。

1032
00:49:37,030 --> 00:49:41,905
Um, so there's a very active area of research now using the Self-Attention models for,
嗯，现在有一个非常活跃的研究领域，现在使用Self-Attention模型，

1033
00:49:41,905 --> 00:49:43,975
for, for less auto-regressive generation.
对于较少的自回归生成。

1034
00:49:43,975 --> 00:49:45,790
So notice a- at generation time,
所以请注意 - 在世代时间，

1035
00:49:45,790 --> 00:49:47,575
notice that the decoder mask was causal,
注意解码器掩码是因果关系，

1036
00:49:47,575 --> 00:49:48,670
we couldn't look into the future.
我们无法展望未来。

1037
00:49:48,670 --> 00:49:51,190
So when we're, when we're generating we're still
所以，当我们生成时，我们仍在生产

1038
00:49:51,190 --> 00:49:54,250
generating sequentially left to right on the target side.
在目标侧从左到右依次生成。

1039
00:49:54,250 --> 00:49:56,845
Um, so, um, and, and,
嗯，嗯，和，和，

1040
00:49:56,845 --> 00:49:59,170
and, and why, why is generation hard?
而且，为什么，为什么一代人很难？

1041
00:49:59,170 --> 00:50:00,670
Well, because your outputs are multi-modal.
好吧，因为你的输出是多模态的。

1042
00:50:00,670 --> 00:50:02,845
I f you had- if you want to translate English to German,
我有你 - 如果你想把英语翻译成德语，

1043
00:50:02,845 --> 00:50:04,285
there's multiple ways and,
有多种方式，

1044
00:50:04,285 --> 00:50:08,410
and, and your, your second word that you're translating will depend on the first word.
而且，你正在翻译的第二个词将取决于第一个词。

1045
00:50:08,410 --> 00:50:11,605
For example, if you, if you first- the first word that you predict was danke,
例如，如果你，如果你是第一个 - 你预测的第一个词是danke，

1046
00:50:11,605 --> 00:50:13,675
then that's going to change the second word that you predict.
那会改变你预测的第二个词。

1047
00:50:13,675 --> 00:50:15,670
And if you just predicted them independently,
如果你只是独立预测它们，

1048
00:50:15,670 --> 00:50:17,620
then you can imagine you can just have all sorts of
那么你可以想象你可以拥有各种各样的东西

1049
00:50:17,620 --> 00:50:20,185
permutations of these which will be incorrect.
这些的排列是不正确的。

1050
00:50:20,185 --> 00:50:22,690
Uh, and the way we actually break modes is
呃，我们实际打破模式的方式是

1051
00:50:22,690 --> 00:50:24,940
just- or we make decisions is just sequential generation.
只是 - 或者我们做出决定只是顺序生成。

1052
00:50:24,940 --> 00:50:27,700
Once we commit to a word that makes a decision,
一旦我们承诺做出决定，

1053
00:50:27,700 --> 00:50:30,490
and then that nails down what's the next word that you're going to predict.
然后指出你将要预测的下一个词是什么。

1054
00:50:30,490 --> 00:50:34,210
So there's been some, there's been some work on, it's an active research area, uh,
所以有一些，有一些工作，这是一个活跃的研究领域，呃，

1055
00:50:34,210 --> 00:50:36,700
and you can kind of categorize some of these papers like
你可以对这些论文中的一些进行分类

1056
00:50:36,700 --> 00:50:41,740
the non-autogressive transformer of the fast- the third paper, fast decoding.
快速的第三篇论文的非渐进式变换器，快速解码。

1057
00:50:41,740 --> 00:50:43,870
Um, the fourth paper towards a better understanding
嗯，第四篇有助于更好理解的论文

1058
00:50:43,870 --> 00:50:46,000
of all Vector Quantized Auto-encoders into this group,
所有矢量量化自动编码器进入该组，

1059
00:50:46,000 --> 00:50:49,255
where they're actually make- doing the decision making in a latent space,
实际上他们在潜在的空间做决策，

1060
00:50:49,255 --> 00:50:53,470
that's being, uh, it's e- either being learned using word alignments,
是的，呃，这是e-要么是使用单词对齐来学习的，

1061
00:50:53,470 --> 00:50:56,860
uh, fertilities, or that's being learned using Auto-encoders.
呃，这些或者是使用自动编码器学习的。

1062
00:50:56,860 --> 00:50:59,680
So you make- you do the decision making in latent space,
所以你做 - 你在潜在空间做决策，

1063
00:50:59,680 --> 00:51:02,275
and then you- once you've made the decisions in latent space,
然后你 - 一旦你在潜伏的空间做出决定，

1064
00:51:02,275 --> 00:51:04,030
you assume that all your outputs,
你假设你的所有输出，

1065
00:51:04,030 --> 00:51:05,725
are actually conditionally independent,
实际上是条件独立的

1066
00:51:05,725 --> 00:51:07,180
given that you've made these decisions.
鉴于你做出了这些决定。

1067
00:51:07,180 --> 00:51:08,485
So that's how they actually speed up.
这就是他们实际加速的方式。

1068
00:51:08,485 --> 00:51:10,600
There's also- there's ano- there's another paper.
还有 - 还有另一篇论文。

1069
00:51:10,600 --> 00:51:11,860
The second one is a
第二个是

1070
00:51:11,860 --> 00:51:14,020
paper that does Iterative Refinement.
做迭代细化的论文。

1071
00:51:14,020 --> 00:51:17,665
There is also a Blockwise Parallel Decoding paper by Mitchell Stern,
米切尔斯特恩还有一个Blockwise Parallel Decoding论文，

1072
00:51:17,665 --> 00:51:20,215
uh, Noam Shazeer, and Jakob Uszkoreit, uh,
呃，Noam Shazeer和Jakob Uszkoreit，呃，

1073
00:51:20,215 --> 00:51:23,440
where they essentially just run multiple models like, uh,
他们基本上只运行多个模型，呃，

1074
00:51:23,440 --> 00:51:29,440
and rescore using a more- a decode using a faster model and score,
并使用更快的模型和分数使用更多解码，

1075
00:51:29,440 --> 00:51:31,405
using the more expensive model.
使用更昂贵的模型。

1076
00:51:31,405 --> 00:51:33,580
So that's how it sort of it speeds it up.
这就是它如何加快速度。

1077
00:51:33,580 --> 00:51:38,350
Um, [NOISE] transfer learning has had the- Self-Attention has been beneficial in transfer
嗯，[NOISE]转移学习已经 - 自我注意在转移中是有益的

1078
00:51:38,350 --> 00:51:42,820
learning, GPT from OpenAI and BERT are two classic examples.
学习，OpenAI和BERT的GPT是两个经典的例子。

1079
00:51:42,820 --> 00:51:44,995
There's been some work on actually, scaling this up,
实际上有一些工作，扩大规模，

1080
00:51:44,995 --> 00:51:48,085
like add a factor as, uh, efficient optimizer.
喜欢添加一个因素，呃，高效的优化器。

1081
00:51:48,085 --> 00:51:52,120
Um, there's a, there's a recent paper by Rohan Anil and Yoram Singer.
嗯，还有一个，Rohan Anil和Yoram Singer最近发表了一篇论文。

1082
00:51:52,120 --> 00:51:54,445
Um, there's also Mesh-Tensorflow,
嗯，还有Mesh-Tensorflow，

1083
00:51:54,445 --> 00:51:57,850
which actually they've been able to train models
实际上他们已经能够训练模型了

1084
00:51:57,850 --> 00:52:02,530
of just several orders of magnitude larger than the original models have been trained.
仅比原始模型大几个数量级的训练。

1085
00:52:02,530 --> 00:52:05,710
So there's, I mean, when you're working this large data regime you would probably want to
所以，我的意思是，当你正在使用这种大数据制度时，你可能会想要

1086
00:52:05,710 --> 00:52:07,720
memorize a lot of- you want to memorize
记住很多 - 你想记住

1087
00:52:07,720 --> 00:52:10,270
a lot of things inside your parameters used to train a larger model.
你的参数中有很多东西用来训练一个更大的模型。

1088
00:52:10,270 --> 00:52:12,415
Uh, Mesh-Tensorflow can uh, can let you do that.
呃，Mesh-Tensorflow可以，呃，可以让你这样做。

1089
00:52:12,415 --> 00:52:16,300
Um, there has been a lot of interesting work, universal transformers,
嗯，有很多有趣的工作，通用变压器，

1090
00:52:16,300 --> 00:52:19,240
sort of recurrent neural networks can actually count very nicely.
一种反复出现的神经网络实际上可以非常好地计算。

1091
00:52:19,240 --> 00:52:21,910
There's these cute papers by Schmidhuber where he actually shows
Schmidhuber有这些可爱的论文，他实际上是在那里展示的

1092
00:52:21,910 --> 00:52:25,480
that recurring neural, the count- the cell mechanism just learns a nice counter,
那个反复发生的神经，计数 - 细胞机制才能学会一个好的计数器，

1093
00:52:25,480 --> 00:52:27,340
like if you're- you can learn kind of a to the n,
就像你 - 你可以学到一种对n，

1094
00:52:27,340 --> 00:52:29,230
b to the n, uh, with LSTM.
b到n，呃，用LSTM。

1095
00:52:29,230 --> 00:52:31,735
So then, uh, universals transformers
那么，呃，普遍变形金刚

1096
00:52:31,735 --> 00:52:34,660
brings back recurrence in depth inside the transformer.
带回变压器内部的深度重现。

1097
00:52:34,660 --> 00:52:37,195
Uh, there is a really cool Wikipedia paper,
呃，有一篇很酷的维基百科论文，

1098
00:52:37,195 --> 00:52:40,900
um, simultaneously with the image transformer paper that also uses local attention.
嗯，与图像变压器纸同时使用本地注意力。

1099
00:52:40,900 --> 00:52:46,060
Transformer-XL paper that sort of combines recurrence with Self-Attention,
Transformer-XL纸张将复发与自我注意结合起来，

1100
00:52:46,060 --> 00:52:47,290
so they do Self-Attention in chunks,
所以他们一块一块地自我注意，

1101
00:52:47,290 --> 00:52:50,275
but they sort of summarize history by using recurrence, it's kinda cute.
但他们通过使用复发来总结历史，它有点可爱。

1102
00:52:50,275 --> 00:52:52,135
It's been used in speech but I don't know if there's been
它已被用于演讲，但我不知道是否有过

1103
00:52:52,135 --> 00:52:55,315
some fairly big success stories of Self-Attention in speech.
演讲中自我注意的一些相当大的成功故事。

1104
00:52:55,315 --> 00:52:58,350
Uh, again, similar issues where you have very large, uh,
呃，再次，你有很大的类似问题，呃，

1105
00:52:58,350 --> 00:53:00,900
um as positions to,
作为职位，

1106
00:53:00,900 --> 00:53:03,165
uh, to do Self-Attention over.
呃，要自我注意。

1107
00:53:03,165 --> 00:53:08,050
So yeah, um, self supervision is a- if it works it would be,
所以，是的，嗯，自我监督是 - 如果它有效，那将是，

1108
00:53:08,050 --> 00:53:09,640
it would be, it would be very beneficial.
它会，这将是非常有益的。

1109
00:53:09,640 --> 00:53:12,910
We wouldn't need large label datasets, understanding transfer,
我们不需要大型标签数据集，了解转移，

1110
00:53:12,910 --> 00:53:15,490
transfers is becoming very succe- becoming- is becoming
转移正在变得非常成功

1111
00:53:15,490 --> 00:53:18,960
a reality in NLP with BERT and some of these other models.
与BERT和其他一些模型在NLP中的现实。

1112
00:53:18,960 --> 00:53:21,630
So understanding how these, what's actually happening is a-
因此，了解这些，实际发生的是 -

1113
00:53:21,630 --> 00:53:24,555
is an interesting area of ongoing research for me and a couple.
对我和一对夫妇来说，这是一个有趣的研究领域。

1114
00:53:24,555 --> 00:53:29,505
And a few of my collaborators and uh, multitask learning and surmounting this,
还有一些我的合作者和呃，多任务学习和超越这个，

1115
00:53:29,505 --> 00:53:32,860
this quadratic problem with Self-Attention is
这种自我注意的二次问题是

1116
00:53:32,860 --> 00:53:38,150
an interesting area of research that I- that I'd like to pursue. Thank you.
我想要研究的一个有趣的研究领域。谢谢。

1117


