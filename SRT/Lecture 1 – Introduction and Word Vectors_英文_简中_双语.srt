1
00:00:04,430 --> 00:00:07,410
Okay. Hello everyone.
好的。大家好。

2
00:00:07,410 --> 00:00:11,265
[LAUGHTER] Okay we should get started.
[大笑]好的，我们应该开始吧。

3
00:00:11,265 --> 00:00:14,640
Um, they're actually are still quite a few seats left.
嗯，他们实际上还剩下不少座位。

4
00:00:14,640 --> 00:00:15,960
If you wanna be really bold,
如果你想真的很大胆，

5
00:00:15,960 --> 00:00:18,525
there are a couple of seats right in front of me in the front row.
前排有几个座位就在我面前。

6
00:00:18,525 --> 00:00:20,445
If you're less bolder a few over there.
如果你在那里不那么大胆。

7
00:00:20,445 --> 00:00:23,940
Um, but they're also on some of the rows are quite a few middle seat.
嗯，但他们也在一些行上有相当多的中间座位。

8
00:00:23,940 --> 00:00:28,080
So if people wanted to be really civic minded some people could sort of
因此，如果人们想成为一个真正的公民意识，有些人可能会有所不同

9
00:00:28,080 --> 00:00:32,280
squeeze towards the edges and make  more accessible um,
挤向边缘，使更容易接近，

10
00:00:32,280 --> 00:00:35,685
some of the seats that still exist in the classroom.
教室里仍然存在一些席位。

11
00:00:35,685 --> 00:00:39,435
Okay. Um, so, um,
好的。嗯，恩，嗯，

12
00:00:39,435 --> 00:00:42,890
it's really exciting and great to see so many people here.
看到这么多人真是令人兴奋和高兴。

13
00:00:42,890 --> 00:00:47,390
So I'm a hearty welcome to CS224N and occasionally also
所以我对CS224N表示热烈欢迎，偶尔也欢迎

14
00:00:47,390 --> 00:00:52,625
known as Ling 284 which is Natural Language Processing with Deep Learning.
被称为Ling 284，它是深度学习的自然语言处理。

15
00:00:52,625 --> 00:00:55,420
Um, as just a sort of a  personal anecdote,
嗯，只是一种个人轶事，

16
00:00:55,420 --> 00:00:59,720
is still sort of blows my mind that so many people turn up to this class these days.
我觉得这些日子里有这么多人上这堂课了。

17
00:00:59,720 --> 00:01:03,980
So, for about the first decade that I taught NLP here,
那么，我在这里教授NLP的第一个十年，

18
00:01:03,980 --> 00:01:08,180
you know the number of people I got each year was approximately 45.
你知道我每年得到的人数约为45人。

19
00:01:08,180 --> 00:01:11,240
[LAUGHTER] So it's an order of [LAUGHTER] magnitude smaller than
[大笑]所以这是[笑声]大小的顺序

20
00:01:11,240 --> 00:01:14,360
it is now but guess it says quite a lot
它现在但是猜它说了很多

21
00:01:14,360 --> 00:01:17,450
on about what a revolutionary   impact
关于什么是革命性的影响

22
00:01:17,450 --> 00:01:20,870
that artificial intelligence in general and machine learning,
人工智能一般和机器学习，

23
00:01:20,870 --> 00:01:25,600
deep learning, NLP are starting to have in modern society.
深度学习，NLP开始在现代社会中发挥作用。

24
00:01:25,600 --> 00:01:28,860
Okay. So this is our plan for today.
好的。所以这是我们今天的计划。

25
00:01:28,860 --> 00:01:32,750
So, um, um, we're really gonna get straight down to business today.
所以，嗯，嗯，我们今天真的要开始做生意了。

26
00:01:32,750 --> 00:01:37,970
So they'll be a brief, very brief introduction some of the sort of course logistics,
因此，他们将简要介绍一些课程后勤，

27
00:01:37,970 --> 00:01:42,140
very brief discussion and talk about human language and
非常简短的讨论和谈论人类语言和

28
00:01:42,140 --> 00:01:46,370
word meaning and then we wanna get right into talking about um,
单词含义，然后我们想谈谈你，

29
00:01:46,370 --> 00:01:50,540
the first thing that we're doing which is coming up with word vectors and looking
我们正在做的第一件事是提出单词向量和看

30
00:01:50,540 --> 00:01:55,010
at the word2vec algorithm and that will then sort of fill up the rest of the class.
在word2vec算法，然后将填写其余的类。

31
00:01:55,010 --> 00:01:56,840
There are still two seats right in
还有两个席位

32
00:01:56,840 --> 00:01:59,480
the front row for someone who wants to sit right in front of me,
想要坐在我面前的人的前排，

33
00:01:59,480 --> 00:02:02,760
just letting you know [LAUGHTER].
只是让你知道[笑声]。

34
00:02:02,760 --> 00:02:06,365
Okay. Okay. So here are the course logistics in brief.
好的。好的。所以这里是课程后勤简介。

35
00:02:06,365 --> 00:02:08,345
So I'm Christopher Manning,
所以我是克里斯托弗曼宁，

36
00:02:08,345 --> 00:02:15,290
the person who bravely became the head TA is Abigail See is right there.
勇敢地成为TA主管的人是Abigail See就在那里。

37
00:02:15,290 --> 00:02:18,920
And then we have quite a lot of wonderful TA's.
然后我们有很多很棒的TA。

38
00:02:18,920 --> 00:02:22,700
To the people who are wonderful TA's just sort of stand up for one moment.
对于那些精彩TA的人来说，只是站了一会儿。

39
00:02:22,700 --> 00:02:26,810
So, um, [LAUGHTER] we have some sense for wonderful TAs.
所以，嗯，[笑声]我们对美妙的TA有一定的感觉。

40
00:02:26,810 --> 00:02:28,900
[LAUGHTER] Okay great.
[大笑]好的。

41
00:02:28,900 --> 00:02:31,320
Um, okay.
嗯，好的。

42
00:02:31,320 --> 00:02:33,260
So you know when the lecture is because you made it
所以你知道讲座的时间是因为你做到了

43
00:02:33,260 --> 00:02:37,100
here and so welcome also to SCPD people.
在这里，也欢迎SCPD人。

44
00:02:37,100 --> 00:02:41,300
This is also an SCPD class and you can watch it on video.
这也是一个SCPD课程，您可以在视频中观看。

45
00:02:41,300 --> 00:02:44,300
But we love for Stanford students to turn
但我们喜欢斯坦福大学的学生

46
00:02:44,300 --> 00:02:47,300
up and show their beautiful faces in the classroom.
在教室里展示他们美丽的面孔。

47
00:02:47,300 --> 00:02:52,810
Okay. So, um, the web-page has all the info about syllabus et cetera et cetera.
好的。所以，嗯，网页上有关于教学大纲等等的所有信息。

48
00:02:52,810 --> 00:02:56,175
Okay. So this class what do we hope to teach?
好的。那么这堂课我们希望教什么？

49
00:02:56,175 --> 00:02:59,240
So, one thing that we wanna teach is, uh, you know,
所以，我们想教的一件事是，呃，你知道，

50
00:02:59,240 --> 00:03:02,495
an understanding of effective modern methods for deep learning.
了解有效的现代深度学习方法。

51
00:03:02,495 --> 00:03:05,090
Starting off by reviewing some of the basics and then
首先回顾一些基础知识然后

52
00:03:05,090 --> 00:03:08,780
particularly talking about the kinds of techniques including um,
特别是谈论包括嗯在内的各种技术，

53
00:03:08,780 --> 00:03:11,450
recurrent networks and attention that are widely
反复出现的网络和广泛的关注

54
00:03:11,450 --> 00:03:14,570
used for natural language processing models.
用于自然语言处理模型。

55
00:03:14,570 --> 00:03:18,770
A second thing we wanna teach is a big picture understanding of
我们想要教的第二件事是对大局的全面了解

56
00:03:18,770 --> 00:03:23,075
human languages and some of the difficulties in understanding and producing them.
人类语言以及理解和产生它们的一些困难。

57
00:03:23,075 --> 00:03:25,490
Of course if you wanna know a lot about human languages,
当然，如果你想了解很多关于人类语言的知识，

58
00:03:25,490 --> 00:03:29,060
there's a whole linguistics department and you can do a lot of courses of that.
这里有一个完整的语言学系，你可以做很多课程。

59
00:03:29,060 --> 00:03:33,590
Um, but so I wanna give at least some appreciation so you have some clue of what are
嗯，但是我想至少给予一些赞赏，所以你有一些线索是什么

60
00:03:33,590 --> 00:03:38,235
the challenges and difficulties and varieties of human languages.
人类语言的挑战，困难和多样性。

61
00:03:38,235 --> 00:03:41,315
And then this is also kind of a practical class.
然后这也是一个实用的课程。

62
00:03:41,315 --> 00:03:44,960
Like we actually wanna teach you how you can
就像我们真的想教你怎么做

63
00:03:44,960 --> 00:03:49,670
build practical systems that work for some of the major parts of NLP.
构建适用于NLP某些主要部分的实用系统。

64
00:03:49,670 --> 00:03:53,750
So if you go and get a job at one of those tech firms and they say "Hey,
所以，如果你去其中一家科技公司找工作，他们说“嘿，

65
00:03:53,750 --> 00:03:55,789
could you build us a named entity recognizer?"
你能为我们建立一个命名的实体识别器吗？“

66
00:03:55,789 --> 00:03:58,130
You can say "Sure, I can do that."
你可以说“当然，我能做到。”

67
00:03:58,130 --> 00:04:00,530
And so for a bunch of problems,
对于一堆问题，

68
00:04:00,530 --> 00:04:02,090
obviously we can't do everything,
显然我们无法做到一切，

69
00:04:02,090 --> 00:04:03,230
we're gonna do word meaning,
我们会做单词的意思，

70
00:04:03,230 --> 00:04:07,579
dependency parsing, machine translation and you have an option to do question answering,
依赖解析，机器翻译，你可以选择进行问答，

71
00:04:07,579 --> 00:04:10,340
I'm actually building systems for those.
我实际上正在为那些人构建系统。

72
00:04:10,340 --> 00:04:15,080
If you'd been talking to friends who did the class in the last couple of years,
如果你和过去几年上课的朋友说话，

73
00:04:15,080 --> 00:04:18,860
um, here are the differences for this year just to get things straight.
嗯，今年的差异只是为了让事情顺利进行。

74
00:04:18,860 --> 00:04:21,830
Um, so we've updated some of the content of the course.
嗯，所以我们更新了课程的一些内容。

75
00:04:21,830 --> 00:04:26,285
So, uh, between me and guest lectures there's new content.
所以，呃，在我和客座讲座之间有新的内容。

76
00:04:26,285 --> 00:04:28,470
Well that look bad.
那看起来很糟糕。

77
00:04:29,030 --> 00:04:32,505
Wonder if that will keep happening, we'll find out.
不管怎么说会继续发生，我们会发现。

78
00:04:32,505 --> 00:04:38,165
There's new content and on various topics that are sort of developing areas.
有新的内容和各种主题，这些都是发展中的领域。

79
00:04:38,165 --> 00:04:41,300
One of the problems with this course is really big area of deep learning at
这门课程的一个问题是深度学习的重要领域

80
00:04:41,300 --> 00:04:44,755
the moment is still just developing really really quickly.
现在仍然只是真正快速发展。

81
00:04:44,755 --> 00:04:47,480
So, it's sort of seems like one-year-old content is already
所以，它似乎已经有一年的内容了

82
00:04:47,480 --> 00:04:51,290
things kind of data and we're trying to update things.
事情类型的数据，我们正在尝试更新的东西。

83
00:04:51,290 --> 00:04:54,140
A big change that we're making this year is we're
我们今年要做的一个重大变化就是我们

84
00:04:54,140 --> 00:04:56,930
having five-one week assignments instead of
有五个星期的任务而不是

85
00:04:56,930 --> 00:04:59,450
three-two week assignments at the beginning of
在开始的三个两周的任务

86
00:04:59,450 --> 00:05:02,795
the course and I'll say a bit more about that in a minute.
这个课程，我会在一分钟内再说一点。

87
00:05:02,795 --> 00:05:06,215
Um, this year we're gonna use PyTorch instead of TensorFlow,
嗯，今年我们要用PyTorch而不是TensorFlow，

88
00:05:06,215 --> 00:05:08,860
and we'll talk about that more later too.
我们稍后会再讨论这个问题。

89
00:05:08,860 --> 00:05:13,880
Um, we're having the assignments due before class on either Tuesday or Thursday.
嗯，我们要在课前的周二或周四完成作业。

90
00:05:13,880 --> 00:05:16,585
So you're not distracted and can come to class.
所以你不会分心，可以上课。

91
00:05:16,585 --> 00:05:20,355
So starting off, um, yeah.
所以开始，嗯，是的。

92
00:05:20,355 --> 00:05:22,680
So we're trying to give an easier,
所以我们试图让一个更容易，

93
00:05:22,680 --> 00:05:26,510
gentler ramp-up but on the other hand a fast ramp-up.
温和的提升，但另一方面快速提升。

94
00:05:26,510 --> 00:05:29,555
So we've got this first assignment which is sort of easy, uh,
所以我们有了第一个任务，这很简单，呃，

95
00:05:29,555 --> 00:05:34,040
but it's available right now and is due next Tuesday.
但它现在可用，将于下周二到期。

96
00:05:34,040 --> 00:05:37,460
And the final thing is we're not having a midterm this year.
最后一件事是我们今年没有中期。

97
00:05:37,460 --> 00:05:39,395
Um, okay.
嗯，好的。

98
00:05:39,395 --> 00:05:40,790
So this is what we're doing.
所以这就是我们正在做的事情。

99
00:05:40,790 --> 00:05:44,300
So there are five of these assignments that I just mentioned.
所以我刚才提到的这些任务中有五项。

100
00:05:44,300 --> 00:05:46,340
Um, So six percent for the first one,
嗯，第一个百分之六，

101
00:05:46,340 --> 00:05:49,090
12 percent for each of the other ones,
每个其他的12％，

102
00:05:49,090 --> 00:05:52,185
um, and, I already said that.
嗯，我已经说过了。

103
00:05:52,185 --> 00:05:54,230
We're gonna use gradescope for grading.
我们将使用成绩镜进行评分。

104
00:05:54,230 --> 00:05:56,780
It'll be really help out the TAs if you could use
如果可以的话，它将真正帮助你

105
00:05:56,780 --> 00:06:01,010
your SUnet ID as your gradescope account ID.
您的SUnet ID是您的gradecope帐户ID。

106
00:06:01,010 --> 00:06:04,205
Um, so then for the second part of the course,
嗯，那么对于课程的第二部分，

107
00:06:04,205 --> 00:06:08,795
people do a final project and there are two choices for the final project.
人们做最后的项目，最终项目有两种选择。

108
00:06:08,795 --> 00:06:12,080
You can either do our default final project,
你可以做我们默认的最终项目，

109
00:06:12,080 --> 00:06:14,030
which is a good option for many people,
对很多人来说这是个不错的选择，

110
00:06:14,030 --> 00:06:15,890
or you can do a custom final project and I'll
或者你可以做一个自定义的最终项目，我会

111
00:06:15,890 --> 00:06:19,010
talk about that in the more in the beginning.
在一开始就谈论这个。

112
00:06:19,010 --> 00:06:21,200
This is not working right.
这不行。

113
00:06:21,200 --> 00:06:25,130
Um, and so then at the end we have
嗯，所以最后我们有

114
00:06:25,130 --> 00:06:30,425
a final poster presentation session at which your attendance is expected,
最后的海报展示会，期待您的出席，

115
00:06:30,425 --> 00:06:34,580
and we're gonna be having that Wednesday in the evening.
我们将在周三晚上举行。

116
00:06:34,580 --> 00:06:37,460
Probably not quite five hours but it'll be within that window,
可能不会超过五个小时，但它会在那个窗口内，

117
00:06:37,460 --> 00:06:39,485
we'll work out the details in a bit.
我们稍后会弄清楚细节。

118
00:06:39,485 --> 00:06:41,510
Three percent for participation,
百分之三的参与，

119
00:06:41,510 --> 00:06:43,390
see the website for details.
有关详细信息，请访问网站

120
00:06:43,390 --> 00:06:45,885
Six late days, um,
六天晚些时候，嗯，

121
00:06:45,885 --> 00:06:50,330
collaboration, like always in computer science classes,
合作，就像计算机科学课一样，

122
00:06:50,330 --> 00:06:55,340
we want you to do your own work and not borrow stuff from other people's Githubs and
我们希望你做自己的工作，而不是借用其他人的Githubs和

123
00:06:55,340 --> 00:06:57,650
so we really do emphasize that you should
所以我们确实强调你应该这样做

124
00:06:57,650 --> 00:07:01,150
read and pay attention to collaboration policies.
阅读并注意协作政策。

125
00:07:01,150 --> 00:07:04,700
Okay. So here's the high level plan for the problem sets.
好的。所以这是问题集的高级计划。

126
00:07:04,700 --> 00:07:07,790
So, homework one available right now,
所以，现在可以做作业，

127
00:07:07,790 --> 00:07:10,130
is a hopefully easy on ramp.
是一个希望轻松的坡道。

128
00:07:10,130 --> 00:07:11,720
That's on iPython notebook,
这是在iPython笔记本上，

129
00:07:11,720 --> 00:07:13,565
just help get everyone up to speed.
只是帮助每个人加快速度。

130
00:07:13,565 --> 00:07:17,750
Homework two is pure Python plus numpy but that
作业二是纯粹的Python加上numpy但是那个

131
00:07:17,750 --> 00:07:22,190
will start to kind of teach you more about the sort of underlying,
会开始教你更多关于底层的东西，

132
00:07:22,190 --> 00:07:24,260
how do we do deep learning.
我们如何做深度学习。

133
00:07:24,260 --> 00:07:29,430
If you're not so good or a bit rusty or never seen um,
如果你不是那么好或有点生疏或从未见过嗯，

134
00:07:29,430 --> 00:07:31,155
Python or numpy, um,
Python或numpy，嗯，

135
00:07:31,155 --> 00:07:34,730
we're gonna have an extra section on Friday.
我们星期五会有一个额外的部分。

136
00:07:34,730 --> 00:07:38,210
So Friday from 1:30 to 2:50 um,
星期五从1:30到2:50，

137
00:07:38,210 --> 00:07:42,710
in Skilling Auditorium, we'll have a section that's a Python review.
在Skilling Auditorium中，我们将有一个Python评论部分。

138
00:07:42,710 --> 00:07:44,610
That's our only plan section at the moment,
那是我们目前唯一的计划部分，

139
00:07:44,610 --> 00:07:46,595
we're not gonna have a regular section.
我们不会有常规部分。

140
00:07:46,595 --> 00:07:49,550
Um, so encourage to go to that and that will also be
嗯，所以鼓励去那，那也是

141
00:07:49,550 --> 00:07:53,515
recorded for SCPD and available for video as well.
为SCPD录制并可用于视频。

142
00:07:53,515 --> 00:07:56,790
Um, then Homework three um,
嗯，然后家庭作业三嗯，

143
00:07:56,790 --> 00:08:00,850
will start us on using PyTorch.
我们将开始使用PyTorch。

144
00:08:00,850 --> 00:08:04,760
And then homeworks four and five we're then gonna be using
然后我们将使用四个和五个家庭作业

145
00:08:04,760 --> 00:08:08,720
py- PyTorch on GPU and we're actually gonna be using
在GPU上py-PyTorch，我们实际上将要使用

146
00:08:08,720 --> 00:08:13,520
Microsoft Azure with big thank yous to the kind Microsoft Azure people who have
Microsoft Azure非常感谢那些拥有Microsoft Azure的人

147
00:08:13,520 --> 00:08:19,165
sponsored our GPU computing for the last um, three years.
赞助我们的GPU计算最后一年，三年。

148
00:08:19,165 --> 00:08:24,995
Um, yes. So basically I mean all of modern deep learning has moved to the use
嗯，是的。所以基本上我的意思是所有现代深度学习都转向了使用

149
00:08:24,995 --> 00:08:30,589
of one or other of the large deep learning libraries like PyTorch TensorFlow,
一个或多个大型深度学习库，如PyTorch TensorFlow，

150
00:08:30,589 --> 00:08:32,210
Chainer or MXNet um,
Chainer或MXNet嗯，

151
00:08:32,210 --> 00:08:36,440
et cetera and then doing the computing on GPU.
等等，然后在GPU上进行计算。

152
00:08:36,440 --> 00:08:38,600
So of course since we're in the one building,
所以当然，因为我们在一栋楼里

153
00:08:38,600 --> 00:08:40,450
we should of course be using, um,
我们当然应该使用，嗯，

154
00:08:40,450 --> 00:08:42,620
GPUs [LAUGHTER] but I mean in general
GPU [笑声]但我的意思是一般的

155
00:08:42,620 --> 00:08:48,830
the so parallelisms scalability of GPUs is what's powered most of modern deep learning.
GPU的并行性可扩展性是大多数现代深度学习的动力。

156
00:08:48,830 --> 00:08:50,720
Okay. The final project.
好的。最后的项目。

157
00:08:50,720 --> 00:08:55,460
So for the final project there are two things that you can do.
因此，对于最终项目，您可以做两件事。

158
00:08:55,460 --> 00:09:00,665
So we have a default final project which is essentially our final project in a box.
所以我们有一个默认的最终项目，它本质上是我们在一个盒子里的最终项目。

159
00:09:00,665 --> 00:09:06,215
And so this is building a question answering system and we do it over the squad dataset.
所以这是建立一个问答系统，我们在小队数据集上做。

160
00:09:06,215 --> 00:09:11,450
So what you build and how you can improve your performance is completely up to you.
因此，您构建的内容以及如何提高性能完全取决于您。

161
00:09:11,450 --> 00:09:14,480
It is open-ended but it has an easier start,
它是开放式的，但它有一个更容易的开始，

162
00:09:14,480 --> 00:09:16,910
a clearly defined objective and we can
一个明确定义的目标，我们可以

163
00:09:16,910 --> 00:09:19,775
have a leaderboard for how well things are working.
有一个排行榜，了解事情的运作情况。

164
00:09:19,775 --> 00:09:24,680
Um, so if you don't have a clear research objective that can be a good choice for you
嗯，如果你没有一个明确的研究目标，那对你来说是个不错的选择

165
00:09:24,680 --> 00:09:29,600
or you can propose the custom Final Project and  assuming it's sensible,
或者您可以提出自定义最终项目并假设它是明智的，

166
00:09:29,600 --> 00:09:32,539
we will approve your custom final project,
我们将批准您的自定义最终项目，

167
00:09:32,539 --> 00:09:34,190
we will give you feedback, um,
我们会给你反馈，嗯，

168
00:09:34,190 --> 00:09:36,755
form someone as a mentor, um,
把某人当作导师，嗯，

169
00:09:36,755 --> 00:09:42,410
and either way for only the final project we allow teams of one, two or three.
无论哪种方式，只有最终项目我们允许一，二或三队。

170
00:09:42,410 --> 00:09:45,200
For the homework should expect it to do them yourself.
对于家庭作业应该期望它自己做。

171
00:09:45,200 --> 00:09:50,020
Of course you can chat to people in a general way about the problems.
当然，您可以通过一般方式与人们聊聊问题。

172
00:09:50,020 --> 00:09:53,010
Okay. So that is the course.
好的。这就是课程。

173
00:09:53,010 --> 00:09:55,700
All good, and not even behind schedule yet.
一切都很好，甚至还没有落后于时间表。

174
00:09:55,700 --> 00:10:01,730
Okay. So the next section is human language and word meaning.Um.
好的。所以接下来的部分是人类语言和词义。嗯。

175
00:10:01,730 --> 00:10:04,745
You know, if I was um,
你知道，如果我是，

176
00:10:04,745 --> 00:10:10,265
really going to tell you a lot about human language that would take a lot of time um,
真的会告诉你很多关于人类语言会花很多时间的事情，

177
00:10:10,265 --> 00:10:12,110
which I don't really have here.
我真的不在这里。

178
00:10:12,110 --> 00:10:14,015
So I'm just going to tell you um,
所以我只想告诉你，嗯，

179
00:10:14,015 --> 00:10:16,655
two anecdotes about human language.
关于人类语言的两个轶事。

180
00:10:16,655 --> 00:10:19,970
And the first is this XKCD cartoon.
首先是这张XKCD卡通片。

181
00:10:19,970 --> 00:10:22,520
Um, and I mean this isn't,
嗯，我的意思是这不是，

182
00:10:22,520 --> 00:10:25,110
and I don't know why that's happening.
我不知道为什么会这样。

183
00:10:26,050 --> 00:10:28,250
I'm not sure what to make of that.
我不知道该怎么做。

184
00:10:28,250 --> 00:10:34,070
Um, so, I actually really liked this XKCD cartoon.
嗯，所以，我其实非常喜欢这款XKCD卡通片。

185
00:10:34,070 --> 00:10:37,310
It's not one of the classic ones that you see most often around the place,
它不是你经常在这个地方看到的经典之作，

186
00:10:37,310 --> 00:10:42,140
but I actually think it says a lot about language and is worth thinking about.
但我实际上认为它说的很多语言，值得思考。

187
00:10:42,140 --> 00:10:45,650
Like I think a lot of the time for the kind of people who come
就像我认为很多人来的那种时候

188
00:10:45,650 --> 00:10:49,384
to this class who are mainly people like CS people,
这个班主要是CS人，

189
00:10:49,384 --> 00:10:51,950
and EE people and random others.
和EE人和随机的其他人。

190
00:10:51,950 --> 00:10:55,250
There's some other people I know since these people linguists and so on around.
自从这些人语言学家等以来，我知道其他一些人。

191
00:10:55,250 --> 00:10:57,050
But for a lot of those people like,
但对于很多人来说，

192
00:10:57,050 --> 00:11:01,610
you've sort of spent your life looking at formal languages and the impression
你有点花在生活中看正式的语言和印象

193
00:11:01,610 --> 00:11:06,185
is that sort of human language as a sort of somehow a little bit broken formal languages,
是那种人类语言，有点像一些破坏的形式语言，

194
00:11:06,185 --> 00:11:08,570
but there's really a lot more to it than that, right?
但它真的还有很多，对吗？

195
00:11:08,570 --> 00:11:11,165
That language is this amazing um,
那语言真是太神奇了，

196
00:11:11,165 --> 00:11:15,110
human created system that is used for
人类创建的系统用于

197
00:11:15,110 --> 00:11:19,520
all sorts of purposes and is adaptable to all sorts of purposes.
各种各样的目的，适应各种目的。

198
00:11:19,520 --> 00:11:23,750
So you can do everything from describing mathematics and human language
所以你可以通过描述数学和人类语言来做所有事情

199
00:11:23,750 --> 00:11:28,520
um to sort of nuzzling up to your best friend and getting them to understand you better.
嗯，为了你最好的朋友，让他们更好地了解你。

200
00:11:28,520 --> 00:11:31,910
So there's actually an amazing thing of human language. Anyway, I'll just read it.
所以人类语言实际上是一件令人惊奇的事情。无论如何，我只是读它。

201
00:11:31,910 --> 00:11:34,655
Um, so it's the first person,
嗯，所以这是第一个人，

202
00:11:34,655 --> 00:11:36,185
the dark haired person says,
黑头发的人说，

203
00:11:36,185 --> 00:11:38,105
"Anyway, I could care less."
“无论如何，我可以少关心。”

204
00:11:38,105 --> 00:11:40,010
And her friend says,
而她的朋友说，

205
00:11:40,010 --> 00:11:42,440
"I think you mean you couldn't care less."
“我想你的意思是你不在乎。”

206
00:11:42,440 --> 00:11:46,490
Saying you could care less implies you care at least some amount.
说你可以少关心意味着你至少关心一些金额。

207
00:11:46,490 --> 00:11:49,775
And the dark haired person says, "I don't know,
黑头发的人说：“我不知道，

208
00:11:49,775 --> 00:11:54,590
we're these unbelievably complicated brains drifting through a void trying
我们是这些令人难以置信的复杂大脑在虚空中徘徊

209
00:11:54,590 --> 00:11:59,630
in vain to connect with one another by blindly flinging words out into the darkness."
盲目地将文字扔进黑暗中，相互联系是徒劳的。“

210
00:11:59,630 --> 00:12:02,720
Every choice of phrasing and spelling, and tone,
每个选择的措辞和拼写，以及语气，

211
00:12:02,720 --> 00:12:07,775
and timing carries countless signals and contexts and subtexts and more.
和时间带有无数的信号和上下文和子文字等等。

212
00:12:07,775 --> 00:12:11,435
And every listener interprets those signals in their own way.
每个听众都以自己的方式解释这些信号。

213
00:12:11,435 --> 00:12:13,565
Language isn't a formal system,
语言不是正式的系统，

214
00:12:13,565 --> 00:12:16,235
language is glorious chaos.
语言是光荣的混乱。

215
00:12:16,235 --> 00:12:20,750
You can never know for sure what any words will mean to anyone.
你永远无法确定任何单词对任何人都意味着什么。

216
00:12:20,750 --> 00:12:26,150
All you can do is try to get better at guessing how your words affect people so
你所能做的就是尽量好好猜测你的话语如何影响人们

217
00:12:26,150 --> 00:12:28,790
you can have a chance of finding the ones that will make
你有机会找到那些会做的

218
00:12:28,790 --> 00:12:31,790
them feel something like what you want them to feel.
他们感受到了你想让他们感受到的东西。

219
00:12:31,790 --> 00:12:34,235
Everything else is pointless.
其他一切都毫无意义。

220
00:12:34,235 --> 00:12:37,390
I assume you're giving me tips on how you interpret
我假设你给我提示你如何解释

221
00:12:37,390 --> 00:12:41,065
words because you want me to feel less alone.
因为你希望我感觉不那么孤单。

222
00:12:41,065 --> 00:12:43,510
If so, thank you.
如果是的话，谢谢。

223
00:12:43,510 --> 00:12:45,585
That means a lot.
这意味着很多。

224
00:12:45,585 --> 00:12:48,440
But if you're just running my sentences past
但是，如果你只是把我的句子过去了

225
00:12:48,440 --> 00:12:51,785
some mental checklist so you can show off how well you know it,
一些心理检查表，以便你可以炫耀你对它的了解程度，

226
00:12:51,785 --> 00:12:53,180
then I could care less.
然后我可以少关心。

227
00:12:53,180 --> 00:13:02,825
[NOISE] Um, and so I think um,
[NOISE]嗯，所以我想，嗯，

228
00:13:02,825 --> 00:13:07,790
I think actually this has some nice messages about how language is this uncertain
我认为实际上这有一些关于语言如何不确定的好消息

229
00:13:07,790 --> 00:13:13,340
evolved system of communication but somehow we have enough agreed meaning that you know,
进化的通信系统，但不知何故，我们有足够的同意，你知道，

230
00:13:13,340 --> 00:13:15,500
we can kind of pretty much communicate.
我们几乎可以沟通。

231
00:13:15,500 --> 00:13:16,865
But we're doing some kind of you know
但我们正在做某种你知道的事情

232
00:13:16,865 --> 00:13:20,540
probabilistic inference of guessing what people mean and we're
猜测人们的意思和我们的概率推理

233
00:13:20,540 --> 00:13:22,070
using language not just for
使用语言不仅仅是为了

234
00:13:22,070 --> 00:13:26,195
the information functions but for the social functions etc etc.
信息功能，但社会功能等。

235
00:13:26,195 --> 00:13:32,310
Okay. And then here's my one other thought I had review about language.
好的。然后这是我的另一个想法，我已经审查了语言。

236
00:13:33,490 --> 00:13:40,565
So, essentially if we want to have artificial intelligence that's intelligent,
所以，基本上如果我们想拥有智能的人工智能，

237
00:13:40,565 --> 00:13:43,940
what we need to somehow get to the point of having
我们需要以某种方式达到目的

238
00:13:43,940 --> 00:13:48,560
compu- computers that have the knowledge of human beings, right?
拥有人类知识的计算机，对吧？

239
00:13:48,560 --> 00:13:52,430
Because human beings have knowledge that gives them intelligence.
因为人类拥有能够为他们提供智慧的知识。

240
00:13:52,430 --> 00:13:55,460
And if you think about how we sort of
如果你考虑我们如何排序

241
00:13:55,460 --> 00:13:59,270
convey knowledge around the place in our human world,
传达我们人类世界中的知识，

242
00:13:59,270 --> 00:14:04,025
mainly the way we do it is through human language.
主要是我们这样做的方式是通过人类语言。

243
00:14:04,025 --> 00:14:06,410
You know, some kinds of knowledge you can sort of
你知道，你可以使用某些类型的知识

244
00:14:06,410 --> 00:14:09,260
work out for yourself by doing physical stuff right,
通过做正确的事情来为自己锻炼，

245
00:14:09,260 --> 00:14:11,900
I can hold this and drop that and I've learnt something.
我能抓住这一点并放弃它，我已经学到了一些东西。

246
00:14:11,900 --> 00:14:13,760
So I have to learn a bit of knowledge there.
所以我必须在那里学到一些知识。

247
00:14:13,760 --> 00:14:17,180
But sort of most of the knowledge in your heads and why you're sitting in
但是你头脑中的大部分知识和你为什么坐在那里

248
00:14:17,180 --> 00:14:21,980
this classroom has come from people communicating in human language to you.
这个教室来自人们用人类语言沟通的人。

249
00:14:21,980 --> 00:14:24,260
Um, so one of the famous,
嗯，所以其中一个着名的，

250
00:14:24,260 --> 00:14:26,990
most famous steep learning people Yann Le Cun,
最着名的陡峭学习者Yann Le Cun，

251
00:14:26,990 --> 00:14:29,165
he likes to say this line about,
他喜欢说这句话，

252
00:14:29,165 --> 00:14:33,380
oh, you know really I think that you know there's not much difference
哦，你知道我认为你知道没有太大区别

253
00:14:33,380 --> 00:14:37,965
between the intelligence of human being and orangutan.
在人类的智慧和猩猩之间。

254
00:14:37,965 --> 00:14:40,510
And I actually think he's really wrong on that.
而我实际上认为他真的错了。

255
00:14:40,510 --> 00:14:42,790
Like the sense in which he means that is,
就像他所说的意义一样，

256
00:14:42,790 --> 00:14:45,835
an orangutan has a really good vision system.
猩猩有一个非常好的视觉系统。

257
00:14:45,835 --> 00:14:48,610
Orangutans have very good you know control of
你知道猩猩非常善于控制

258
00:14:48,610 --> 00:14:52,060
their arms just like human beings for picking things up.
他们的手臂就像人类一样捡东西。

259
00:14:52,060 --> 00:14:58,970
Orangutans um can use tools um and orangutans can make plans so
猩猩可以使用工具，猩猩可以制定计划

260
00:14:58,970 --> 00:15:02,270
that if you sort of put the food somewhere where they have to sort of move
如果你把食物放在他们必须移动的地方

261
00:15:02,270 --> 00:15:05,960
the plank to get to the island with the food they can do a plan like that.
用食物来到岛上的木板，他们可以做这样的计划。

262
00:15:05,960 --> 00:15:09,890
So yeah, in a sense they've got a fair bit of intelligence but you know,
所以是的，从某种意义上说，他们有一点智慧，但你知道，

263
00:15:09,890 --> 00:15:13,385
sort of orangutans just aren't like human beings.
有点猩猩不像人类。

264
00:15:13,385 --> 00:15:16,100
And why aren't they like human beings?
他们为什么不喜欢人类？

265
00:15:16,100 --> 00:15:21,605
And I'd like to suggest to you the reason for that is what human beings have achieved is,
我想告诉你，人类取得的成就是什么，

266
00:15:21,605 --> 00:15:25,070
we don't just have sort of one computer like
我们不仅仅有一台计算机

267
00:15:25,070 --> 00:15:29,825
a you know dusty old IBM PC in your mother's garage.
你知道母亲车库里装满尘土的旧PC。

268
00:15:29,825 --> 00:15:33,740
What we have is a human computer network.
我们拥有的是人机界面。

269
00:15:33,740 --> 00:15:37,520
And the way that we've achieved that human computer network is that,
我们实现人机计算机网络的方式是，

270
00:15:37,520 --> 00:15:41,285
we use human languages as our networking language.
我们使用人类语言作为我们的网络语言。

271
00:15:41,285 --> 00:15:44,690
Um, and so, when you think about it um,
嗯，当你想到它时，嗯，

272
00:15:44,690 --> 00:15:51,815
so on any kind of evolutionary scale language is super super super super recent, right?
那么任何一种进化规模的语言都是超级超级超级近期，对吧？

273
00:15:51,815 --> 00:15:57,470
That um, creatures have had vision for people don't quite know but you know,
那个嗯，生物对人有远见但不知道，但你知道，

274
00:15:57,470 --> 00:16:00,980
maybe it's 75 million years or maybe it's longer, right?
也许它是7500万年或者可能更长，对吧？

275
00:16:00,980 --> 00:16:03,845
A huge length of time.
很长的时间。

276
00:16:03,845 --> 00:16:07,295
How long have human beings have had language?
人类有多长时间有语言？

277
00:16:07,295 --> 00:16:09,860
You know people don't know that either because it turns out you know,
你知道人们也不知道，因为结果你知道，

278
00:16:09,860 --> 00:16:11,015
when you have fossils,
当你有化石时，

279
00:16:11,015 --> 00:16:13,490
you can't knock the skull on the side and say,
你不能把头骨撞到一边然后说，

280
00:16:13,490 --> 00:16:15,050
do you not have language.
你没有语言吗？

281
00:16:15,050 --> 00:16:19,100
Um, but you know, most people estimate that sort of language is
嗯，但是你知道，大多数人估计那种语言是

282
00:16:19,100 --> 00:16:25,985
a very recent invention before current human beings moved out of um, out of Africa.
在现在的人类离开非洲之前，这是一项非常新的发明。

283
00:16:25,985 --> 00:16:28,550
So that many people think that we've only had language for
因此，许多人认为我们只有语言

284
00:16:28,550 --> 00:16:31,460
something like a 100,000 years or something like that.
像10万年或类似的事情。

285
00:16:31,460 --> 00:16:35,450
So that's sort of you know blink of an eye on the evolutionary timescale.
因此，您可以在进化时间尺度上眨眼。

286
00:16:35,450 --> 00:16:39,740
But you know, it was the development of language [inaudible]
但是你知道，这是语言的发展[音频不清晰]

287
00:16:39,740 --> 00:16:43,970
that sort of made human beings invisible- [NOISE] in invincible, right?
这种让人类看不见 -  [NOISE]立于不败之地，对吧？

288
00:16:43,970 --> 00:16:46,475
It wasn't that, human beings um,
不是这样，人类嗯，

289
00:16:46,475 --> 00:16:51,410
developed poison fangs or developed ability to run
发展出毒牙或发达的能力

290
00:16:51,410 --> 00:16:53,660
faster than any other creature or
比任何其他生物或更快

291
00:16:53,660 --> 00:16:56,210
put a big horn on their heads or something like that, right?
在他们的头上放一个大喇叭或类似的东西，对吧？

292
00:16:56,210 --> 00:16:59,060
You know, humans are basically pretty puny um,
你知道，人类基本上都很乖，

293
00:16:59,060 --> 00:17:01,190
but they had this um,
但他们有这个，

294
00:17:01,190 --> 00:17:04,310
unbeatable advantage that they could communicate with
他们可以与之沟通的无与伦比的优势

295
00:17:04,310 --> 00:17:07,880
each other and therefore work much more effectively in teams.
彼此，因此在团队中更有效地工作。

296
00:17:07,880 --> 00:17:11,495
And that sort of basically made human beings invincible.
而这种基本上使人类立于不败之地。

297
00:17:11,495 --> 00:17:15,575
But you know, even then humans were kind of limited, right?
但是你知道，即使那时人类也有限，对吧？

298
00:17:15,575 --> 00:17:18,140
That kind of got you to about the Stone Age right,
那种让你了解石器时代的权利，

299
00:17:18,140 --> 00:17:20,390
where you could bang on your stones and with
在那里你可以敲打你的石头和

300
00:17:20,390 --> 00:17:23,240
the right kind of stone make something sharp to cut with.
正确的石头使切割的东西变得锋利。

301
00:17:23,240 --> 00:17:25,685
Um, what got humans beyond that,
嗯，是什么让人类超越了这个，

302
00:17:25,685 --> 00:17:28,100
was that they invented writing.
是他们发明了写作。

303
00:17:28,100 --> 00:17:32,915
So writing was then an ability where you could take knowledge
因此，写作是一种你可以学习知识的能力

304
00:17:32,915 --> 00:17:37,730
not only communicated um mouth to mouth to people that you saw.
不仅与你见过的人口口相传。

305
00:17:37,730 --> 00:17:41,660
You could put it down on your piece of papyrus so your clay tablet or whatever
你可以把它放在你的纸莎草上，这样你的粘土片或其他什么

306
00:17:41,660 --> 00:17:45,620
it was at first and that knowledge could then be sent places.
起初它是知识，然后可以发送知识。

307
00:17:45,620 --> 00:17:50,270
It could be sent spatially around the world and it could then
它可以在世界范围内空间发送，然后可以

308
00:17:50,270 --> 00:17:55,430
be sent temporally through time.
通过时间暂时发送。

309
00:17:55,430 --> 00:17:57,290
And well, how old is writing?
好吧，写作多大了？

310
00:17:57,290 --> 00:18:00,890
I mean, we sort of basically know about how old writing is, right?
我的意思是，我们基本上都知道写作有多久，对吧？

311
00:18:00,890 --> 00:18:04,115
That writing is about 5,000 years old.
那篇文章大约有5000年的历史。

312
00:18:04,115 --> 00:18:09,740
It's incredibly incredibly recent on this scale of evolution but you know,
在这种进化规模上，这是令人难以置信的最近，但你知道，

313
00:18:09,740 --> 00:18:16,730
essentially writing was so powerful as a way of having knowledge that then in those 5,000
基本上写作是如此强大，以至于拥有知识的方式，然后在那5000个

314
00:18:16,730 --> 00:18:24,035
years that enabled human beings to go from stone age sharp piece or flint to you know,
多年让人类从石器时代的尖锐片段或燧石中走出来，你知道，

315
00:18:24,035 --> 00:18:26,240
having iPhones and all of these things,
拥有iPhone和所有这些东西，

316
00:18:26,240 --> 00:18:28,790
all these incredibly sophisticated devices.
所有这些非常复杂的设备。

317
00:18:28,790 --> 00:18:32,960
So, language is pretty special thing I'd like to suggest.
因此，语言是我想提出的非常特别的事情。

318
00:18:32,960 --> 00:18:37,910
Um, but you know, if I go back to my analogy that sort of it's allowed humans to
嗯，但是你知道，如果我回到我的类比，那是允许人类做的那种

319
00:18:37,910 --> 00:18:43,280
construct a networked computer that is way way more powerful than um,
构建一个比um更强大的联网计算机，

320
00:18:43,280 --> 00:18:47,600
just having individual creatures as sort of intelligent like an orangutan.
只是让个体生物像猩猩一样聪明。

321
00:18:47,600 --> 00:18:50,525
Um, and you compare it to our computer networks,
嗯，你把它与我们的计算机网络进行比较，

322
00:18:50,525 --> 00:18:53,045
it's a really funny kind of network, right?
这是一个非常有趣的网络，对吧？

323
00:18:53,045 --> 00:18:55,745
You know that these days um,
你知道这些天嗯，

324
00:18:55,745 --> 00:19:01,805
we have networks that run around where we have sort of large network bandwidth, right?
我们有网络，我们有大量的网络带宽，对吧？

325
00:19:01,805 --> 00:19:03,770
You know, we might be frustrated sometimes with
你知道，我们有时可能会感到沮丧

326
00:19:03,770 --> 00:19:06,530
our Netflix downloads but by and large you know,
我们的Netflix下载但总的来说，你知道，

327
00:19:06,530 --> 00:19:09,755
we can download hundreds of megabytes really easily and quickly.
我们可以非常轻松快速地下载数百兆字节。

328
00:19:09,755 --> 00:19:11,570
And we don't think that's fast enough,
我们认为这不够快，

329
00:19:11,570 --> 00:19:13,670
so we're going to be rolling out 5G networks.
所以我们将推出5G网络。

330
00:19:13,670 --> 00:19:16,400
So it's an order of magnitude faster again.
所以它再次快一个数量级。

331
00:19:16,400 --> 00:19:18,800
I mean, by comparison to that, I mean,
我的意思是，相比之下，我的意思是，

332
00:19:18,800 --> 00:19:23,540
human language is a pathetically slow network, right?
人类语言是一个可怜的慢网络吧？

333
00:19:23,540 --> 00:19:29,465
That the amount of information you can convey by human language is very slow.
您可以通过人类语言传达的信息量非常慢。

334
00:19:29,465 --> 00:19:33,950
I mean you know, whatever it is I sort of speak at about 15 words a second right,
我的意思是你知道，无论是什么，我都会说出大约15个单词的权利，

335
00:19:33,950 --> 00:19:35,420
you can start doing um,
你可以开始做嗯，

336
00:19:35,420 --> 00:19:37,550
your information theory if you know some right?
你的信息理论，如果你知道一些吗？

337
00:19:37,550 --> 00:19:41,060
But um, you don't actually get much bandwidth at all.
但是，嗯，实际上你根本没有获得多少带宽。

338
00:19:41,060 --> 00:19:44,405
And that then leads- so you can think of,
然后导致 - 所以你可以想到，

339
00:19:44,405 --> 00:19:45,980
how does it work then?
它是如何工作的呢？

340
00:19:45,980 --> 00:19:47,570
So, humans have come up with
所以，人类已经想到了

341
00:19:47,570 --> 00:19:53,390
this incredibly impressive system which is essentially form of compression.
这个令人难以置信的令人印象深刻的系

342
00:19:53,390 --> 00:19:56,120
Sort of a very adaptive form of compression,
一种非常自适应的压缩形式，

343
00:19:56,120 --> 00:19:58,070
so that when we're talking to people,
这样当我们与人交谈时，

344
00:19:58,070 --> 00:20:02,870
we assume that they have an enormous amount of knowledge in their heads which
我们假设他们头脑中有大量的知识

345
00:20:02,870 --> 00:20:07,640
isn't the same as but it's broadly similar to mine when I'm talking to you right?
当我和你说话的时候，它与我的大致相似？

346
00:20:07,640 --> 00:20:10,565
That you know what English words mean,
你知道英文单词的意思，

347
00:20:10,565 --> 00:20:13,850
and you know a lot about how the wor- world works.
而且你对这个世界的运作方式了解很多。

348
00:20:13,850 --> 00:20:17,149
And therefore, I can say a short message and communicate
因此，我可以说一条短信并进行沟通

349
00:20:17,149 --> 00:20:22,820
only a relatively short bit string and you can actually understand a lot. All right?
只有一个相对较短的位串，你实际上可以理解很多。行？

350
00:20:22,820 --> 00:20:26,030
So, I can say sort of whatever you know,
所以，我可以说你所知道的一切，

351
00:20:26,030 --> 00:20:28,850
imagine a busy shopping mall and that
想象一下繁忙的购物中心

352
00:20:28,850 --> 00:20:31,630
there are two guys standing in front of a makeup counter,
有两个人站在化妆柜台前，

353
00:20:31,630 --> 00:20:36,290
and you know I've only said whatever that was sort of about 200 bits of
而且你知道我只说了大约200比特的东西

354
00:20:36,290 --> 00:20:38,960
information but that's enabled you to construct
信息，但这使你能够构建

355
00:20:38,960 --> 00:20:42,340
a whole visual scene that we're taking megabytes to um,
一个完整的视觉场景，我们花费了几兆字节，

356
00:20:42,340 --> 00:20:44,385
represent as an image.
表示为图像。

357
00:20:44,385 --> 00:20:46,625
So, that's why language is good.
所以，这就是语言好的原因。

358
00:20:46,625 --> 00:20:49,100
Um, so from that more authorial level,
嗯，从更多的作者级别来看，

359
00:20:49,100 --> 00:20:51,425
I'll now move back to the concrete stuff.
我现在回到具体的东西。

360
00:20:51,425 --> 00:20:55,925
What we wanna do in this class is not solve the whole of language,
我们想在这堂课中做的不是解决整个语言，

361
00:20:55,925 --> 00:20:57,950
but we want to represent, um,
但我们要代表，嗯，

362
00:20:57,950 --> 00:21:00,380
the meaning of words, right?
话语的意思吧？

363
00:21:00,380 --> 00:21:03,230
So, a lot of language is bound up in words and their meanings
所以，很多语言都与单词及其含义有关

364
00:21:03,230 --> 00:21:06,200
and words can have really rich meanings, right?
言语可以有丰富的意义，对吧？

365
00:21:06,200 --> 00:21:07,970
As soon as you say a word teacher,
一说一句老师，

366
00:21:07,970 --> 00:21:12,530
that's kinda quite a lot of rich meaning or you can have actions that have rich meaning.
这有很多丰富的意义，或者你可以采取具有丰富意义的行动。

367
00:21:12,530 --> 00:21:17,225
So, if I say a word like prognosticate or,
所以，如果我说一个像预测的话，或者，

368
00:21:17,225 --> 00:21:19,070
um, total or something you know,
嗯，总或你知道的，

369
00:21:19,070 --> 00:21:22,385
these words that have rich meanings and a lot of nuance on them.
这些词语含义丰富，细微之处。

370
00:21:22,385 --> 00:21:24,395
And so we wanna represent meaning.
所以我们想要代表意义。

371
00:21:24,395 --> 00:21:26,510
And so, the question is what is meaning?
所以，问题是什么意思？

372
00:21:26,510 --> 00:21:29,360
So, you can of course you can- dictionaries are meant to tell you about meanings.
所以，你当然可以告诉你有关词义的意思。

373
00:21:29,360 --> 00:21:31,490
So, you can look up dictionaries um,
所以，你可以查找词典，嗯，

374
00:21:31,490 --> 00:21:35,720
and Webster says sort of tries to relate meaning to idea.
而韦伯斯特则试图将意义与想法联系起来。

375
00:21:35,720 --> 00:21:39,515
The idea that is represented by a word or a phrase.
由单词或短语表示的想法。

376
00:21:39,515 --> 00:21:44,240
The idea that a person wants to express by word signs et cetera.
一个人想通过文字符号等表达的想法。

377
00:21:44,240 --> 00:21:46,190
I mean, you know,
我的意思是，你知道，

378
00:21:46,190 --> 00:21:49,730
you could think that these definitions are kind of a cop-out because it seems
你可以认为这些定义似乎是一种警察，因为它似乎

379
00:21:49,730 --> 00:21:53,015
like they're rewriting meaning in terms of the word idea,
就像他们用词的想法重写意义一样，

380
00:21:53,015 --> 00:21:55,040
and is that really gotten you anywhere.
这真的让你在任何地方。

381
00:21:55,040 --> 00:21:58,370
Um, how do linguists think about meaning?
嗯，语言学家如何看待意义？

382
00:21:58,370 --> 00:22:03,110
I mean, the most common way that linguists have thought about
我的意思是，语言学家最常见的思考方式

383
00:22:03,110 --> 00:22:05,660
meaning is an idea that's called denotational
意思是一种被称为指称的想法

384
00:22:05,660 --> 00:22:08,420
semantics which is also used in programming languages.
语义，也用于编程语言。

385
00:22:08,420 --> 00:22:14,810
So, the idea of that is we think of meaning as what things represent.
所以，我们的想法是将意义视为事物的代表。

386
00:22:14,810 --> 00:22:16,955
So, if I say the word chair,
所以，如果我说“椅子”这个词，

387
00:22:16,955 --> 00:22:21,140
the denotation of the word chair includes this one here and that one,
主题一词的含​​义包括这一个和那一个，

388
00:22:21,140 --> 00:22:22,325
that one, that one, that one.
那个，那一个，那个。

389
00:22:22,325 --> 00:22:24,919
And so, the word chair is sort of representing
因此，椅子这个词有点代表

390
00:22:24,919 --> 00:22:28,580
all the things that are chairs and you can sort of, um,
所有椅子都可以，你可以这样，嗯，

391
00:22:28,580 --> 00:22:33,410
you can then think of something like running as well that you know there's sort of sets
然后，你可以想到像跑步一样的东西，你知道那里有一套

392
00:22:33,410 --> 00:22:37,985
of actions that people can partake that- that's their denotation.
人们可以参与的行动 - 这是他们的外延。

393
00:22:37,985 --> 00:22:42,200
And that's sort of what you most commonly see in philosophy or linguistics as denotation.
这就是你在哲学或语言学中最常见的那些作为外延的东西。

394
00:22:42,200 --> 00:22:47,135
It's kind of a hard thing to get your hands on, um, computationally.
这是一件很难接触的事，嗯，计算上。

395
00:22:47,135 --> 00:22:50,480
So, um, what type of people most commonly
所以，嗯，最常见的是什么类型的人

396
00:22:50,480 --> 00:22:54,020
do or use the most commonly do I guess I should say now
做或最常用的我想我现在应该说

397
00:22:54,020 --> 00:22:57,530
for working out the meaning of words on the computer that
用于解决计算机上的文字含义

398
00:22:57,530 --> 00:23:01,115
commonly that turn to something that was a bit like a dictionary.
通常转向有点像字典的东西。

399
00:23:01,115 --> 00:23:06,200
In particular favorite online thing was this online thesaurus called WordNet which
特别喜欢在线的东西是这个名为WordNet的在线词库

400
00:23:06,200 --> 00:23:11,510
sort of tells you about word meanings and relationships between word meanings.
有点告诉你关于词义和词义之间的关系。

401
00:23:11,510 --> 00:23:16,445
Um, so this is just giving you the very slices sense of,
嗯，所以这只是给你切片的感觉，

402
00:23:16,445 --> 00:23:19,820
um, of what's in WordNet.
嗯，WordNet中的内容。

403
00:23:19,820 --> 00:23:24,485
Um, so this is an actual bit of Python code up there which you can,
嗯，所以这是一个Python代码的实际位，你可以，

404
00:23:24,485 --> 00:23:28,370
um, type into your computer and run and do this for yourself.
嗯，输入您的计算机并运行并为自己执行此操作。

405
00:23:28,370 --> 00:23:31,040
Um, so this uses a thing called NLTK.
嗯，所以这使用了一个名为NLTK的东西。

406
00:23:31,040 --> 00:23:33,725
Um, so NLTK is sort of like
嗯，所以NLTK有点像

407
00:23:33,725 --> 00:23:39,364
the "Swiss Army Knife of NLP" meaning that it's not terribly good for anything,
“NLP的瑞士军刀”意味着它对任何东西都不是非常好，

408
00:23:39,364 --> 00:23:41,570
but it has a lot of basic tools.
但它有很多基本工具。

409
00:23:41,570 --> 00:23:46,460
So, if you wanted to do something like just get some stuff out of WordNet and show it,
所以，如果你想做一些事情，比如从WordNet中获取一些东西并展示它，

410
00:23:46,460 --> 00:23:49,625
it's the perfect thing to use. Um, okay.
这是完美的选择。嗯，好的。

411
00:23:49,625 --> 00:23:54,830
So, um, from NLTK I'm importing WordNet and so then I can say,
所以，嗯，来自NLTK，我正在导入WordNet，所以我可以说，

412
00:23:54,830 --> 00:24:01,355
"Okay, um, for the word good tell me about the synonym sets with good participates in."
“好吧，嗯，好的这个词告诉我关于同义词集的好参与。”

413
00:24:01,355 --> 00:24:03,440
And there's good goodness as a noun.
并且作为名词有很好的善良。

414
00:24:03,440 --> 00:24:04,760
There is an adjective good.
形容词很好。

415
00:24:04,760 --> 00:24:08,330
There's one estimable good, honorable, respectable.
有一个可敬的好，尊贵，可敬。

416
00:24:08,330 --> 00:24:11,150
Um, this looks really complex and hard to understand.
嗯，这看起来很复杂，很难理解。

417
00:24:11,150 --> 00:24:13,700
But the idea of word- WordNet makes
但是WordNet的想法使得

418
00:24:13,700 --> 00:24:18,080
these very fine grain distinctions between senses of a word.
这些非常精细的细微差别在一个词的意义之间。

419
00:24:18,080 --> 00:24:20,675
So, what sort of saying for good, um,
那么，什么样的好说，嗯，

420
00:24:20,675 --> 00:24:23,570
there's what some sensors where it's a noun, right?
有些传感器就是名词，对吧？

421
00:24:23,570 --> 00:24:24,755
That's where you sort of,
那是你的地方，

422
00:24:24,755 --> 00:24:27,200
I bought some goods for my trip, right?
我为我的旅行买了一些货，对吗？

423
00:24:27,200 --> 00:24:28,880
So, that's sort of, um,
所以，那是那种，嗯，

424
00:24:28,880 --> 00:24:32,780
one of these noun sensors like this one I guess.
我猜这些名词传感器就像这样一个。

425
00:24:32,780 --> 00:24:35,480
Um, then there are adjective sensors and it's trying to
嗯，然后有形容词传感器，它正在尝试

426
00:24:35,480 --> 00:24:38,840
distinguish- there's a basic adjective sense of good being good,
区分 - 有一个基本的形容词良好的感觉，

427
00:24:38,840 --> 00:24:41,270
and then in certain, um, sensors,
然后在某些，嗯，传感器，

428
00:24:41,270 --> 00:24:44,750
there are these extended sensors of good in different directions.
这些扩展的传感器在不同方向上都很好。

429
00:24:44,750 --> 00:24:48,515
So, I guess this is good in the sense of beneficial, um,
所以，我觉得从有益的意义上说这是好的，嗯，

430
00:24:48,515 --> 00:24:52,925
and this one is sort of person who is respectable or something.
这个人是一个受人尊敬的人。

431
00:24:52,925 --> 00:24:55,580
He's a good man or something like that, right?
他是个好人或类似的东西，对吗？

432
00:24:55,580 --> 00:24:56,855
So, um, but you know,
所以，嗯，但你知道，

433
00:24:56,855 --> 00:24:59,660
part of what's kind of makes us
是什么让我们的一部分

434
00:24:59,660 --> 00:25:02,630
think very problematic and practice to use is it tries to make
认为非常有问题，并且尝试使用它是试图制造的

435
00:25:02,630 --> 00:25:06,850
all these very fine-grain differences between sensors that are a human being can
所有这些人类传感器之间的细微差别都可以

436
00:25:06,850 --> 00:25:11,410
barely understand the difference between them um, and relate to.
勉强理解他们之间的区别，并与之相关。

437
00:25:11,410 --> 00:25:13,690
Um, so you can then do other things with WordNet.
嗯，所以你可以用WordNet做其他事情。

438
00:25:13,690 --> 00:25:18,460
So, this bit of code you can sort of well walk up and is a kind of hierarchy.
所以，这些代码你可以很好地走，并且是一种层次结构。

439
00:25:18,460 --> 00:25:21,635
So, it's kinda like a traditional, um, database.
所以，它有点像传统的嗯数据库。

440
00:25:21,635 --> 00:25:29,030
So, if I start with a panda and say- [NOISE] if I start with a panda.
所以，如果我从一只熊猫开始说 - 如果我从一只熊猫开始说 -  [NOISE]。

441
00:25:29,030 --> 00:25:32,180
Um, and walk up, um,
嗯，走吧，嗯，

442
00:25:32,180 --> 00:25:35,330
the pandas are [inaudible].
大熊猫是[音频不清晰]。

443
00:25:35,330 --> 00:25:37,640
Maybe you'd guys to bio which are carnivores,
也许你们是生物学的食肉动物，

444
00:25:37,640 --> 00:25:39,545
placentals, mammals, blah, blah, blah.
胎盘，哺乳动物，等等，等等等等。

445
00:25:39,545 --> 00:25:44,135
Okay, so, um, that's the kind of stuff you can get out to- out of WordNet.
好吧，那么，嗯，这就是你可以从WordNet中获得的东西。

446
00:25:44,135 --> 00:25:47,105
Um, you know, in practice WordNet has been.
嗯，你知道，在实践中WordNet一直都是。

447
00:25:47,105 --> 00:25:49,580
Everyone sort of used to use it because it gave
每个人都习惯使用它，因为它给了

448
00:25:49,580 --> 00:25:51,995
you some sort of sense of the meaning of the word.
你对某个词的含义有某种意义。

449
00:25:51,995 --> 00:25:54,125
But you know it's also sort of well-known.
但是你知道它也是众所周知的。

450
00:25:54,125 --> 00:25:56,540
It never worked that well.
它从来没有那么好用。

451
00:25:56,540 --> 00:26:02,720
Um, so you know that sort of the synonym sets miss a lot of nuance.
嗯，所以你知道那种同义词集错过了很多细微差别。

452
00:26:02,720 --> 00:26:05,270
So, you know one of the synonym sets for good has
所以，你知道一个好的同义词集

453
00:26:05,270 --> 00:26:08,240
proficient in it and good sort of like proficient
精通它，好像精通

454
00:26:08,240 --> 00:26:11,495
but doesn't proficient have some more connotations and nuance?
但是不熟练有一些内涵和细微差别？

455
00:26:11,495 --> 00:26:13,250
I think it does.
我认为确实如此。

456
00:26:13,250 --> 00:26:18,080
Um, WordNet like most hand built resources is sort of very incomplete.
嗯，WordNet像大多数手工制作的资源一样非常不完整。

457
00:26:18,080 --> 00:26:21,290
So, as soon as you're coming to new meanings of words,
所以，只要你想要新的含义，

458
00:26:21,290 --> 00:26:23,705
or new words and slang words,
或者新词和俚语，

459
00:26:23,705 --> 00:26:25,310
well then, that gives you nothing.
那么，那什么都没给你。

460
00:26:25,310 --> 00:26:28,985
Um, it's sort of built with human labor,
嗯，它是用人工建造的，

461
00:26:28,985 --> 00:26:35,030
um, in ways that you know it's hard to sort of create and adapt.
嗯，以你知道的方式很难创造和适应。

462
00:26:35,030 --> 00:26:37,670
And in particular, what we want to focus on is,
特别是，我们要关注的是，

463
00:26:37,670 --> 00:26:41,870
seems like a basic thing you'd like to do with words and it's actually at least
看起来像是你想用文字做的基本事情，实际上至少是这样

464
00:26:41,870 --> 00:26:45,920
understand similarities and relations between the meaning of words.
理解词语意义之间的相似性和关系。

465
00:26:45,920 --> 00:26:49,520
And it turns out that you know WordNet doesn't actually do that that well
事实证明，你知道WordNet实际上并没有这么做

466
00:26:49,520 --> 00:26:53,600
because it just has these sort of fixed discrete synonym sets.
因为它只有这些固定的离散同义词集。

467
00:26:53,600 --> 00:26:56,090
So, if you have a words in a synonym said that there's
所以，如果你有一个同义词中的单词说有

468
00:26:56,090 --> 00:26:59,075
sort of a synonym and maybe not exactly the same meaning,
一种同义词，可能不完全相同，

469
00:26:59,075 --> 00:27:00,800
they're not in the same synonyms set,
它们不在同一个同义词集中，

470
00:27:00,800 --> 00:27:04,580
you kind of can't really measure the partial resemblance as a meaning for them.
你有点无法将部分相似性视为对他们的意义。

471
00:27:04,580 --> 00:27:08,435
So, if something like good and marvelous aren't in the same synonym set,
所以，如果好的和奇妙的东西不在同一个同义词集中，

472
00:27:08,435 --> 00:27:11,960
but there's something that they share in common that you'd like to represent.
但是他们有一些你想要代表的共同点。

473
00:27:11,960 --> 00:27:16,880
Okay. So, um, that's kinda turn to lead into
好的。所以，嗯，这有点转向

474
00:27:16,880 --> 00:27:21,935
us wanting to do something different and better for word meaning.
我们想要做一些不同的事情，更好地理解词义。

475
00:27:21,935 --> 00:27:25,730
And, um, before getting there I just sort of wanna again sort
而且，嗯，在到达那里之前我只想再次排序

476
00:27:25,730 --> 00:27:29,495
of build a little from traditional NLP.
从传统的NLP构建一点点。

477
00:27:29,495 --> 00:27:33,275
So, traditional NLP in the context of this course sort of means
所以，传统的NLP在本课程的背景下有点手段

478
00:27:33,275 --> 00:27:39,275
Natural Language Processing up until approximately 2012.
自然语言处理直到大约2012年。

479
00:27:39,275 --> 00:27:43,640
There were some earlier antecedents but as basically, um,
有一些早期的前因，但基本上，嗯，

480
00:27:43,640 --> 00:27:47,600
in 2013 that things really began to change with
在2013年，事情真的开始发生变化

481
00:27:47,600 --> 00:27:53,060
people starting to use neural net style representations for natural language processing.
人们开始使用神经网络风格表示来进行自然语言处理。

482
00:27:53,060 --> 00:27:55,430
So, up until 2012,
所以，直到2012年，

483
00:27:55,430 --> 00:27:58,055
um, standardly you know we had words.
嗯，标准的是你知道我们有话语。

484
00:27:58,055 --> 00:28:02,210
They are just words. So, we had hotel conference motel.
他们只是言语。所以，我们有酒店会议汽车旅馆。

485
00:28:02,210 --> 00:28:06,650
They were words, and we'd have you know lexicons and put words into our model.
他们是单词，我们让你知道词典并在我们的模型中加入单词。

486
00:28:06,650 --> 00:28:12,290
Um, and in neural networks land this is referred to as a localist representation.
嗯，在神经网络中，这被称为地方主义代表。

487
00:28:12,290 --> 00:28:14,960
I'll come back to those terms again next time.
我下次再回来谈谈这些条款。

488
00:28:14,960 --> 00:28:20,015
But that's sort of meaning that for any concept there's sort of one particular,
但这有点意思，对于任何概念都有一个特别的，

489
00:28:20,015 --> 00:28:24,080
um, place which is the word hotel or the word motel.
嗯，这是酒店或汽车旅馆这个词的地方。

490
00:28:24,080 --> 00:28:26,465
A way of thinking about that is to think
一种思考方式就是思考

491
00:28:26,465 --> 00:28:29,615
about what happens when you build a machine learning model.
关于构建机器学习模型时会发生什么。

492
00:28:29,615 --> 00:28:34,759
So, if you have a categorical variable like you have words with the choice of word
所以，如果你有一个分类变量，就像你有单词选择的单词

493
00:28:34,759 --> 00:28:40,130
and you want to stick that into some kind of classifier in a Machine Learning Model,
并且你想在机器学习模型中将其粘贴到某种分类器中，

494
00:28:40,130 --> 00:28:42,905
somehow you have to code that categorical variable,
不知何故，你必须编码那个分类变量，

495
00:28:42,905 --> 00:28:46,550
and the standard way of doing it is that you code it by having
这样做的标准方法是你通过拥有它来编码

496
00:28:46,550 --> 00:28:51,275
different levels of the variable which means that you have a vector,
不同级别的变量意味着你有一个向量，

497
00:28:51,275 --> 00:28:53,840
and you have, this is the word house.
你有，这就是房子这个词。

498
00:28:53,840 --> 00:28:55,670
This is the word cat. This is the word dog.
这是单词cat。这就是单词dog。

499
00:28:55,670 --> 00:28:57,020
This is the word some chairs.
这是一些椅子这个词。

500
00:28:57,020 --> 00:28:58,190
This is the word agreeable.
这是一个令人愉快的词。

501
00:28:58,190 --> 00:28:59,465
This is the word something else.
这是别的东西。

502
00:28:59,465 --> 00:29:01,415
This is the word, um,
这个词，嗯，

503
00:29:01,415 --> 00:29:05,750
hotel, um, and this is another word for something different, right?
酒店，嗯，这是另一个不同的词，对吗？

504
00:29:05,750 --> 00:29:08,075
So that you have put a one at the position
所以你已经把一个放在了这个位置

505
00:29:08,075 --> 00:29:11,120
and neural net land we call these one-hot vectors,
和神经网络我们称之为一个热的向量，

506
00:29:11,120 --> 00:29:12,470
and so these might be, ah,
所以这些可能是，啊，

507
00:29:12,470 --> 00:29:16,250
one-hot vectors for hotel and motel.
酒店和汽车旅馆的单热矢量。

508
00:29:16,250 --> 00:29:19,040
So, there are a couple of things that are bad here.
所以，这里有一些不好的事情。

509
00:29:19,040 --> 00:29:21,005
Um, the one that's sort of, ah,
嗯，那个，啊，

510
00:29:21,005 --> 00:29:27,140
practical nuisance is you know languages have a lot of words.
实际上令人讨厌的是你知道语言有很多单词。

511
00:29:27,140 --> 00:29:30,590
Ah, so, it's sort of one of those dictionaries that you might have still had in
啊，那么，它可能是你可能还有的那些词典之一

512
00:29:30,590 --> 00:29:35,450
school that you probably have about 250,000 words in them.
学校你可能有大约250,000字。

513
00:29:35,450 --> 00:29:37,400
But you know, if you start getting into
但是你知道，如果你开始进入

514
00:29:37,400 --> 00:29:41,855
more technical and scientific English it's easy to get to a million words.
更加技术和科学的英语很容易达到一百万字。

515
00:29:41,855 --> 00:29:45,690
I mean, actually the number of words that you have in a language, um,
我的意思是，实际上你在一种语言中拥有的单词数量，嗯，

516
00:29:45,690 --> 00:29:48,620
like English is actually infinite because we have
像英语一样，实际上是无限的因为我们有

517
00:29:48,620 --> 00:29:52,220
these processes which are called derivational morphology,
这些过程称为衍生形态学，

518
00:29:52,220 --> 00:29:56,930
um, where you can make more words by adding endings onto existing words.
嗯，你可以通过在现有单词上添加结尾来创造更多单词。

519
00:29:56,930 --> 00:29:59,660
So, you know you can start with something like paternalist,
所以，你知道你可以从家长式的东西开始，

520
00:29:59,660 --> 00:30:03,470
fatherly, and then you can sort of say from maternal,
父亲，然后你可以从母亲那里说，

521
00:30:03,470 --> 00:30:06,275
you can say paternalist, or paternalistic,
你可以说是家长式的，或家长式的，

522
00:30:06,275 --> 00:30:10,070
paternalism and pa- I did it paternalistically.
家长作风和pa-我做了家长式的。

523
00:30:10,070 --> 00:30:14,255
Right? Now all of these ways that you can bake bigger words by adding more stuff into it.
对？现在所有这些方法都可以通过添加更多内容来烘焙更大的单词。

524
00:30:14,255 --> 00:30:18,905
Um, and so really you end up with an infinite space of words.
嗯，所以你最终会得到无限的文字空间。

525
00:30:18,905 --> 00:30:22,880
Um, yeah. So that's a minor problem, right?
嗯，是的这是一个小问题，对吧？

526
00:30:22,880 --> 00:30:28,275
We have very big vectors if we want to represent a sensible size vocabulary.
如果我们想要表示合理的大小词汇，我们有很大的向量。

527
00:30:28,275 --> 00:30:31,990
Um, but there's a much bigger problem than that, which is, well,
嗯，但是有一个更大的问题，那就是，嗯，

528
00:30:31,990 --> 00:30:35,200
precisely what we want to do all the time, is we want to,
正是我们想要一直做的，是我们想要的，

529
00:30:35,200 --> 00:30:38,590
sort of, understand relationships and the meaning of words.
某种，理解关系和词语的意义。

530
00:30:38,590 --> 00:30:42,380
So, you know, an obvious example of this is web search.
所以，你知道，一个明显的例子就是网络搜索。

531
00:30:42,380 --> 00:30:45,350
So, if I do a search for Seattle motel,
所以，如果我搜索西雅图汽车旅馆，

532
00:30:45,350 --> 00:30:48,710
it'd be useful if it also showed me results that had
如果它也向我展示了结果，那将是有用的

533
00:30:48,710 --> 00:30:52,655
Seattle hotel on the page and vice versa because,
西雅图酒店在页面上，反之亦然，因为，

534
00:30:52,655 --> 00:30:55,415
you know, hotels and motels pretty much the same thing.
你知道，酒店和汽车旅馆几乎是一回事。

535
00:30:55,415 --> 00:30:59,900
Um, but, you know, if we have these one-hot vectors like we had before they have
嗯，但是，你知道，如果我们拥有像我们之前那样的热门载体

536
00:30:59,900 --> 00:31:04,250
no s- similarity relationship between them, right?
他们之间没有相似的关系吧？

537
00:31:04,250 --> 00:31:05,675
So, in math terms,
所以，在数学方面，

538
00:31:05,675 --> 00:31:07,775
these two vectors are orthogonal.
这两个向量是正交的。

539
00:31:07,775 --> 00:31:10,865
No similarity relationship between them.
他们之间没有相似关系。

540
00:31:10,865 --> 00:31:12,650
Um, and so you,
嗯，你呢，

541
00:31:12,650 --> 00:31:14,705
kind of, get nowhere.
有点，无处可去。

542
00:31:14,705 --> 00:31:16,880
Now, you know, there are things that you could do,
现在，你知道，有些事你可以做，

543
00:31:16,880 --> 00:31:18,710
I- I just showed you WordNet's.
我 - 我刚给你看了WordNet的。

544
00:31:18,710 --> 00:31:20,840
WordNet's shows you some synonyms and stuff.
WordNet向您展示了一些同义词和内容。

545
00:31:20,840 --> 00:31:22,610
So that might help a bit.
所以这可能会有所帮助。

546
00:31:22,610 --> 00:31:24,035
There are other things you could do.
你还可以做其他事情。

547
00:31:24,035 --> 00:31:25,415
You could sort of say, well wait,
你可以说，等等，

548
00:31:25,415 --> 00:31:29,645
why don't we just build up a big table where we have a big table of,
为什么我们不建立一个大桌子，我们有一个大桌子，

549
00:31:29,645 --> 00:31:32,675
um, word similarities, and we could work with that.
嗯，有相似之处，我们可以解决这个问题。

550
00:31:32,675 --> 00:31:34,910
And, you know, people used to try and do that, right?
而且，你知道，人们过去常常尝试这样做，对吗？

551
00:31:34,910 --> 00:31:39,770
You know, that's sort of what Google did in 2005 or something.
你知道，这就是谷歌2005年所做的事情。

552
00:31:39,770 --> 00:31:42,080
You know, it had word similarity tables.
你知道，它有单词相似表。

553
00:31:42,080 --> 00:31:44,510
The problem with doing that is you know,
这样做的问题是你知道的，

554
00:31:44,510 --> 00:31:48,290
we were talking about how maybe we want 500,000 words.
我们在谈论我们可能想要500,000个单词。

555
00:31:48,290 --> 00:31:52,040
And if you want to build up then a word similarity table out
如果你想建立一个单词相似表

556
00:31:52,040 --> 00:31:56,060
of our pairs of words from one-hot representations,
从一个热门的陈述中我们的一对词，

557
00:31:56,060 --> 00:31:58,640
um, you- that means that the size of that table,
嗯，你 - 这意味着那张桌子的大小，

558
00:31:58,640 --> 00:32:00,380
as my math is pretty bad,
因为我的数学非常糟糕，

559
00:32:00,380 --> 00:32:02,315
is it 2,5 trillion?
是2,5万亿？

560
00:32:02,315 --> 00:32:07,130
It's some very big number of cells in your similarity, um, matrix.
你的相似性，嗯，矩阵中有一些非常大的细胞。

561
00:32:07,130 --> 00:32:09,230
So that's almost impossible to do.
所以这几乎是不可能的。

562
00:32:09,230 --> 00:32:13,715
So, what we're gonna instead do is explore a method in which,
所以，我们要做的是探索一种方法，其中，

563
00:32:13,715 --> 00:32:16,670
um, we are going to represent words as vectors,
嗯，我们要将单词表示为向量，

564
00:32:16,670 --> 00:32:18,140
in a way I'll show you just, um,
在某种程度上，我会告诉你，嗯，

565
00:32:18,140 --> 00:32:21,770
a minute in such a way that just the representation of
以这种方式表达的一分钟

566
00:32:21,770 --> 00:32:26,480
a word gives you their similarity with no further work.
一句话给你的相似之处，没有进一步的工作。

567
00:32:26,480 --> 00:32:30,635
Okay. And so that's gonna lead into these different ideas.
好的。因此，这将导致这些不同的想法。

568
00:32:30,635 --> 00:32:34,175
So, I mentioned before denotational semantics.
所以，我之前提到了指称语义。

569
00:32:34,175 --> 00:32:39,115
Here's another idea for representing the meaning of words,
这是表示单词含义的另一个想法，

570
00:32:39,115 --> 00:32:41,980
um, which is called distributional semantics.
嗯，这叫做分布式语义。

571
00:32:41,980 --> 00:32:45,140
And so the idea of distributional semantics is, well,
因此，分布式语义的概念是，

572
00:32:45,140 --> 00:32:50,900
how are we going to represent the meaning of a word is by looking at the contexts,
我们如何通过观察背景来表示一个词的意义，

573
00:32:50,900 --> 00:32:52,925
um, in which it appears.
嗯，它出现了。

574
00:32:52,925 --> 00:32:56,510
So, this is a picture of JR Firth who was a British linguist.
所以，这是一张英国语言学家JR Firth的照片。

575
00:32:56,510 --> 00:32:58,400
Um, he's famous for this saying,
嗯，他这个说法很有名，

576
00:32:58,400 --> 00:33:01,535
"You shall know a word by the company it keeps."
“你应该知道它所保留的公司的一句话。”

577
00:33:01,535 --> 00:33:06,950
Um, but another person who's very famous for developing this notion of meaning is, um,
嗯，但另一个因发展这种意义概念而闻名的人是，嗯，

578
00:33:06,950 --> 00:33:10,670
the philosopher Ludwig- Ludwig Wittgenstein in his later writings,
哲学家路德维希 - 路德维希·维特根斯坦在后来的着作中，

579
00:33:10,670 --> 00:33:13,445
which he referred to as a use theory of meeting- meaning.
他称之为会议意义的使用理论。

580
00:33:13,445 --> 00:33:16,070
Well, actually he's- he used some big German word that I don't know,
好吧，实际上他 - 他使用了一些我不知道的德语大词，

581
00:33:16,070 --> 00:33:18,530
but, um, we'll call it a use theory of meaning.
但是，嗯，我们称之为意义的使用理论。

582
00:33:18,530 --> 00:33:22,535
And, you know, essentially the point was, well, you know,
而且，你知道，基本上重点是，你知道，

583
00:33:22,535 --> 00:33:26,780
if you can explain every- if- if you can
如果你可以解释每一个 - 如果可以的话

584
00:33:26,780 --> 00:33:31,160
explain what contexts it's correct to use a certain word,
解释使用某个单词是正确的，

585
00:33:31,160 --> 00:33:34,595
versus in what contexts would be the wrong word to use,
与在什么情况下使用的错误词相比，

586
00:33:34,595 --> 00:33:38,135
this maybe gives you bad memories of doing English in high school,
这可能会让你忘记在高中做英语，

587
00:33:38,135 --> 00:33:40,490
when people said, ah, that's the wrong word to use there,
当人们说啊，这是错误的用法，

588
00:33:40,490 --> 00:33:43,205
um, well, then you understand the meaning of the word, right?
嗯，那么你理解这个词的意思吧？

589
00:33:43,205 --> 00:33:47,045
Um, and so that's the idea of distributional semantics.
嗯，这就是分布式语义的概念。

590
00:33:47,045 --> 00:33:49,790
And it's been- so one of the most successful ideas in
它一直是最成功的想法之一

591
00:33:49,790 --> 00:33:54,005
modern statistical NLP because it gives you a great way to learn about word meaning.
现代统计NLP，因为它为您提供了一个学习词义的好方法。

592
00:33:54,005 --> 00:33:56,615
And so what we're gonna do is we're going to say,
所以我们要做的就是说，

593
00:33:56,615 --> 00:33:58,925
haha, I want to know what the word banking means.
哈哈，我想知道银行这个词是什么意思。

594
00:33:58,925 --> 00:34:01,730
So, I'm gonna grab a lot of texts,
所以，我要抓很多文本，

595
00:34:01,730 --> 00:34:04,520
which is easy to do now when we have the World Wide Web,
当我们拥有万维网时，这很容易做到

596
00:34:04,520 --> 00:34:07,955
I'll find lots of sentences where the word banking is used,
我会发现许多句子都使用了bank这个词，

597
00:34:07,955 --> 00:34:12,770
Government debt problems turning into banking crises as happened in 2009.
政府债务问题转变为2009年发生的银行业危机。

598
00:34:12,770 --> 00:34:15,845
And both these- I'm just going to say all of
这两个 - 我只想说全部

599
00:34:15,845 --> 00:34:19,115
this stuff is the meaning of the word banking.
这个东西是银行这个词的意思。

600
00:34:19,115 --> 00:34:23,750
Um, that those are the contexts in which the word banking is used.
嗯，这些是使用银行业务这个词的背景。

601
00:34:23,750 --> 00:34:29,495
And that seems like very simple and perhaps even not quite right idea,
这看起来很简单，甚至可能不太正确，

602
00:34:29,495 --> 00:34:34,880
but it turns out to be a very usable idea that does a great job at capturing meaning.
但事实证明这是一个非常有用的想法，可以很好地捕捉意义。

603
00:34:34,880 --> 00:34:38,300
And so what we're gonna do is say rather than
所以我们要做的就是说而不是

604
00:34:38,300 --> 00:34:42,950
our old localist representation we're now gonna
我们现在要去的旧地方主义代表

605
00:34:42,950 --> 00:34:48,215
represent words in what we call a distributed representation.
代表我们称之为分布式表示的单词。

606
00:34:48,215 --> 00:34:51,830
And so, for the distributed representation we're still going
因此，对于分布式表示，我们仍然会继续

607
00:34:51,830 --> 00:34:55,655
to [NOISE] represent the meaning of a word as a numeric vector.
to [NOISE]表示单词作为数字向量的含义。

608
00:34:55,655 --> 00:34:59,480
But now we're going to say that the meaning of each word is,
但现在我们要说每个单词的含义是，

609
00:34:59,480 --> 00:35:01,520
ah, smallish vector, um,
啊，小矢量，嗯，

610
00:35:01,520 --> 00:35:07,760
but it's going to be a dense vector where by all of the numbers are non-zero.
但它将是一个密集的向量，其中所有数字都是非零的。

611
00:35:07,760 --> 00:35:10,010
So the meaning of banking is going to be
银行业的意义就在于此

612
00:35:10,010 --> 00:35:13,340
distributed over the dim- dimensions of this vector.
分布在这个向量的暗淡维度上。

613
00:35:13,340 --> 00:35:19,190
Um, now, my vector here is of dimension nine because I want to keep the slide, um, nice.
嗯，现在，我的向量是九维，因为我想保持幻灯片，嗯，很好。

614
00:35:19,190 --> 00:35:23,195
Um, life isn't quite that good in practice.
嗯，生活在实践中并不是那么好。

615
00:35:23,195 --> 00:35:25,970
When we do this we use a larger dimensionality,
当我们这样做时，我们使用更大的维度，

616
00:35:25,970 --> 00:35:29,075
kinda, solid the minimum that people use is 50.
有点，坚固，人们使用的最低限度是50。

617
00:35:29,075 --> 00:35:32,330
Um, a typical number that you might use on your laptop is
嗯，你可能在笔记本电脑上使用的典型号码是

618
00:35:32,330 --> 00:35:35,945
300 if you want to really max out performance,
300，如果你想真正最大化性能，

619
00:35:35,945 --> 00:35:38,885
um, maybe 1,000, 2,000, 4,000.
嗯，可能是1,000,2,000,4,000。

620
00:35:38,885 --> 00:35:42,020
But, you know, nevertheless [NOISE] orders of magnitude is
但是，你知道，然而[NOISE]数量级是

621
00:35:42,020 --> 00:35:46,320
smaller compared to a length 500,000 vector.
与长度为500,000的向量相比更小。

622
00:35:46,810 --> 00:35:51,890
Okay. So we have words with their vector representations.
好的。所以我们有他们的矢量表示的单词。

623
00:35:51,890 --> 00:35:55,790
And so since each word is going to have a vector, um,
因为每个单词都会有一个向量，嗯，

624
00:35:55,790 --> 00:36:01,160
representation we then have a vector space in which we can place all of the words.
表示我们然后有一个向量空间，我们可以在其中放置所有单词。

625
00:36:01,160 --> 00:36:03,980
Um, and that's completely unreadable, um,
嗯，这完全不可读，嗯，

626
00:36:03,980 --> 00:36:08,135
but if you zoom into the vector space it's still completely unreadable.
但如果你放大矢量空间，它仍然是完全不可读的。

627
00:36:08,135 --> 00:36:10,115
But if you zoom in a bit further,
但如果你进一步放大，

628
00:36:10,115 --> 00:36:13,100
um, you can find different parts of this space.
嗯，你可以找到这个空间的不同部分。

629
00:36:13,100 --> 00:36:16,820
So here's the part that where countries attending to,
所以这是国家参加的部分，

630
00:36:16,820 --> 00:36:18,950
um, exist Japanese, German,
嗯，存在日语，德语，

631
00:36:18,950 --> 00:36:21,950
French, Russian, British Australian American,
法国，俄罗斯，英国澳大利亚人，

632
00:36:21,950 --> 00:36:25,130
um, France, Britain, Germany et cetera.
嗯，法国，英国，德国等。

633
00:36:25,130 --> 00:36:27,770
And you can shift over to a different part of the space.
你可以转移到空间的不同部分。

634
00:36:27,770 --> 00:36:31,040
So here's a part of the space where various verbs are,
所以这里是各种动词的空间的一部分，

635
00:36:31,040 --> 00:36:33,485
so has have, had, been, be.
所以已经，过去，过去了。

636
00:36:33,485 --> 00:36:40,880
Oops. Um, um, [inaudible] be always was where.
哎呀。嗯，[听不清]总是在哪里。

637
00:36:40,880 --> 00:36:43,970
You can even see that some morphological forms are grouping together,
你甚至可以看到一些形态形式在一起组合，

638
00:36:43,970 --> 00:36:46,100
and things that sort of go together like say,
和那些喜欢说话的东西一样

639
00:36:46,100 --> 00:36:48,770
think expect to things that take those, kind of, compliment.
我希望能够接受那些带有那些，有点赞美的东西。

640
00:36:48,770 --> 00:36:50,795
He said or thought something.
他说或想到了什么。

641
00:36:50,795 --> 00:36:52,415
Um, they group together.
嗯，他们聚在一起。

642
00:36:52,415 --> 00:36:55,010
Now, what am I actually showing you here?
现在，我在这里向你展示了什么？

643
00:36:55,010 --> 00:36:57,755
Um, you know, really this was built from,
嗯，你知道，这真的是建立在，

644
00:36:57,755 --> 00:37:00,575
ah, 100 dimensional word vectors.
啊，100维词向量。

645
00:37:00,575 --> 00:37:05,630
And there is this problem is really hard to visualize 100 dimensional word vectors.
并且存在这个问题实际上难以可视化100维单词向量。

646
00:37:05,630 --> 00:37:09,860
So, what is actually happening here is these, um,
那么，这里真正发生的是这些，嗯，

647
00:37:09,860 --> 00:37:15,110
100 dimensional word vectors are being projected down into two-dimensions,
100维单词向量被投射到二维，

648
00:37:15,110 --> 00:37:17,990
and you're so- seeing the two-dimensional view,
你看到了二维视图，

649
00:37:17,990 --> 00:37:19,790
which I'll get back to later.
我稍后会回来的。

650
00:37:19,790 --> 00:37:22,400
Um, so, on the one hand, um,
嗯，一方面，嗯，

651
00:37:22,400 --> 00:37:24,410
whenever you see these pictures you should hold on to
每当你看到这些照片时，你都应该坚持下去

652
00:37:24,410 --> 00:37:26,840
the your wallet because there's a huge amount of
你的钱包，因为有大量的钱包

653
00:37:26,840 --> 00:37:31,535
detail on the original vector space that got completely killed and went away, um,
完全杀死并离开的原始矢量空间的细节，嗯，

654
00:37:31,535 --> 00:37:32,839
in the 2D projection,
在2D投影中，

655
00:37:32,839 --> 00:37:37,070
and indeed some of what push things together in the 2D,
确实有些东西在2D中推动了一起，

656
00:37:37,070 --> 00:37:39,875
um, projection may really, really,
嗯，投影可能真的，真的，

657
00:37:39,875 --> 00:37:42,590
really misrepresent what's in the original space.
真的歪曲了原始空间里的东西。

658
00:37:42,590 --> 00:37:45,740
Um, but even looking at these 2D representations,
嗯，但即使看这些2D表示，

659
00:37:45,740 --> 00:37:46,850
the overall feeling is,
整体感觉是，

660
00:37:46,850 --> 00:37:48,920
my gosh this actually sort of works, doesn't it?
我的天哪这实际上有点作品，不是吗？

661
00:37:48,920 --> 00:37:54,365
Um, we can sort of see similarities, um, between words.
嗯，我们可以在文字之间看到相似之处。

662
00:37:54,365 --> 00:38:02,375
Okay. So, um, ha- so that was the idea of what we want to do.
好的。那么，嗯，那么这就是我们想要做的事情的想法。

663
00:38:02,375 --> 00:38:04,310
Um, the next part, um,
嗯，下一部分，嗯，

664
00:38:04,310 --> 00:38:07,940
is then how do we actually go about doing it?
那么我们实际上是如何去做的呢？

665
00:38:07,940 --> 00:38:10,445
I'll pause for breath for half a minute.
我会停下来呼吸半分钟。

666
00:38:10,445 --> 00:38:12,710
Has anyone got a question they're dying to ask?
有没有人有一个他们想要问的问题？

667
00:38:12,710 --> 00:38:20,300
[NOISE] Yeah.
[NOISE]是的

668
00:38:20,300 --> 00:38:26,720
Where were the- the vectors is each, um,
那些载体在哪里，嗯，

669
00:38:26,720 --> 00:38:28,460
had a different order in each contact,
每个联系人都有不同的顺序，

670
00:38:28,460 --> 00:38:30,530
like, say the first decimal vector,
比如，说第一个十进制矢量，

671
00:38:30,530 --> 00:38:32,840
second decimal vector, are those standard
第二个十进制向量，是那些标准

672
00:38:32,840 --> 00:38:35,475
across all theory or people choose them themselves?
所有理论或人们自己选择它们？

673
00:38:35,475 --> 00:38:42,340
Um, they're not standards across NLP um and they're not chosen at all.
嗯，他们不是NLP的标准，他们根本就没有被选中。

674
00:38:42,340 --> 00:38:45,055
So what we're gonna present is a learning algorithm.
所以我们要呈现的是学习算法。

675
00:38:45,055 --> 00:38:48,430
So where we just sort of shuffle in lots of text
所以我们只是在很多文本中进行洗牌

676
00:38:48,430 --> 00:38:51,970
and miraculously these word vectors come out.
奇迹般地，这些单词向量出来了。

677
00:38:51,970 --> 00:38:57,760
And so the l- learning algorithm itself decides the dimensions.
因此，l-学习算法本身决定了维度。

678
00:38:57,760 --> 00:39:03,085
But um that actually reminds me of something I sort of meant to say which was yeah,
但是，这实际上让我想起了一些我想说的是什么，是的，

679
00:39:03,085 --> 00:39:05,425
I mean, since this is a vector space,
我的意思是，因为这是一个向量空间，

680
00:39:05,425 --> 00:39:09,580
in some sense the dimensions over the arbitrary right,
在某种意义上，任意权利的维度，

681
00:39:09,580 --> 00:39:12,570
because you can you know just have your basis vectors in
因为你可以知道你的基础载体

682
00:39:12,570 --> 00:39:15,945
any different direction and you could sort of re-represent,
任何不同的方向，你可以重新代表，

683
00:39:15,945 --> 00:39:19,715
um the words in the vector space with a different set of basics,
嗯，向量空间中的单词具有不同的基础，

684
00:39:19,715 --> 00:39:22,930
basis vectors and it'd be exactly the same vector space
基矢量，它是完全相同的矢量空间

685
00:39:22,930 --> 00:39:26,380
just sort of rotate around to your new um, vectors.
只是旋转到你的新嗯，矢量。

686
00:39:26,380 --> 00:39:30,580
So, you know, you shouldn't read too much into the sort of elements.
所以，你知道，你不应该过多地阅读这些元素。

687
00:39:30,580 --> 00:39:32,860
So, it actually turns out that because of the way a lot of
所以，事实证明，由于很多方式

688
00:39:32,860 --> 00:39:36,070
deep learning um operations work,
深入学习运营工作，

689
00:39:36,070 --> 00:39:38,170
some things they do, do element-wise.
他们做的一些事情，做元素。

690
00:39:38,170 --> 00:39:42,775
So that the dimensions do actually tend to get some meaning to them it turns out.
事实证明，维度实际上往往会对他们产生一些意义。

691
00:39:42,775 --> 00:39:46,900
But um, though I think I really wanted to say was,
但是嗯，虽然我觉得我真想说的是，

692
00:39:46,900 --> 00:39:52,240
that you know one thing we can just think of is how close things
你知道我们可以想到的一件事是多么接近

693
00:39:52,240 --> 00:39:54,250
are in the vector space and that's
是在向量空间，那是

694
00:39:54,250 --> 00:39:57,805
a notion of meaning similarity that we are going to exploit.
我们将要利用的意义相似性概念。

695
00:39:57,805 --> 00:40:00,640
But you might hope that you get more than that,
但是你可能希望得到更多，

696
00:40:00,640 --> 00:40:03,010
and you might actually think that there's meaning in
你可能会认为它有意义

697
00:40:03,010 --> 00:40:06,925
different dimensions and directions in the word vector space.
词向量空间中的不同维度和方向。

698
00:40:06,925 --> 00:40:11,335
And the answer to that is there is and I'll come back to that a bit later.
答案就是这样，我稍后会再回过头来。

699
00:40:11,335 --> 00:40:17,770
Okay. Um, so in some sense this thing that had
好的。嗯，所以从某种意义上讲，这件事情已经发生了

700
00:40:17,770 --> 00:40:22,240
the biggest impact um in sort of turning the world of
影响世界的最大影响

701
00:40:22,240 --> 00:40:27,625
NLP in a neural networks direction was that picture.
神经网络方向的NLP就是那张照片。

702
00:40:27,625 --> 00:40:32,260
Um, was this um algorithm that um
嗯，这是你的算法嗯

703
00:40:32,260 --> 00:40:37,345
Thomas Mikolov came up with in 2013 called the word2vec algorithm.
Thomas Mikolov在2013年提出了word2vec算法。

704
00:40:37,345 --> 00:40:43,210
So it wasn't the first work and having distributed representations of words.
因此，这不是第一部作品，而是分发了单词的表示。

705
00:40:43,210 --> 00:40:45,730
So there was older work from Yoshua Bengio that went
因此，来自Yoshua Bengio的旧工作已经开始了

706
00:40:45,730 --> 00:40:48,370
back to about the sort of turn on the millennium,
回到关于千禧年的转折，

707
00:40:48,370 --> 00:40:52,780
that somehow it's sort of hadn't really sort of hit the world over their head and had
不知怎的，这种情况并没有真正触及世界的头脑而已

708
00:40:52,780 --> 00:40:57,730
a huge impact and has really sort of Thomas Mikolov showed this very simple,
一个巨大的影响，真的有一点托马斯米科洛夫表明这很简单，

709
00:40:57,730 --> 00:41:00,070
very scalable way of learning
非常可扩展的学习方式

710
00:41:00,070 --> 00:41:05,005
vector representations of um words and that sort of really opened the flood gates.
um词的矢量表示和那种真正打开了洪水门。

711
00:41:05,005 --> 00:41:08,650
And so that's the algorithm that I'm going to um show now.
所以这就是我现在要展示的算法。

712
00:41:08,650 --> 00:41:15,775
Okay. So the idea of this algorithm is you start with a big pile of text.
好的。所以这个算法的想法是从一大堆文本开始。

713
00:41:15,775 --> 00:41:20,650
Um, so wherever you find you know web pages on newspaper articles or something,
嗯，所以，只要你发现你知道报纸上的文章或其他东西的网页，

714
00:41:20,650 --> 00:41:22,480
a lot of continuous text, right?
很多连续的文字吧？

715
00:41:22,480 --> 00:41:26,350
Actual sentences because we want to learn wo- word meaning context.
实际的句子，因为我们想要学习含义的语境。

716
00:41:26,350 --> 00:41:32,470
Um, NLP people call a large pile of text a corpus.
嗯，NLP人称一大堆文本为语料库。

717
00:41:32,470 --> 00:41:35,890
And I mean that's just the Latin word for body, right?
我的意思是，这只是拉丁语中的身体，对吗？

718
00:41:35,890 --> 00:41:37,915
It's a body of text.
这是一个文本正文。

719
00:41:37,915 --> 00:41:43,224
Important things to note if you want to seem really educated is in Latin,
如果你想要真正受过教育，重要的事情是拉丁语，

720
00:41:43,224 --> 00:41:46,690
this is a fourth declensions noun.
这是第四个变种名词。

721
00:41:46,690 --> 00:41:49,900
So the plural of corpus is corpora.
所以语料库的复数是语料库。

722
00:41:49,900 --> 00:41:51,190
And whereas if you say
而如果你说的话

723
00:41:51,190 --> 00:41:55,390
core Pi everyone will know that you didn't study Latin in high school.
核心Pi每个人都会知道你没有在高中学习拉丁语。

724
00:41:55,390 --> 00:42:00,490
[LAUGHTER] Um, okay.
[大笑]嗯，好的。

725
00:42:00,490 --> 00:42:06,460
Um, so right- so we then want to say that every word um
嗯，好吧 - 所以我们想说每个字嗯

726
00:42:06,460 --> 00:42:08,890
in a- in a fixed vocabulary which would just be
在一个固定的词汇表中

727
00:42:08,890 --> 00:42:12,445
the vocabulary the corpus is um represented by a vector.
语料库的词汇由向量表示。

728
00:42:12,445 --> 00:42:16,615
And we just start those vectors off as random vectors.
我们只是将这些向量作为随机向量启动。

729
00:42:16,615 --> 00:42:18,340
And so then what we're going to do is do
那么我们要做的就是做

730
00:42:18,340 --> 00:42:22,585
this big iterative algorithm where we go through each position in the text.
这个大迭代算法，我们遍历文本中的每个位置。

731
00:42:22,585 --> 00:42:24,715
We say, here's a word in the text.
我们说，这是文中的一个词。

732
00:42:24,715 --> 00:42:30,520
Let's look at the words around it and what we're going to want to do is say well,
让我们来看看它周围的单词以及我们想要做的是说得好，

733
00:42:30,520 --> 00:42:32,890
the meaning of a word is its contexts of use.
一个词的意思是它的使用背景。

734
00:42:32,890 --> 00:42:35,290
So we want the representation of the word
所以我们想要这个词的表示

735
00:42:35,290 --> 00:42:37,870
in the middle to be able to predict the words that are
在中间能够预测那些词

736
00:42:37,870 --> 00:42:43,720
around it and so we're gonna achieve that by moving the position of the word vector.
围绕它，所以我们将通过移动单词向量的位置来实现这一点。

737
00:42:43,720 --> 00:42:47,500
And we just repeat that a billion times and
我们只重复十亿次

738
00:42:47,500 --> 00:42:51,190
somehow a miracle occurs and outcomes at the end we have
不知怎的，奇迹发生了，最后我们得到了结果

739
00:42:51,190 --> 00:42:54,790
a word vector space that looks like a picture I showed where it has
一个单词矢量空间看起来像我展示它所在的图片

740
00:42:54,790 --> 00:42:59,530
a good meaning of word meet good representation of word meaning.
词语的良好含义符合词义的良好表现。

741
00:42:59,530 --> 00:43:03,090
So slightly more, um,
那么多一点，嗯，

742
00:43:03,090 --> 00:43:07,240
um, slightly more um graphically right.
嗯，稍微更正好用图形表示。

743
00:43:07,240 --> 00:43:08,440
So here's the situation.
所以情况就是这样。

744
00:43:08,440 --> 00:43:12,835
So we've got part of our corpus problems turning into banking crisis,
所以我们的部分语料库问题变成了银行危机，

745
00:43:12,835 --> 00:43:14,290
and so what we want to say is well,
所以我们想说的很好，

746
00:43:14,290 --> 00:43:17,725
we want to know the meaning of the word into and so we're going to hope that
我们想知道这个词的含义，所以我们希望如此

747
00:43:17,725 --> 00:43:21,400
its representation can be used in a way that'll
它的表示可以以一种方式使用

748
00:43:21,400 --> 00:43:24,820
make precise to predict what words appear in
准确地预测出现的单词

749
00:43:24,820 --> 00:43:28,600
the context of into because that's the meaning of into.
进入的背景因为那是进入的意义。

750
00:43:28,600 --> 00:43:31,525
And so we're going to try and make those predictions,
所以我们将尝试做出这些预测，

751
00:43:31,525 --> 00:43:34,855
see how well we can predict and then change
看看我们如何预测然后改变

752
00:43:34,855 --> 00:43:39,475
the vector representations of words in a way that we can do that prediction better.
单词的向量表示，我们可以更好地进行预测。

753
00:43:39,475 --> 00:43:41,320
And then once we've dealt with into,
然后，一旦我们处理了，

754
00:43:41,320 --> 00:43:43,765
we just go onto the next word and we say,
我们只是谈谈下一个词，我们说，

755
00:43:43,765 --> 00:43:46,060
okay, let's take banking as the word.
好的，我们以银行业为单位。

756
00:43:46,060 --> 00:43:49,795
The meaning of banking is predicting the contexts in which banking occurs.
银行业的含义是预测银行业发生的背景。

757
00:43:49,795 --> 00:43:51,265
Here's one context.
这是一个背景。

758
00:43:51,265 --> 00:43:54,550
Let's try and predict these words that occur around banking and
让我们试着预测银行和银行周围发生的这些话

759
00:43:54,550 --> 00:43:58,735
see how we do and then we'll move on again from there.
看看我们如何做，然后我们将再次从那里继续前进。

760
00:43:58,735 --> 00:44:02,470
Okay. Um, sounds easy so far.
好的。嗯，到目前为止听起来很容易。

761
00:44:02,470 --> 00:44:06,100
Um, [NOISE] now we go on and sort of do a bit more stuff.
嗯，[NOISE]现在我们继续做更多的事情。

762
00:44:06,100 --> 00:44:12,460
Okay. So overall, we have a big long corpus of capital T words.
好的。总的来说，我们有一大笔资本T字。

763
00:44:12,460 --> 00:44:17,125
So if we have a whole lot of documents we just concatenate them all together and we say,
因此，如果我们有大量文档，我们只是将它们连接在一起，我们说，

764
00:44:17,125 --> 00:44:19,014
okay, here's a billion words,
好的，这是十亿字，

765
00:44:19,014 --> 00:44:21,745
and so big long list of words.
这么长的单词列表。

766
00:44:21,745 --> 00:44:23,305
And so what we're gonna do,
那么我们要做什么，

767
00:44:23,305 --> 00:44:26,875
is for the first um product we're going to sort of
是我们要用的第一款产品

768
00:44:26,875 --> 00:44:30,954
go through all the words and then for the second product,
仔细阅读所有的话，然后是第二个产品，

769
00:44:30,954 --> 00:44:34,630
we're gonna say- we're gonna choose some fixed size window, you know,
我们要说 - 我们要选择一些固定尺寸的窗户，你知道，

770
00:44:34,630 --> 00:44:37,990
it might be five words on each side or something and we're going to try and
它可能是每个方面的五个字或什么，我们将尝试和

771
00:44:37,990 --> 00:44:42,010
predict the 10 words that are around that center word.
预测围绕该中心词的10个单词。

772
00:44:42,010 --> 00:44:44,200
And we're going to predict in the sense of trying to
我们将在尝试的意义上预测

773
00:44:44,200 --> 00:44:46,780
predict that word given the center word.
预测这个词给出了中心词。

774
00:44:46,780 --> 00:44:48,460
That's our probability model.
这是我们的概率模型。

775
00:44:48,460 --> 00:44:51,175
And so if we multiply all those things together,
所以，如果我们将所有这些东西混合在一起，

776
00:44:51,175 --> 00:44:54,610
that's our model likelihood is how good a job it
这是我们的模型可能性是一个多么好的工作

777
00:44:54,610 --> 00:44:58,375
does at predicting the words around every word.
预测每个单词周围的单词。

778
00:44:58,375 --> 00:45:01,600
And that model likelihood is going to depend
而这种模式可能性将取决于

779
00:45:01,600 --> 00:45:05,185
on the parameters of our model which we write as theta.
关于我们写成theta的模型的参数。

780
00:45:05,185 --> 00:45:07,855
And in this particular model,
在这个特定的模型中，

781
00:45:07,855 --> 00:45:10,690
the only parameters in it is actually
其中唯一的参数实际上是

782
00:45:10,690 --> 00:45:13,810
going to be the vector representations we give the words.
将成为我们给出的单词的向量表示。

783
00:45:13,810 --> 00:45:16,945
The model has absolutely no other parameters to it.
该模型绝对没有其他参数。

784
00:45:16,945 --> 00:45:20,050
So, we're just going to say we're representing
所以，我们只是说我们要代表

785
00:45:20,050 --> 00:45:23,695
a word with a vector in a vector space and that
一个单词与向量空间中的向量和那

786
00:45:23,695 --> 00:45:27,880
representation of it is its meaning and we're then going to be able to
它的代表是它的意义，然后我们就能够

787
00:45:27,880 --> 00:45:32,335
use that to predict what other words occur in a way I'm about to show you.
用它来预测其他单词会以我即将向您展示的方式出现。

788
00:45:32,335 --> 00:45:37,240
Okay. So, um, that's our likelihood and so what we do in all of
好的。所以，嗯，这是我们的可能性，所以我们在所有方面做了什么

789
00:45:37,240 --> 00:45:42,280
these models is we sort of define an objective function and then we're going to be,
这些模型是我们定义一个目标函数，然后我们将，

790
00:45:42,280 --> 00:45:45,880
I want to come up with vector representations of words in
我想提出单词的矢量表示

791
00:45:45,880 --> 00:45:50,740
such a way as to minimize our objective function.
这样可以最大限度地减少我们的目标函数。

792
00:45:50,740 --> 00:45:56,380
Um, so objective function is basically the same as what's on the top half of the slide,
嗯，所以客观功能基本上与幻灯片上半部分相同，

793
00:45:56,380 --> 00:45:58,045
but we change a couple of things.
但我们改变了一些事情。

794
00:45:58,045 --> 00:46:03,040
We stick a minus sign in front of it so we can do minimization rather than maximization.
我们在它前面贴了一个减号，这样我们就可以做到最小化而不是最大化。

795
00:46:03,040 --> 00:46:05,515
Completely arbitrary makes no difference.
完全随意没有区别。

796
00:46:05,515 --> 00:46:08,125
Um, we stick a one and T in front of it,
嗯，我们在它前面贴一个和T，

797
00:46:08,125 --> 00:46:11,800
so that we're working out the sort of average
所以我们正在努力达到平均水平

798
00:46:11,800 --> 00:46:16,150
as of a goodness of predicting for each choice of center word.
作为预测每个中心词的选择的好处。

799
00:46:16,150 --> 00:46:19,360
Again, that sort of makes no difference but it kinda keeps the scale of
再一次，这种情况没有区别，但它有点保持规模

800
00:46:19,360 --> 00:46:23,095
things ah not dependent on the size of the corpus.
事情啊不依赖于语料库的大小。

801
00:46:23,095 --> 00:46:27,235
Um, the bit that's actually important is we stick a log in front of
嗯，实际上重要的是我们在前面贴上一个日志

802
00:46:27,235 --> 00:46:31,690
the function that was up there um because it turns out that everything always gets nice.
在那里的功能，因为事实证明一切都变得很好。

803
00:46:31,690 --> 00:46:33,805
So when you stick logs and find the products
所以当你粘贴日志并找到产品时

804
00:46:33,805 --> 00:46:36,370
um when you're doing things like optimization.
嗯，当你做优化这样的事情。

805
00:46:36,370 --> 00:46:38,860
So, when we do that we then got a log of
所以，当我们这样做时，我们得到了一个日志

806
00:46:38,860 --> 00:46:42,430
all these products which will allow us to turn things you know,
所有这些产品都可以让我们转变你所知道的东西，

807
00:46:42,430 --> 00:46:46,300
into a sums of the log of this probability
成为这个概率的对数的总和

808
00:46:46,300 --> 00:46:50,755
and we'll go through that again um in just a minute.
我们会在一分钟内再次讨论这个问题。

809
00:46:50,755 --> 00:46:55,420
Okay. Um, and so if we can mi- if we can change
好的。嗯，如果我们可以，我们可以改变

810
00:46:55,420 --> 00:47:00,865
our vector representations of these words so as to minimize this J of theta,
我们对这些词的矢量表示，以便最小化这个the of the of the of the of the the

811
00:47:00,865 --> 00:47:06,110
that means we'll be good at predicting words in the context of another word.
这意味着我们善于在另一个词的语境中预测单词。

812
00:47:06,540 --> 00:47:10,450
So then, that all sounded good but it was all
那么，这一切听起来都不错，但一切都好

813
00:47:10,450 --> 00:47:13,960
dependent on having this probability function where you wanna
依赖于你想要的概率函数

814
00:47:13,960 --> 00:47:17,020
predict the probability of a word in
预测一个单词的概率

815
00:47:17,020 --> 00:47:20,635
the context given the center word and the question is,
给出中心词和问题的上下文是，

816
00:47:20,635 --> 00:47:23,620
how can you possibly do that?
你怎么可能那样做？

817
00:47:23,620 --> 00:47:28,390
Um, well um, remember what I said is actually our model is just gonna
嗯，嗯，记住我所说的实际上我们的模型就是这样

818
00:47:28,390 --> 00:47:33,655
have vector representations of words and that was the only parameters of the model.
有单词的矢量表示，这是模型的唯一参数。

819
00:47:33,655 --> 00:47:35,650
Now, that's, that's almost true.
现在，那就是，这几乎是真的。

820
00:47:35,650 --> 00:47:37,105
It's not quite true.
这不是真的。

821
00:47:37,105 --> 00:47:39,220
Um, we actually cheat slightly.
嗯，我们实际上有点作弊。

822
00:47:39,220 --> 00:47:42,400
Since we actually propose two vector representations for
因为我们实际上提出了两个向量表示

823
00:47:42,400 --> 00:47:46,600
each word and this makes it simpler to do this.
每个单词，这使得这样做更简单。

824
00:47:46,600 --> 00:47:48,070
Um, you cannot do this,
嗯，你不能这样做，

825
00:47:48,070 --> 00:47:50,620
there are ways to get around it but this is the simplest way to do it.
有办法解决它，但这是最简单的方法。

826
00:47:50,620 --> 00:47:54,610
So we have one vector for word when it's the center word that's predicting
因此，当它是预测的中心词时，我们有一个单词向量

827
00:47:54,610 --> 00:47:59,500
other words but we have a second vector for each word when it's a context word,
换句话说，但是当它是一个上下文单词时，每个单词都有第二个向量，

828
00:47:59,500 --> 00:48:01,225
so that's one of the words in context.
这是上下文中的一个词。

829
00:48:01,225 --> 00:48:02,680
So for each word type,
所以对于每个单词类型，

830
00:48:02,680 --> 00:48:06,850
we have these two vectors as center word, as context word.
我们将这两个向量作为中心词，作为上下文词。

831
00:48:06,850 --> 00:48:12,700
Um, so then we're gonna work out this probability of a word in the context,
嗯，那么我们将在上下文中找出一个单词的概率，

832
00:48:12,700 --> 00:48:14,574
given the center word,
给出中心词，

833
00:48:14,574 --> 00:48:22,105
purely in terms of these vectors and the way we do it is with this equation right here,
纯粹就这些向量而言，我们这样做的方式就是这个等式，

834
00:48:22,105 --> 00:48:25,165
which I'll explain more in just a moment.
我稍后会解释一下。

835
00:48:25,165 --> 00:48:29,650
So we're still on exactly the same situation, right?
所以我们仍然处于完全相同的情况，对吧？

836
00:48:29,650 --> 00:48:32,050
That we're wanting to work out probabilities of
我们想要弄清楚的可能性

837
00:48:32,050 --> 00:48:35,665
words occurring in the context of our center word.
在我们的中心词语中出现的单词。

838
00:48:35,665 --> 00:48:38,785
So the center word is C and the context words represented with
因此，中心词是C，用上下文词表示

839
00:48:38,785 --> 00:48:42,370
O and these [inaudible] slide notation but sort of,
O和这些[听不清]幻灯片符号，但有点，

840
00:48:42,370 --> 00:48:44,890
we're basically saying there's one kind of
我们基本上说有一种

841
00:48:44,890 --> 00:48:47,590
vector for center words is a different kind of vector
中心词的矢量是一种不同的矢量

842
00:48:47,590 --> 00:48:53,665
for context words and we're gonna work out this probabilistic prediction um,
对于上下文单词，我们要解决这个概率预测，

843
00:48:53,665 --> 00:48:56,470
in terms of these word vectors.
就这些单词向量而言。

844
00:48:56,470 --> 00:48:59,260
Okay. So how can we do that?
好的。那我们怎么做呢？

845
00:48:59,260 --> 00:49:02,950
Well, the way we do it is with this um,
那么，我们这样做的方式就是这个，

846
00:49:02,950 --> 00:49:07,870
formula here which is the sort of shape that you see over and over again um,
这里的公式是你一遍又一遍看到的那种形状嗯，

847
00:49:07,870 --> 00:49:10,300
in deep learning with categorical staff.
在深入学习与分类员工。

848
00:49:10,300 --> 00:49:12,670
So for the very center bit of it,
所以对于它的中心位，

849
00:49:12,670 --> 00:49:17,815
the bit in orange are more the same thing occurs in the um, denominator.
橙色的位是更多相同的东西发生在嗯，分母。

850
00:49:17,815 --> 00:49:21,130
What we're doing there is calculating a dot product.
我们在那里做的是计算点积。

851
00:49:21,130 --> 00:49:24,460
So, we're gonna go through the components of our vector and we're gonna
所以，我们要经历我们的矢量组件，我们会

852
00:49:24,460 --> 00:49:28,750
multiply them together and that means if um,
将它们相乘，这意味着如果嗯，

853
00:49:28,750 --> 00:49:32,800
different words have B components of the same sign,
不同的单词有相同符号的B组成部分，

854
00:49:32,800 --> 00:49:35,620
plus or minus, in the same positions,
加或减，在相同的位置，

855
00:49:35,620 --> 00:49:38,920
the dot product will be big and if
点积将很大，如果

856
00:49:38,920 --> 00:49:42,460
they have different signs or one is big and one is small,
他们有不同的标志，或者一个很大，一个很小，

857
00:49:42,460 --> 00:49:44,410
the dot product will be a lot smaller.
点积将小很多。

858
00:49:44,410 --> 00:49:48,100
So that orange part directly calculates uh,
所以橙色部分直接计算呃，

859
00:49:48,100 --> 00:49:51,670
sort of a similarity between words where
单词之间的相似之处

860
00:49:51,670 --> 00:49:55,345
the similarity is the sort of vectors looking the same, right?
相似性是那种看起来相同的向量，对吧？

861
00:49:55,345 --> 00:49:57,610
Um, and so that's the heart of it, right?
嗯，这就是它的核心，对吧？

862
00:49:57,610 --> 00:50:00,130
So we're gonna have words that have similar vectors,
所以我们会有类似载体的单词，

863
00:50:00,130 --> 00:50:04,240
IS close together in the vector space have similar meaning.
在向量空间中靠近在一起具有相似的含义。

864
00:50:04,240 --> 00:50:06,580
Um, so for the rest of it- um,
嗯，对于其余部分，嗯，

865
00:50:06,580 --> 00:50:10,330
so the next thing we do is take that number and put an X around it.
所以我们接下来要做的就是拿这个数字并在它周围放一个X.

866
00:50:10,330 --> 00:50:12,100
So, um, the exponential has
所以，嗯，指数有

867
00:50:12,100 --> 00:50:15,295
this nice property that no matter what number you stick into it,
这个不错的属性，无论你坚持到底是什么号码，

868
00:50:15,295 --> 00:50:17,845
because the dot product might be positive or negative,
因为点积可能是正数或负数，

869
00:50:17,845 --> 00:50:20,890
it's gonna come out as a positive number and if
它会作为一个正数出来，如果

870
00:50:20,890 --> 00:50:24,160
we eventually wanna get a probability, um, that's really good.
我们最终想得到一个概率，嗯，这真的很好。

871
00:50:24,160 --> 00:50:28,450
If we have positive numbers and not negative numbers, um, so that's good.
如果我们有正数而不是负数，那么这很好。

872
00:50:28,450 --> 00:50:33,370
Um, then the third part of which is the bid in blue is we wanted to have
嗯，其中第三部分是蓝色的出价是我们想要的

873
00:50:33,370 --> 00:50:36,070
probabilities and probabilities are meant to add up to
概率和概率意味着加起来

874
00:50:36,070 --> 00:50:39,970
one and so we do that in the standard, dumbest possible way.
一个，所以我们以标准，最愚蠢的方式做到这一点。

875
00:50:39,970 --> 00:50:42,205
We sum up what this quantity is,
我们总结一下这个数量是多少，

876
00:50:42,205 --> 00:50:47,080
that every different word in our vocabulary and we divide through by
我们的词汇中的每一个不同的词都是我们分过来的

877
00:50:47,080 --> 00:50:52,315
it and so that normalizes things and turns them into a probability distribution.
它使事物正常化并将它们变成概率分布。

878
00:50:52,315 --> 00:50:54,685
Yeah, so there's sort of in practice,
是的，所以有一些实践，

879
00:50:54,685 --> 00:50:55,990
there are two parts.
有两个部分。

880
00:50:55,990 --> 00:50:59,110
There's the orange part which is this idea of using
橙色部分是这个使用的想法

881
00:50:59,110 --> 00:51:03,580
dot product and a vector space as our similarity measure between words
点积和向量空间作为词之间的相似性度量

882
00:51:03,580 --> 00:51:07,480
and then the second part is all the rest of it where we feed it
然后第二部分是我们喂它的所有其余部分

883
00:51:07,480 --> 00:51:11,665
through what we refer to a news all the time as a softmax distribution.
通过我们所说的新闻作为softmax发行版。

884
00:51:11,665 --> 00:51:17,530
So the two parts of the expen normalizing gives you a softmax distribution.
因此，费用标准化的两个部分为您提供softmax分布。

885
00:51:17,530 --> 00:51:22,120
Um, and softmax functions will sort of map any numbers into
嗯，softmax函数会将任何数字映射到

886
00:51:22,120 --> 00:51:26,950
a probability distribution always for the two reasons that I gave and so,
概率分布总是出于我给出的两个原因，因此，

887
00:51:26,950 --> 00:51:30,000
it's referred to as a softmax um,
它被称为softmax um，

888
00:51:30,000 --> 00:51:33,525
because it works like a softmax, right?
因为它像softmax一样工作，对吧？

889
00:51:33,525 --> 00:51:35,040
So if you have numbers,
所以，如果你有数字，

890
00:51:35,040 --> 00:51:39,735
you could just say what's the max of these numbers, um,
你可以说这些数字的最大值是什么，嗯，

891
00:51:39,735 --> 00:51:46,810
and you know that's sort of a hot- if you sort of map your original numbers into,
而且你知道这有点热 - 如果你将原始数字映射到，

892
00:51:46,810 --> 00:51:49,390
if it's the max of the max and everything else is zero,
如果它是最大值的最大值，其他一切都为零，

893
00:51:49,390 --> 00:51:51,160
that's sort of a hard max.
这是一个很难的最大值。

894
00:51:51,160 --> 00:51:56,935
Um, soft- this is a softmax because the exponenti- you know,
嗯，软 - 这是一个softmax，因为指数 - 你知道，

895
00:51:56,935 --> 00:52:00,310
if you sort of imagine this but- if we just ignore the problem
如果你有点想象这个但是 - 如果我们忽略了这个问题

896
00:52:00,310 --> 00:52:04,315
negative numbers for a moment and you got rid of the exp, um,
一段时间的负数，你摆脱了exp，嗯，

897
00:52:04,315 --> 00:52:06,220
then you'd sort of coming out with
然后你就会出来

898
00:52:06,220 --> 00:52:09,640
a probability distribution but by and large it's so be fairly
一个概率分布，但总的来说它是公平的

899
00:52:09,640 --> 00:52:12,070
flat and wouldn't particularly pick out the max of
平坦，并不会特别挑选出最大值

900
00:52:12,070 --> 00:52:15,310
the different XI numbers whereas when you exponentiate them,
不同的XI数字，而当你取代它们时，

901
00:52:15,310 --> 00:52:18,670
that sort of makes big numbers way bigger and so, this,
那种大数字会变大，所以，这个，

902
00:52:18,670 --> 00:52:25,990
this softmax sort of mainly puts mass where the max's or the couple of max's are.
这种softmax主要是将质量放在最大值或最大值的最大值。

903
00:52:25,990 --> 00:52:29,920
Um, so that's the max part and a soft part is that this isn't
嗯，所以这是最大的部分和软的部分是这不是

904
00:52:29,920 --> 00:52:34,900
a hard decisions still spreads a little bit of probability mass everywhere else.
一个艰难的决定仍然会在其他地方传播一点概率。

905
00:52:34,900 --> 00:52:40,540
Okay, so now we have uh, loss function.
好的，现在我们有呃，失去功能。

906
00:52:40,540 --> 00:52:45,160
We have a loss function with a probability model on the inside that we can
我们有一个损失函数，我们可以在内部使用概率模型

907
00:52:45,160 --> 00:52:50,230
build and so what we want to be able to do is then um,
构建，所以我们想要做的就是嗯，

908
00:52:50,230 --> 00:52:55,690
move our vector representations of words around
移动我们的单词的向量表示

909
00:52:55,690 --> 00:53:01,075
so that they are good at predicting what words occur in the context of other words.
这样他们就能善于预测在其他词语中出现的词语。

910
00:53:01,075 --> 00:53:06,400
Um, and so, at this point what we're gonna do is optimization.
嗯，在这一点上，我们要做的就是优化。

911
00:53:06,400 --> 00:53:10,465
So, we have vector components of different words.
所以，我们有不同单词的向量组件。

912
00:53:10,465 --> 00:53:13,180
We have a very high-dimensional space again but here,
我们再次拥有一个非常高维度的空间，但在这里，

913
00:53:13,180 --> 00:53:16,270
I've just got two for the picture and we're gonna wanna
我刚刚有两张照片，我们想要的

914
00:53:16,270 --> 00:53:19,510
say how- how can we minimize this function and we're going to
说怎么样我们可以最小化这个功能，我们会去

915
00:53:19,510 --> 00:53:23,920
want to jiggle the numbers that are used in the word representations in
想要摆动单词表示中使用的数字

916
00:53:23,920 --> 00:53:28,990
such a way that we're walking down the slope of this space.
这样一种方式，我们走在这个空间的斜坡上。

917
00:53:28,990 --> 00:53:32,095
I walking down the gradient and um,
我走下梯度，嗯，

918
00:53:32,095 --> 00:53:37,330
then we're gonna minimize the function we found good representations for words.
那么我们将最大限度地减少我们找到好的词汇表示的功能。

919
00:53:37,330 --> 00:53:39,775
So doing this for this case,
所以这样做，

920
00:53:39,775 --> 00:53:42,070
we want to make a very big vector in
我们想要制作一个非常大的载体

921
00:53:42,070 --> 00:53:45,400
a very high-dimensional vector space of all the parameters of
一个非常高维的矢量空间的所有参数

922
00:53:45,400 --> 00:53:48,730
our model and the only parameters that this model
我们的模型和这个模型的唯一参数

923
00:53:48,730 --> 00:53:53,095
has is literally the vector space representations of words.
字面上是字的向量空间表示。

924
00:53:53,095 --> 00:53:56,170
So if there are a 100 dimensional word representations,
所以，如果有一个100维的单词表示，

925
00:53:56,170 --> 00:53:59,320
they're sort of a 100 parameters for aardvark and context,
它们是土豚和环境的100个参数，

926
00:53:59,320 --> 00:54:03,400
100 parameters for the word a- in context et cetera going through,
在上下文等单词a-的100个参数，

927
00:54:03,400 --> 00:54:08,020
100 parameters for the word aardvark [NOISE] as a center word et cetera,
单词aardvark [NOISE]作为中心词等100个参数，

928
00:54:08,020 --> 00:54:12,520
et cetera through that gives us a high big vector of parameters to
等等，为我们提供了一个很大的参数向量

929
00:54:12,520 --> 00:54:18,265
optimize and we're gonna run this optimization and then um, move them down.
优化，我们将运行此优化然后嗯，将它们向下移动。

930
00:54:18,265 --> 00:54:23,740
Um, [NOISE] yeah so that's essentially what you do.
嗯，[NOISE]是的，所以这基本上就是你做的。

931
00:54:23,740 --> 00:54:26,365
Um, I sort of wanted to go through um,
嗯，我有点想通过嗯，

932
00:54:26,365 --> 00:54:28,990
the details of this um,
这个细节，

933
00:54:28,990 --> 00:54:32,440
just so we've kind of gone through things concretely to
所以我们已经具体地经历了一些事情

934
00:54:32,440 --> 00:54:36,070
make sure everyone is on the same page.
确保每个人都在同一页面上。

935
00:54:36,070 --> 00:54:39,475
Um, so I suspect that, you know,
嗯，所以我怀疑，你知道，

936
00:54:39,475 --> 00:54:43,510
if I try and do this concretely,
如果我试着具体地这样做，

937
00:54:43,510 --> 00:54:45,865
um, there are a lot of people um,
嗯，有很多人嗯，

938
00:54:45,865 --> 00:54:50,830
that this will bore and some people that are- will bore very badly,
这会让人厌烦，而且有些人会非常糟糕，

939
00:54:50,830 --> 00:54:54,415
um, so I apologize for you,
嗯，所以我为你道歉，

940
00:54:54,415 --> 00:54:55,810
um, but you know,
嗯，但你知道，

941
00:54:55,810 --> 00:54:59,140
I'm hoping and thinking that there's probably
我希望并且认为可能存在

942
00:54:59,140 --> 00:55:02,650
some people who haven't done as much of this stuff recently
有些人最近没有做过这么多的事

943
00:55:02,650 --> 00:55:05,740
and it might just actually be good to do it concretely
具体地说，实际上可能真的很好

944
00:55:05,740 --> 00:55:09,760
and get everyone up to speed right at the beginning. Yeah?
并让每个人在开始时加快速度。是吗？

945
00:55:09,760 --> 00:55:14,680
[inaudible] how do we calculate [inaudible] specifically?
[听不清]我们如何具体计算[音频不清晰]？

946
00:55:14,680 --> 00:55:20,275
Well, so, we- so the way we calculate the,
那么，我们 - 所以我们计算的方式，

947
00:55:20,275 --> 00:55:26,050
the U and V vectors is we're literally going to start with a random vector for
U和V向量我们实际上将从随机向量开始

948
00:55:26,050 --> 00:55:33,010
each word and then we iteratively going to change those vectors a little bit as we learn.
每个单词然后我们迭代地在我们学习的时候稍微改变那些向量。

949
00:55:33,010 --> 00:55:37,135
And the way we're going to work out how to change them is we're gonna say,
我们要弄清楚如何改变它们的方式是我们要说的，

950
00:55:37,135 --> 00:55:42,400
"I want to do optimization," and that is going to be implemented as okay.
“我想做优化”，这将是可以实现的。

951
00:55:42,400 --> 00:55:44,830
We have the current vectors for each word.
我们有每个单词的当前向量。

952
00:55:44,830 --> 00:55:51,550
Let me do some calculus to work out how I could change the word vectors, um, to mean,
让我做一些微积分来弄清楚如何改变单词vector，嗯，意思是，

953
00:55:51,550 --> 00:55:55,780
that the word vectors would calculate a higher probability for
单词向量将计算更高的概率

954
00:55:55,780 --> 00:56:00,160
the words that actually occur in contexts of this center word.
在这个中心词的背景中实际出现的词。

955
00:56:00,160 --> 00:56:01,855
And we will do that,
我们会这样做，

956
00:56:01,855 --> 00:56:03,925
and we'll do it again and again and again,
我们会一次又一次地这样做，

957
00:56:03,925 --> 00:56:06,760
and then will eventually end up with good word vectors.
然后最终将以良好的单词向量结束。

958
00:56:06,760 --> 00:56:08,260
Thank you for that question,
谢谢你的提问，

959
00:56:08,260 --> 00:56:10,780
cause that's a concept that you're meant to have understood.
因为这是一个你应该理解的概念。

960
00:56:10,780 --> 00:56:13,330
Is that how this works and maybe I didn't
这是如何工作的，也许我没有

961
00:56:13,330 --> 00:56:16,645
explain that high-level recipe well enough, yeah.
高级食谱解释得很好，是的。

962
00:56:16,645 --> 00:56:20,410
Okay, so yeah, so let's just go through it. So, we've seen it, right?
好的，是的，所以让我们来看看吧。所以，我们已经看到了，对吧？

963
00:56:20,410 --> 00:56:24,070
So, we had this formula that we wanted to maximize, you know,
所以，我们有这个公式，我们想要最大化，你知道，

964
00:56:24,070 --> 00:56:32,410
our original function which was the product of T equals one to T,
我们的原始函数是T的乘积等于1到T，

965
00:56:32,410 --> 00:56:35,995
and then the product of the words, uh,
然后是单词的产物，呃，

966
00:56:35,995 --> 00:56:40,720
position minus M less than or equal to J,
位置减去M小于或等于J，

967
00:56:40,720 --> 00:56:42,460
less than or equal to M,
小于或等于M，

968
00:56:42,460 --> 00:56:46,000
J not equal to zero of, um,
J不等于零，嗯，

969
00:56:46,000 --> 00:56:51,640
the probability of W. At prime at T
W的概率。在T处的素数

970
00:56:51,640 --> 00:56:57,700
plus J given WT according to the parameters of our model.
根据我们模型的参数，加上给定WT。

971
00:56:57,700 --> 00:57:01,330
Okay, and then we'd already seen that we were gonna convert that
好的，然后我们已经看到我们要转换它

972
00:57:01,330 --> 00:57:05,515
into the function that we're going to use where we have J of Theta,
进入我们将要使用的功能，我们有The of theta，

973
00:57:05,515 --> 00:57:15,490
where we had the minus one on T. Of the sum of T equals one to T of the sum of minus M,
我们在T上有负一个.T的总和等于负M之和的一到T，

974
00:57:15,490 --> 00:57:17,770
less than or equal to J less than or equal to M,
小于或等于J小于或等于M，

975
00:57:17,770 --> 00:57:27,400
J not equal to zero of the log of the probability of W times T, plus J, W,
J不等于W乘以T的概率的对数的零，再加上J，W，

976
00:57:27,400 --> 00:57:31,840
T. Okay, so we had that and then we'd had
好的，所以我们有了，然后我们就有了

977
00:57:31,840 --> 00:57:36,490
this formula that the probability of the outside word given
这个公式表示外部单词给出的概率

978
00:57:36,490 --> 00:57:46,360
the context word is this formula we just went through of xu ot vc over
上下文单词是我们刚刚通过xu ot vc over的公式

979
00:57:46,360 --> 00:57:56,770
the sum of W equals one to the vocabulary size of xu wt vc.
W的总和等于xu wt vc的词汇量。

980
00:57:56,770 --> 00:57:59,530
Okay, so that's sort of our model.
好的，这就是我们的模型。

981
00:57:59,530 --> 00:58:03,835
We want to min- minimize this.
我们想最小化这个。

982
00:58:03,835 --> 00:58:11,230
So, we wanna minimize this and we want to minimize that by changing these parameters.
因此，我们希望最小化这一点，我们希望通过更改这些参数来最小化这一点。

983
00:58:11,230 --> 00:58:15,415
And these parameters are the contents of these vectors.
并且这些参数是这些向量的内容。

984
00:58:15,415 --> 00:58:17,635
And so, what we want to do now,
那么，我们现在想做什么，

985
00:58:17,635 --> 00:58:23,560
is do calculus and we wanna say let's work out in terms of these parameters which are,
是微积分，我们想说让我们根据这些参数来解决这些问题，

986
00:58:23,560 --> 00:58:25,960
u and v vectors, um,
你和v矢量，嗯，

987
00:58:25,960 --> 00:58:30,115
for the current values of the parameters which we initialized randomly.
对于我们随机初始化的参数的当前值。

988
00:58:30,115 --> 00:58:32,050
Like what's the slope of the space?
就像空间的斜率一样？

989
00:58:32,050 --> 00:58:33,490
Where is downhill?
下坡在哪里？

990
00:58:33,490 --> 00:58:35,770
Because if we can work out downhill is,
因为如果我们可以在下坡工作，

991
00:58:35,770 --> 00:58:39,115
we got just gotta walk downhill and our model gets better.
我们得走下坡路，我们的模型变得更好。

992
00:58:39,115 --> 00:58:42,010
So, we're gonna take derivatives and work out what
所以，我们要采取衍生工具并找出解决方案

993
00:58:42,010 --> 00:58:45,610
direction downhill is and then we wanna walk that way, yeah.
下坡的方向是，然后我们想走那条路，是的。

994
00:58:45,610 --> 00:58:50,230
So, why do we wanna maximize that probable edge and like,
所以，为什么我们想要最大限度地利用这个可能的边缘，

995
00:58:50,230 --> 00:58:51,805
like going through every word,
喜欢听完每一个字，

996
00:58:51,805 --> 00:58:57,640
it's like [inaudible] given the [inaudible]
鉴于[听不清]，它就像[音频不清晰]

997
00:58:57,640 --> 00:58:59,665
So, well, so, so,
所以，好吧，所以，所以，

998
00:58:59,665 --> 00:59:02,905
I'm wanting to achieve this, um,
我想要实现这个，嗯，

999
00:59:02,905 --> 00:59:08,395
what I want to achieve for my distributional notion of meaning is,
我想要实现的分布式意义概念是，

1000
00:59:08,395 --> 00:59:11,500
I have a meaningful word, a vector.
我有一个有意义的词，一个向量。

1001
00:59:11,500 --> 00:59:16,810
And that vector knows what words occur in the context of,
并且该向量知道在上下文中出现的单词，

1002
00:59:16,810 --> 00:59:19,525
um, a word- of itself.
嗯，这个词本身。

1003
00:59:19,525 --> 00:59:23,020
And knowing what words occur in its context means,
并且知道在其上下文中出现的单词意味着，

1004
00:59:23,020 --> 00:59:24,790
it can accurately give
它可以准确地给出

1005
00:59:24,790 --> 00:59:28,945
a high probability estimate to those words that occur in the context,
对上下文中出现的单词的高概率估计，

1006
00:59:28,945 --> 00:59:32,319
and it will give low probability estimates
它会给出低概率估计

1007
00:59:32,319 --> 00:59:35,050
to words that don't typically occur in the context.
通常不会出现在上下文中的单词。

1008
00:59:35,050 --> 00:59:37,240
So, you know, if the word is bank,
所以，你知道，如果这个词是银行，

1009
00:59:37,240 --> 00:59:39,549
I'm hoping that words like branch,
我希望像分支这样的话，

1010
00:59:39,549 --> 00:59:41,575
and open, and withdrawal,
开放和退出

1011
00:59:41,575 --> 00:59:43,360
will be given high probability,
会有很高的概率，

1012
00:59:43,360 --> 00:59:45,445
cause they tend to occur with the word bank.
因为它们倾向于与银行一起出现。

1013
00:59:45,445 --> 00:59:49,950
And I'm hoping that some other words, um,
而且我希望还有其他一些词，嗯，

1014
00:59:49,950 --> 00:59:52,740
like neural network or something have
像神经网络或其他东西

1015
00:59:52,740 --> 00:59:57,970
a lower probability because they don't tend to occur with the word bank.
概率较低，因为它们不倾向于出现在单词bank中。

1016
00:59:58,290 --> 01:00:01,525
Okay, um, does that make sense?
好的，嗯，这有意义吗？

1017
01:00:01,525 --> 01:00:01,780
Yeah.
是啊。

1018
01:00:01,780 --> 01:00:03,730
Yeah. And the other thing I was,
是啊。而另一件事我，

1019
01:00:03,730 --> 01:00:06,865
I'd forgotten meant to comment was, you know, obviously,
我忘了打算评论，你知道，显然，

1020
01:00:06,865 --> 01:00:10,480
we're not gonna be able to do this super well or it's just not gonna be able,
我们不能很好地做到这一点，或者它只是不能够，

1021
01:00:10,480 --> 01:00:13,180
that we can say all the words in the context is going to
我们可以说上下文中的所有单词都会发生

1022
01:00:13,180 --> 01:00:15,880
be this word with probability 0,97, right?
这个词的概率为0,97，对吗？

1023
01:00:15,880 --> 01:00:19,750
Because we're using this one simple probability distribution
因为我们正在使用这个简单的概率分布

1024
01:00:19,750 --> 01:00:23,230
to predict all words in our context.
预测我们背景中的所有单词。

1025
01:00:23,230 --> 01:00:27,880
So, in particular, we're using it to predict 10 different words generally, right?
所以，特别是，我们一般用它来预测10个不同的词，对吧？

1026
01:00:27,880 --> 01:00:32,425
So, at best, we can kind of be giving sort of five percent chance to one of them, right?
所以，充其量，我们可以为其中一个提供5％的机会，对吧？

1027
01:00:32,425 --> 01:00:33,820
We can't possibly be,
我们不可能，

1028
01:00:33,820 --> 01:00:35,950
so guessing right every time.
所以每次都猜对了。

1029
01:00:35,950 --> 01:00:37,390
Um, and well, you know,
嗯，嗯，你知道，

1030
01:00:37,390 --> 01:00:40,255
they're gonna be different contexts with different words in them.
他们将在不同的语境中使用不同的词语。

1031
01:00:40,255 --> 01:00:44,610
So, you know, it's gonna be a very loose model,
所以，你知道，这将是一个非常宽松的模型，

1032
01:00:44,610 --> 01:00:48,660
but nevertheless, we wanna capture the fact that, you know,
但是，我们想要捕捉到这样一个事实，你知道，

1033
01:00:48,660 --> 01:00:51,330
withdrawal is much more likely, um,
退出的可能性更大，嗯，

1034
01:00:51,330 --> 01:00:57,580
to occur near the word bank than something like football.
发生在银行附近而不是像足球这样的东西。

1035
01:00:57,580 --> 01:01:01,030
That's, you know, basically what our goal is.
那就是，你知道，基本上我们的目标是什么。

1036
01:01:01,030 --> 01:01:07,360
Okay, um, yes, so we want to maximize this,
好的，嗯，是的，所以我们想要最大化这个，

1037
01:01:07,360 --> 01:01:12,610
by minimizing this, which means we then want to do some calculus to work this out.
通过最小化这个，这意味着我们然后想要做一些微积分来解决这个问题。

1038
01:01:12,610 --> 01:01:14,740
So, what we're then gonna do is,
所以，我们接下来要做的是，

1039
01:01:14,740 --> 01:01:16,720
that we're going to say, well,
我们要说，好吧，

1040
01:01:16,720 --> 01:01:19,495
these parameters are our word vectors
这些参数是我们的单词向量

1041
01:01:19,495 --> 01:01:22,630
and we're gonna sort of want to move these word vectors,
我们会想要移动这些单词向量，

1042
01:01:22,630 --> 01:01:28,180
um, to, um, work things out as to how to, um, walk downhill.
嗯，对，嗯，如何工作，嗯，走下坡路。

1043
01:01:28,180 --> 01:01:32,440
So, the case that I'm going to do now is gonna look at the parameters of
那么，我现在要做的就是看看参数

1044
01:01:32,440 --> 01:01:38,275
this center word vc and work out how to do things with respect to it.
这个中心词汇vc并找出如何处理它的事情。

1045
01:01:38,275 --> 01:01:40,750
Um, now, that's not the only thing that you wanna do,
嗯，现在，这不是你唯一想做的事情，

1046
01:01:40,750 --> 01:01:44,905
you also want to work out the slope with respect to the uo vector.
你也想找出关于uo向量的斜率。

1047
01:01:44,905 --> 01:01:47,965
Um, but I'm not gonna do that because time in class is going to run out.
嗯，但是我不会这样做，因为课堂上的时间会用完。

1048
01:01:47,965 --> 01:01:49,750
So, it'd be really good if you did that one at
所以，如果你做的那个真的很棒

1049
01:01:49,750 --> 01:01:51,715
home and then you'd feel much more competent.
回家然后你会感觉更有能力。

1050
01:01:51,715 --> 01:01:57,130
Right, so then, um, so what I'm wanting you to do is work out the partial derivative with
是的，那么，嗯，所以我想让你做的是找出偏导数

1051
01:01:57,130 --> 01:02:03,205
respect to my vc vector representation of this quantity,
尊重我的vc矢量表示这个数量，

1052
01:02:03,205 --> 01:02:04,810
that we were just looking at.
我们只是在看。

1053
01:02:04,810 --> 01:02:08,290
Which is, um, the quantity in here,
那是，嗯，这里的数量，

1054
01:02:08,290 --> 01:02:11,980
um, where we're taking the log of that quantity.
嗯，我们在那里记录那个数量。

1055
01:02:11,980 --> 01:02:17,560
Right, the log of the x of u,
对了，你的x的日志，

1056
01:02:17,560 --> 01:02:20,140
o, T, v, c,
o，T，v，c，

1057
01:02:20,140 --> 01:02:26,830
over the sum of W equals one to V of the x of u,
在W的总和上等于你的x的一到五，

1058
01:02:26,830 --> 01:02:30,220
o, T, v, c. Okay,
o，T，v，c。好的，

1059
01:02:30,220 --> 01:02:33,219
so this, um, so now we have a log of the division,
所以这个，嗯，所以现在我们有了一个分区的日志，

1060
01:02:33,219 --> 01:02:35,695
so that's easy to rewrite, um,
这样很容易改写，嗯，

1061
01:02:35,695 --> 01:02:39,595
that we have a partial derivative of the log of
我们有一个日志的偏导数

1062
01:02:39,595 --> 01:02:47,560
the numerator minus and
分子减去和

1063
01:02:47,560 --> 01:02:49,690
I can distribute the partial derivative.
我可以分发偏导数。

1064
01:02:49,690 --> 01:02:53,395
So, I can have minus the partial derivative,
所以，我可以减去偏导数，

1065
01:02:53,395 --> 01:02:56,680
um, of the denominator,
嗯，分母，

1066
01:02:56,680 --> 01:02:59,710
um, which is log of this thing.
嗯，这是这个东西的日志。

1067
01:02:59,710 --> 01:03:08,865
[NOISE]
[噪声]

1068
01:03:08,865 --> 01:03:18,190
Okay. Um, so this is sort of what was the numerator and this is what was the denominator.
好的。嗯，所以这就是分子，这就是分母。

1069
01:03:19,190 --> 01:03:27,060
Okay. So, um, the part that was the numerator is really easy.
好的。所以，嗯，作为分子的部分真的很容易。

1070
01:03:27,060 --> 01:03:29,130
In fact maybe I can fit it in here.
事实上，也许我可以在这里适应它。

1071
01:03:29,130 --> 01:03:33,450
Um, so log on exp are just inverses of each other,
嗯，所以登录exp只是彼此的反转，

1072
01:03:33,450 --> 01:03:34,800
so they cancel out.
所以他们取消了。

1073
01:03:34,800 --> 01:03:43,650
So, we've got the partial derivative of U_o T V_c.
所以，我们得到了U_o T V_c的偏导数。

1074
01:03:43,650 --> 01:03:47,460
Okay, so this point I should, um, just, um,
好的，所以这一点我应该，嗯，只是，嗯，

1075
01:03:47,460 --> 01:03:51,630
remind people right that this V_c here's a vector of- um,
提醒人们这个V_c这里是一个矢量，

1076
01:03:51,630 --> 01:03:56,130
it's still a vector right because we had a 100 dimensional representation of a word.
它仍然是一个向量，因为我们有一个单词的100维表示。

1077
01:03:56,130 --> 01:04:00,330
Um, so this is doing multivariate calculus.
嗯，所以这是做多元微积分。

1078
01:04:00,330 --> 01:04:02,790
Um, so you know, if you're,
嗯，你知道，如果你是，

1079
01:04:02,790 --> 01:04:04,530
if you at all, um,
如果你有，嗯，

1080
01:04:04,530 --> 01:04:06,105
remember any of this stuff,
记住这些东西，

1081
01:04:06,105 --> 01:04:08,175
you can say, "Ha this is trivial".
你可以说，“哈，这是微不足道的”。

1082
01:04:08,175 --> 01:04:12,390
The answer to that is you are done, um and that's great.
答案就是你完成了，嗯，这很棒。

1083
01:04:12,390 --> 01:04:14,955
But you know, if you're, um, feeling, um,
但是你知道，如果你是，嗯，感觉，嗯，

1084
01:04:14,955 --> 01:04:17,550
not so good on all of this stuff, um,
所有这些东西都不太好，嗯，

1085
01:04:17,550 --> 01:04:19,125
and you wanna sort of, um,
你想要那样的，嗯，

1086
01:04:19,125 --> 01:04:22,440
cheat a little on the side and try and work out what it is,
在旁边作弊并尝试弄清楚它是什么，

1087
01:04:22,440 --> 01:04:24,180
um, you can sort of say,
嗯，你可以说，

1088
01:04:24,180 --> 01:04:25,980
"Well, let me um,,
“好吧，我，嗯，

1089
01:04:25,980 --> 01:04:28,380
work out the partial derivative,
算出偏导数，

1090
01:04:28,380 --> 01:04:34,200
um with respect to one element of this vector like the first element of this vector".
嗯关于这个向量的一个元素，就像这个向量的第一个元素“。

1091
01:04:34,200 --> 01:04:42,869
Well, what I actually got here for this dot product is I have U_o one times V_c one,
那么，我实际上为这个点产品得到的是我有U_o一次V_c one，

1092
01:04:42,869 --> 01:04:49,560
plus U_o two times V_c two plus dot, dot,
加U_o两次V_c两加点，点，

1093
01:04:49,560 --> 01:04:56,910
dot plus U_o 100 times V_c 100, right,
点加U_o 100倍V_c 100，对，

1094
01:04:56,910 --> 01:05:02,535
and I'm finding the partial derivative of this with respect to V_c one,
我找到了关于V_c的偏导数，

1095
01:05:02,535 --> 01:05:05,490
and hopefully remember that much calculus from high school
并且希望从高中那里记住那么多的微积分

1096
01:05:05,490 --> 01:05:09,135
of none of these terms involve V_c one.
这些术语都不涉及V_c。

1097
01:05:09,135 --> 01:05:12,660
So, the only thing that's left is this U_o one,
所以，唯一剩下的就是这个U_o，

1098
01:05:12,660 --> 01:05:15,960
and that's what I've got there for this dimension.
这就是我在这个方面所拥有的。

1099
01:05:15,960 --> 01:05:17,850
So, this particular parameter.
所以，这个特殊的参数。

1100
01:05:17,850 --> 01:05:23,265
But I don't only want to do the first component of the V_c vector,
但我不仅想要做V_c矢量的第一个组件，

1101
01:05:23,265 --> 01:05:26,745
I also want to do the second component of the V_c vector et cetera,
我还想做V_c矢量等的第二个组件，

1102
01:05:26,745 --> 01:05:30,630
which means I'm going to end up with all of them
这意味着我将最终得到所有这些

1103
01:05:30,630 --> 01:05:35,685
turning up in precisely one of these things.
恰好出现在其中一件事中。

1104
01:05:35,685 --> 01:05:41,190
Um, and so the end result is I get the vector U_o.
嗯，最终结果是我得到了矢量U_o。

1105
01:05:41,190 --> 01:05:43,620
Okay. Um, but you know,
好的。嗯，但是你知道，

1106
01:05:43,620 --> 01:05:47,220
if you're sort of getting confused and your brain is falling apart,
如果你有点困惑，你的大脑正在崩溃，

1107
01:05:47,220 --> 01:05:52,050
I think it can be sort of kind of useful to re- reduce things to sort of um,
我认为将某些东西重新减少到某种程度是有用的，

1108
01:05:52,050 --> 01:05:58,275
single dimensional calculus and actually sort of play out what's actually happening.
单维微积分实际上可以解决实际发生的事情。

1109
01:05:58,275 --> 01:06:00,840
Um, anyway, this part was easy.
嗯，无论如何，这部分很容易。

1110
01:06:00,840 --> 01:06:03,540
The numerator, we get um, U_o.
分子，我们得到你，U_o。

1111
01:06:03,540 --> 01:06:08,085
Um, so things aren't quite so nice when we do the denominator.
嗯，所以当我们分母时，事情并不是那么好。

1112
01:06:08,085 --> 01:06:11,640
So we now want to have this, um, B_d,
所以我们现在想要这个，嗯，B_d，

1113
01:06:11,640 --> 01:06:17,010
V_c of the log of the sum of W equals
W的总和的对数的V_c等于

1114
01:06:17,010 --> 01:06:22,845
one to the P_x of U_o T V_c.
一个到U_o T V_c的P_x。

1115
01:06:22,845 --> 01:06:25,800
Okay. So, now at this point,
好的。那么，现在在这一点上，

1116
01:06:25,800 --> 01:06:27,450
I'm not quite so pretty.
我不是很漂亮。

1117
01:06:27,450 --> 01:06:31,035
We've got this log sum X combination that you see a lot,
我们有这个日志和X组合，你看到很多，

1118
01:06:31,035 --> 01:06:35,640
and so at this point you have to remember that there was E, the chain rule.
所以在这一点上你必须记住E，链规则。

1119
01:06:35,640 --> 01:06:38,520
Okay. So, what we can say is here's you know,
好的。所以，我们可以说这是你知道的，

1120
01:06:38,520 --> 01:06:42,540
our function F and here is the body of the function,
我们的函数F，这里是函数体，

1121
01:06:42,540 --> 01:06:46,245
and so what we want to do is um,
所以我们想做的是嗯，

1122
01:06:46,245 --> 01:06:48,630
do it in two stages.
分两个阶段完成。

1123
01:06:48,630 --> 01:06:51,570
Um, so that at the end of the day,
嗯，所以在一天结束时，

1124
01:06:51,570 --> 01:06:53,430
we've got this V_c at the end.
我们最后得到了这个V_c。

1125
01:06:53,430 --> 01:06:57,105
So, we have sort of some function here.
所以，我们在这里有一些功能。

1126
01:06:57,105 --> 01:06:59,910
There's ultimately a function of V_c,
最终有V_c的功能，

1127
01:06:59,910 --> 01:07:02,220
and so we gonna do with a chain rule.
所以我们要做一个连锁规则。

1128
01:07:02,220 --> 01:07:05,040
We'll say the chain rule is we first take
我们会说链条规则是我们首先采用的

1129
01:07:05,040 --> 01:07:09,135
the derivative of this outside thing putting in this body,
这个外面的东西放在这个身体的衍生物，

1130
01:07:09,135 --> 01:07:13,680
and then we remember that the derivative of log is one on X.
然后我们记得日志的衍生物是X上的一个。

1131
01:07:13,680 --> 01:07:22,920
So, we have one over the sum of W equals one to V of the exp of U_o T V_c
因此，我们有一个超过W的总和，等于U_o T V_c的exp的一到五

1132
01:07:22,920 --> 01:07:26,640
and then we need to multiply that by then taking
然后我们需要乘以那个

1133
01:07:26,640 --> 01:07:32,610
the derivative of the inside part which is um,
内部的衍生物是嗯，

1134
01:07:32,610 --> 01:07:34,750
what we have here.
我们在这里有什么

1135
01:07:40,490 --> 01:07:44,850
Okay. Times the derivative of the inside part with
好的。用内部部分的衍生物来计算

1136
01:07:44,850 --> 01:07:48,600
the important reminder that you need to do a change of variables,
重要提示你需要改变变量，

1137
01:07:48,600 --> 01:07:53,460
and for the inside part use a different variable that you're summing over.
而对于内部部分使用您正在总结的另一个变量。

1138
01:07:53,460 --> 01:08:00,810
Okay. So, now we're trying to find the derivative of a sum of X.
好的。所以，现在我们试图找到X之和的导数。

1139
01:08:00,810 --> 01:08:05,055
The first thing that we can do is v-very easy.
我们能做的第一件事就是非常容易。

1140
01:08:05,055 --> 01:08:08,865
We can move the derivative inside a sum.
我们可以在一个总和内移动导数。

1141
01:08:08,865 --> 01:08:14,430
So, we can rewrite that and have at the sum first of the X equals one to
所以，我们可以重写那个，并且在X的第一个等于1

1142
01:08:14,430 --> 01:08:20,430
V of the partial derivatives with respect to V_c of the [inaudible].
相对于[听不见]的V_c的偏导数的V.

1143
01:08:20,430 --> 01:08:22,575
Um, so that's a little bit of progress.
嗯，这是一点点进步。

1144
01:08:22,575 --> 01:08:26,730
Um and that point we have to sort of do the chain rule again, right.
嗯，那一点，我们必须再做一次链规则吧。

1145
01:08:26,730 --> 01:08:33,210
So, here is our function and here's the thing in it again which is some function of V_c.
所以，这是我们的功能，这里的内容再次是V_c的一些功能。

1146
01:08:33,210 --> 01:08:37,605
So, we again want to do um, the chain rule.
所以，我们再次想做嗯，链规则。

1147
01:08:37,605 --> 01:08:41,340
So, [NOISE] we then have well,
那么，[NOISE]我们就好了，

1148
01:08:41,340 --> 01:08:45,720
the derivative of X um, is exp.
X um的衍生物是exp。

1149
01:08:45,720 --> 01:08:54,630
So, we gonna have the sum of X equals one to V of exp of U_x T V_c,
所以，我们要求X的总和等于U_x T V_c的exp的V，

1150
01:08:54,630 --> 01:09:00,150
and then we're going to multiply that by the partial derivative with
然后我们将乘以偏导数乘以

1151
01:09:00,150 --> 01:09:05,700
respect to T V_c of the inside U_x T V_c.
关于内部U_x T V_c的T V_c。

1152
01:09:05,700 --> 01:09:08,160
Well, we saw that one before, so,
好吧，我们之前看过那个，所以，

1153
01:09:08,160 --> 01:09:13,200
the derivative of that is U- well,
那个衍生物就是U-，

1154
01:09:13,200 --> 01:09:16,320
yeah, U_x because we're doing it through a different X, right.
是的，U_x因为我们是通过不同的X来做的，对吧。

1155
01:09:16,320 --> 01:09:18,780
This then becomes out as U_x,
然后它变成U_x，

1156
01:09:18,780 --> 01:09:23,850
and so we have the sum of the X equals one to
所以我们得到X的总和等于1

1157
01:09:23,850 --> 01:09:30,030
V of this exp U X T B C times the U_of X.
这个exp UXTBC的V乘以U_of X.

1158
01:09:30,030 --> 01:09:34,995
Okay. So, by doing the chain rule twice, we've got that.
好的。所以，通过做两次链式规则，我们已经做到了。

1159
01:09:34,995 --> 01:09:38,190
So, now if we put it together, you know,
所以，现在，如果我们把它放在一起，你知道，

1160
01:09:38,190 --> 01:09:43,050
the derivative of V_c with respect of the whole thing,
关于整个事物，V_c的衍生物，

1161
01:09:43,050 --> 01:09:46,500
this log of the probability of O given C, right.
这个给出C的概率O的对数，对。

1162
01:09:46,500 --> 01:09:51,210
That for the numerator it was just U_o,
对于分子而言，它只是U_o，

1163
01:09:51,210 --> 01:09:54,030
and then we're subtracting,
然后我们减去，

1164
01:09:54,030 --> 01:09:57,645
we had this term here, um,
我们这里有这个词，嗯，

1165
01:09:57,645 --> 01:09:59,730
which is sort of a denominator,
这是一种分母，

1166
01:09:59,730 --> 01:10:03,870
and then we have this term here which is the numerator.
然后我们这个术语就是分子。

1167
01:10:03,870 --> 01:10:07,725
So, we're subtracting in the numerator,
所以，我们在分子中减去，

1168
01:10:07,725 --> 01:10:12,270
we have the sum of X equals one to V of
我们有X等于1到V的总和

1169
01:10:12,270 --> 01:10:18,765
the exp of U_x T V_c times U_x,
U_x T的表达式V_c乘以U_x，

1170
01:10:18,765 --> 01:10:25,395
and then in the denominator, we have um,
然后在分母中，我们有，嗯，

1171
01:10:25,395 --> 01:10:35,920
the sum of W equals one to V of exp of U_w T V_c.
W之和等于U_w T V_c的exp与V之比。

1172
01:10:36,350 --> 01:10:40,035
Um, okay, so we kind of get that.
嗯，好的，所以我们得到了。

1173
01:10:40,035 --> 01:10:44,025
Um, oh wait. Yeah. Yeah, I've gotten.
嗯，等等。是啊。是的，我已经得到了。

1174
01:10:44,025 --> 01:10:45,900
Yeah, that's right. Um, okay.
是啊，没错。嗯，好的。

1175
01:10:45,900 --> 01:10:52,170
We kind of get that and then we can sort of just re-arrange this a little.
我们得到了那个，然后我们可以稍微重新安排一下。

1176
01:10:52,170 --> 01:10:56,475
So, we can have this sum right out front,
所以，我们可以把这笔款项拿出来，

1177
01:10:56,475 --> 01:11:03,284
and we can say that this is sort of a big sum of X equals one to V,
我们可以说这是X等于一到V的一大部分，

1178
01:11:03,284 --> 01:11:09,870
and we can sort of take that U_x out the end and say, okay.
我们可以把U_x拿出来然后说，好吧。

1179
01:11:09,870 --> 01:11:13,155
Let's call that put over here a U_x,
让我们称之为U_x，

1180
01:11:13,155 --> 01:11:15,090
and if we do that,
如果我们这样做，

1181
01:11:15,090 --> 01:11:20,295
sort of an interesting thing has happened because look right here,
发生了一件有趣的事情，因为看看这里，

1182
01:11:20,295 --> 01:11:25,830
we've rediscovered exactly the same form
我们重新发现了完全相同的形式

1183
01:11:25,830 --> 01:11:31,425
that we use as our probability distribution for predicting the probability of words.
我们用它作为概率分布来预测单词的概率。

1184
01:11:31,425 --> 01:11:37,860
So, this is now simply the probability of X given C according to our model.
因此，根据我们的模型，这现在只是给定C的X的概率。

1185
01:11:37,860 --> 01:11:46,155
Um, so we can rewrite this and say that what we're getting is U_o minus the sum of
嗯，所以我们可以改写这个，并说我们得到的是U_o减去总和

1186
01:11:46,155 --> 01:11:54,795
X equals one to V of the probability of X given C times U_x.
X等于给定C乘以U_x的X概率的一到五。

1187
01:11:54,795 --> 01:11:58,755
This has a kind of an interesting meaning if you think about it.
如果你想一想，这有一种有趣的意义。

1188
01:11:58,755 --> 01:12:01,365
So, this is actually giving us, you know,
所以，这实际上是在给我们，你知道，

1189
01:12:01,365 --> 01:12:04,200
our slope in this multi-dimensional space
我们在这个多维空间的斜坡

1190
01:12:04,200 --> 01:12:07,215
and how we're getting that slope is we're taking
以及我们如何获得这个斜坡是我们正在采取的

1191
01:12:07,215 --> 01:12:11,280
the observed representation of
观察到的代表性

1192
01:12:11,280 --> 01:12:18,450
the context word and we're subtracting from that what our model thinks um,
上下文单词，我们从中减去我们的模型所认为的，

1193
01:12:18,450 --> 01:12:20,955
the context should look like.
上下文应该是这样的。

1194
01:12:20,955 --> 01:12:24,465
What does the model think that the context should look like?
模型认为上下文应该是什么样的？

1195
01:12:24,465 --> 01:12:27,330
This part here is formal in expectation.
这部分是正式的期望。

1196
01:12:27,330 --> 01:12:31,395
So, what you're doing is you're finding the weighted average
所以，你正在做的是找到加权平均值

1197
01:12:31,395 --> 01:12:36,375
of the models of the representations of each word,
每个单词的表示模型，

1198
01:12:36,375 --> 01:12:39,990
multiplied by the probability of it in the current model.
乘以当前模型中它的概率。

1199
01:12:39,990 --> 01:12:45,315
So, this is sort of the expected context word according to our current model,
所以，这是根据我们当前模型的预期上下文单词，

1200
01:12:45,315 --> 01:12:47,460
and so we're taking the difference between
所以我们正在采取区别

1201
01:12:47,460 --> 01:12:52,170
the expected context word and the actual context word that showed up,
预期的上下文单词和出现的实际上下文单词，

1202
01:12:52,170 --> 01:12:55,560
and that difference then turns out to exactly give
然后，这种差异结果恰好给出了

1203
01:12:55,560 --> 01:12:58,890
us the slope as to which direction we should be
我们应该是哪个方向的斜率

1204
01:12:58,890 --> 01:13:01,050
walking changing the words
走路改变话语

1205
01:13:01,050 --> 01:13:06,715
representation in order to improve our model's ability to predict.
表示以提高我们模型的预测能力。

1206
01:13:06,715 --> 01:13:11,565
Okay. Um, so we'll,
好的。嗯，所以我们会，

1207
01:13:11,565 --> 01:13:14,100
um, assignment two, um, yeah.
嗯，任务二，嗯，是的。

1208
01:13:14,100 --> 01:13:18,060
So, um, it'll be a great exercise for you guys,
所以，嗯，对你们来说这将是一次很棒的运动，

1209
01:13:18,060 --> 01:13:20,115
um, to in- um,
嗯，嗯，

1210
01:13:20,115 --> 01:13:22,830
to try and do that for the cen-, wait,
尝试为中心做这件事，等等，

1211
01:13:22,830 --> 01:13:26,640
um I did the center words trying to look context words as well
嗯我做了中心词试图看上下文词

1212
01:13:26,640 --> 01:13:31,125
and show you that you can do the same kind of piece of math and have it work out.
并告诉你，你可以做同样的数学，并让它成功。

1213
01:13:31,125 --> 01:13:35,655
Um, if I've just got a few minutes left at the end.
嗯，如果我最后还剩下几分钟的话。

1214
01:13:35,655 --> 01:13:43,320
Um, what I just wanted to show you if I can get all of this to work right.
嗯，我只是想告诉你，如果我能让所有这些工作正常的话。

1215
01:13:43,320 --> 01:13:49,950
Um, let's go [inaudible] this way.
嗯，让我们以这种方式[听不清]。

1216
01:13:49,950 --> 01:13:53,590
Okay, find my.
好的，找到我的。

1217
01:13:54,200 --> 01:14:00,075
Okay. Um, so I just wanted to just show you a quick example.
好的。嗯，所以我只是想给你一个简单的例子。

1218
01:14:00,075 --> 01:14:01,935
So, for the first assignment,
所以，对于第一次任务，

1219
01:14:01,935 --> 01:14:04,170
um, again it's an iPython Notebook.
嗯，这是一个iPython笔记本。

1220
01:14:04,170 --> 01:14:09,015
So, if you're all set up you sort of can do Jupyter Notebook.
所以，如果你们都设置好了，你可以选择Jupyter Notebook。

1221
01:14:09,015 --> 01:14:12,945
Um, and you have some notebook.
嗯，你有一些笔记本。

1222
01:14:12,945 --> 01:14:16,630
Um, here's my little notebook I'm gonna show you,
嗯，这是我要告诉你的小笔记本，

1223
01:14:17,180 --> 01:14:23,620
um, and the trick will be to make this big enough that people can see it.
嗯，诀窍是让人们可以看到它。

1224
01:14:30,940 --> 01:14:35,530
That readable? [LAUGHTER] Okay, um,
那可读吗？ [大笑]好的，嗯，

1225
01:14:35,530 --> 01:14:39,210
so right so, so Numpy is the sort of,
所以就这样，所以Numpy是那种，

1226
01:14:39,210 --> 01:14:41,930
um, do math package in Python.
嗯，用Python做数学包。

1227
01:14:41,930 --> 01:14:43,120
You'll want to know about that.
你会想知道这件事。

1228
01:14:43,120 --> 01:14:44,445
If you don't know about it.
如果你不知道它。

1229
01:14:44,445 --> 01:14:46,440
Um, Matplotlib is sort of the,
嗯，Matplotlib有点像，

1230
01:14:46,440 --> 01:14:49,040
one of the most basic graphing package
最基本的图形包之一

1231
01:14:49,040 --> 01:14:51,755
if you don't know about that you're going to want to know about it.
如果你不知道你会想知道它。

1232
01:14:51,755 --> 01:14:55,900
This is sort of an IPython or Jupyter special that
这是一种特殊的IPython或Jupyter

1233
01:14:55,900 --> 01:14:59,755
lets you have an interactive matplotlib um, inside.
让你在里面有一个交互式matplotlib嗯。

1234
01:14:59,755 --> 01:15:03,675
And if you want to get fancy you can play it- play with your graphic styles.
如果你想获得幻想，你可以玩它 - 玩你的图形样式。

1235
01:15:03,675 --> 01:15:06,615
Um, there's that.
嗯，就是这样。

1236
01:15:06,615 --> 01:15:10,465
Scikit-learn is kind of a general machine learning package.
Scikit-learn是一种通用的机器学习包。

1237
01:15:10,465 --> 01:15:13,350
Um, Gensim isn't a deep learning package.
嗯，Gensim不是一个深入的学习包。

1238
01:15:13,350 --> 01:15:17,590
Gensim is kind of a word similarity package which started off um,
Gensim是一个单词相似性包，起初是，

1239
01:15:17,590 --> 01:15:20,760
with um, methods like Latent Dirichlet analysis.
与嗯，Latent Dirichlet分析等方法。

1240
01:15:20,760 --> 01:15:22,530
If you know about that from modelling words
如果你从建模词汇中知道这一点

1241
01:15:22,530 --> 01:15:25,940
similarities that sort of grown as a good package um,
类似的东西，有点成长为一个良好的包，嗯，

1242
01:15:25,940 --> 01:15:28,570
for doing um, word vectors as well.
为了做，嗯，单词向量。

1243
01:15:28,570 --> 01:15:31,650
So, it's quite often used for word vectors and
因此，它经常用于单词向量和

1244
01:15:31,650 --> 01:15:36,105
word similarities that sort of efficient for doing things at large-scale.
与大规模做事有效的词汇相似性。

1245
01:15:36,105 --> 01:15:37,720
Um, yeah.
嗯，是的

1246
01:15:37,720 --> 01:15:41,360
So, I haven't yet told you about will next time we have
所以，我还没有告诉过你下次我们的意愿

1247
01:15:41,360 --> 01:15:46,400
our own homegrown form of word vectors which are the GloVe word vectors.
我们自己开发的单词向量形式，即GloVe单词向量。

1248
01:15:46,400 --> 01:15:51,270
I'm using them not because it really matters for what I'm showing but you know,
我使用它们并不是因为它对我所展示的内容非常重要，但你知道，

1249
01:15:51,270 --> 01:15:55,745
these vectors are conveniently small.
这些载体很方便。

1250
01:15:55,745 --> 01:16:00,470
It turns out that the vectors that Facebook and Google
事实证明，Facebook和谷歌的载体

1251
01:16:00,470 --> 01:16:05,940
distribute are extremely large vocabulary and extremely high dimensional.
分布是非常大的词汇量和极高的维度。

1252
01:16:05,940 --> 01:16:08,940
So take me just too long to load them in
所以我花了太长时间加载它们

1253
01:16:08,940 --> 01:16:12,860
the last five minutes of this class where conveniently uh,
这个班的最后五分钟，方便呃，

1254
01:16:12,860 --> 01:16:16,865
in our Stanford vectors we have a 100 dimensional vectors, um,
在斯坦福大学的载体中，我们有100维向量，嗯，

1255
01:16:16,865 --> 01:16:19,160
and 50 dimensional vectors which are kinda
和50维矢量有点

1256
01:16:19,160 --> 01:16:21,755
good for doing small things on a laptop frankly.
善于在笔记本电脑上做小事坦诚。

1257
01:16:21,755 --> 01:16:27,330
Um, so, what I'm doing here is Gensim doesn't natively support
嗯，所以，我在这里做的是Gensim本身不支持

1258
01:16:27,330 --> 01:16:30,210
GloVe vectors but they actually provide a utility that
GloVe向量，但它们实际上提供了一个实用程序

1259
01:16:30,210 --> 01:16:33,390
converts the GloVe file format to the word2vec file format.
将GloVe文件格式转换为word2vec文件格式。

1260
01:16:33,390 --> 01:16:40,285
So I've done that. And then I've loaded a pre-trained model of word vectors.
所以我做到了。然后我加载了一个预训练的单词向量模型。

1261
01:16:40,285 --> 01:16:44,430
Um, and, so this is what they call a keyed vector.
嗯，所以这就是他们所谓的键控向量。

1262
01:16:44,430 --> 01:16:46,890
And so, the keyed vector is nothing fancy.
所以，键控矢量没什么特别的。

1263
01:16:46,890 --> 01:16:51,660
It's just you have words like potato and there's a vector that hangs off each one.
只是你有像马铃薯这样的词，每个人都有一个矢量。

1264
01:16:51,660 --> 01:16:55,435
So it's really just sort of a big dictionary with a vector for each thing.
所以它真的只是一个大字典，每个东西都有一个向量。

1265
01:16:55,435 --> 01:16:58,690
But, so this model has been a trained model where
但是，这个模型已经成为训练有素的模型

1266
01:16:58,690 --> 01:17:02,230
we just use the kind of algorithm we looked at and,
我们只是使用我们看到的那种算法，

1267
01:17:02,230 --> 01:17:06,730
you know, trained at billions of times fiddling our word vectors.
你知道，数十亿次训练我们的单词向量。

1268
01:17:06,730 --> 01:17:11,255
Um, and once we have one we can then, um,
嗯，一旦我们有了，我们可以，嗯，

1269
01:17:11,255 --> 01:17:14,265
ask questions like, we can say,
我们可以说，问问题，

1270
01:17:14,265 --> 01:17:17,110
what is the most similar word to some other words?
与其他一些词最相似的词是什么？

1271
01:17:17,110 --> 01:17:19,650
So we could take something like, um,
所以我们可以采取类似的东西，嗯，

1272
01:17:19,650 --> 01:17:23,175
what are the most similar words to Obama let's say?
与奥巴马最相似的话是什么？

1273
01:17:23,175 --> 01:17:25,770
And we get back Barrack, Bush, Clinton,
我们回到巴拉克，布什，克林顿，

1274
01:17:25,770 --> 01:17:29,040
McCain, Gore, Hillary Dole, Martin, Henry.
麦凯恩，戈尔，希拉里多尔，马丁，亨利。

1275
01:17:29,040 --> 01:17:31,425
That seems actually kind of interesting.
这看起来实际上很有趣。

1276
01:17:31,425 --> 01:17:34,050
These factors from a few years ago.
这些因素来自几年前。

1277
01:17:34,050 --> 01:17:37,150
So we don't have a post- post-Obama staff.
所以我们没有后奥巴马的工作人员。

1278
01:17:37,150 --> 01:17:40,750
I mean if you put in another word, um, you know,
我的意思是，如果你再说一句话，嗯，你知道，

1279
01:17:40,750 --> 01:17:44,100
we can put in something like banana and we get coconut,
我们可以加入像香蕉这样的东西，我们得到椰子，

1280
01:17:44,100 --> 01:17:46,600
mango, bananas, potato, pineapple.
芒果，香蕉，土豆，菠萝。

1281
01:17:46,600 --> 01:17:49,430
We get kind of tropical food.
我们得到一种热带食物。

1282
01:17:49,430 --> 01:17:54,070
So, you can actually- you can actually ask uh,
所以，你实际上可以 - 你真的可以问呃，

1283
01:17:54,070 --> 01:17:56,995
for being dissimilar to words.
与文字不同。

1284
01:17:56,995 --> 01:17:59,700
By itself dissimilar isn't very useful.
本身不相似并不是很有用。

1285
01:17:59,700 --> 01:18:04,550
So if I ask most similar and I say um,
所以，如果我问大多数类似的，我说嗯，

1286
01:18:04,550 --> 01:18:09,290
negative equals, um, banana,
负等于，嗯，香蕉，

1287
01:18:09,290 --> 01:18:14,720
um, I'm not sure what your concept of what's most dissimilar to,
嗯，我不确定你最接近什么的概念，

1288
01:18:14,720 --> 01:18:16,620
um, banana is, but you know,
嗯，香蕉是，但是你知道，

1289
01:18:16,620 --> 01:18:22,655
actually by itself you don't get anything useful out of this, um,
实际上，你自己没有得到任何有用的东西，嗯，

1290
01:18:22,655 --> 01:18:28,000
because, um, you just so get these weird really rare words um,
因为，嗯，你只是这样得到这些奇怪的非常罕见的词，嗯，

1291
01:18:28,000 --> 01:18:31,440
which, um, [LAUGHTER] definitely weren't the ones who are thinking of.
哪，嗯，[大笑]绝对不是那些想到的人。

1292
01:18:31,440 --> 01:18:37,570
Um, but it turns out you can do something really useful with this negative idea
嗯，但事实证明你可以用这个消极的想法做一些非常有用的事情

1293
01:18:37,570 --> 01:18:39,000
which was one of
这是其中之一

1294
01:18:39,000 --> 01:18:44,175
the highly celebrated results of word vectors when they first started off.
单词向量在他们刚开始时非常着名的结果。

1295
01:18:44,175 --> 01:18:50,205
And that was this idea that there is actually dimensions of meaning in this space.
这就是这个想法，在这个空间中实际上有意义的维度。

1296
01:18:50,205 --> 01:18:54,820
And so this was the most celebrated example um, which was look,
所以这是最着名的例子，看起来，

1297
01:18:54,820 --> 01:18:59,985
what we could do is we could start with the word king and subtract
我们能做的是我们可以从单词king开始减去

1298
01:18:59,985 --> 01:19:05,355
from it the meaning of man and then we could add to it the meaning of woman.
从它的意义，然后我们可以增加女人的意义。

1299
01:19:05,355 --> 01:19:09,110
And then we could say which word in our vector space as
然后我们可以说我们的向量空间中的哪个词为

1300
01:19:09,110 --> 01:19:13,060
most similar in meaning to that word.
与该词最相似的含义。

1301
01:19:13,060 --> 01:19:15,810
And that would be a way of sort of doing analogies.
这将是一种类比的方式。

1302
01:19:15,810 --> 01:19:18,640
Would be able to do the, um, analogy,
能够做，嗯，类比，

1303
01:19:18,640 --> 01:19:22,050
man is the king as woman is to what?
男人是国王，女人是为了什么？

1304
01:19:22,050 --> 01:19:26,500
And so, the way we're gonna do that is to say we want to be similar to king
所以，我们要这样做的方式就是说我们希望与国王相似

1305
01:19:26,500 --> 01:19:31,220
and woman because they're both positive ones and far away from man.
和女人，因为他们都是积极的，远离人类。

1306
01:19:31,220 --> 01:19:35,185
And so, we could do that manually,
所以，我们可以手动完成

1307
01:19:35,185 --> 01:19:36,950
here is said manually,
这是手动说的，

1308
01:19:36,950 --> 01:19:41,050
most similar positive woman king, negative man.
最相似的积极女人王，消极的男人。

1309
01:19:41,050 --> 01:19:45,410
And we can run this and lo and behold it produces queen.
我们可以运行这个并且看到它产生女王。

1310
01:19:45,410 --> 01:19:48,570
To make that a little bit easier I defined this analogy,
为了使这更容易一点，我定义了这个类比，

1311
01:19:48,570 --> 01:19:53,485
um, analogy predicates so I can run other ones.
嗯，类比谓词所以我可以运行其他的。

1312
01:19:53,485 --> 01:19:59,095
And so I can run another one like analogy Japan Japanese,
所以我可以运行另一个像类比日本日语，

1313
01:19:59,095 --> 01:20:01,160
Austria is to Austrian.
奥地利是奥地利人。

1314
01:20:01,160 --> 01:20:03,125
Um, and you know,
嗯，你知道，

1315
01:20:03,125 --> 01:20:07,150
I think it's fair to say that when people first
我认为，当人们第一时，这是公平的

1316
01:20:07,150 --> 01:20:10,950
saw that you could have this simple piece of math and run it,
看到你可以用这个简单的数学运算它，

1317
01:20:10,950 --> 01:20:12,950
and learn meanings of words.
并学习单词的意义。

1318
01:20:12,950 --> 01:20:18,465
I mean it actually just sort of blew people's minds how effective this was.
我的意思是它实际上只是让人们想到这是多么有效。

1319
01:20:18,465 --> 01:20:22,030
You know. Like there- there's is no mirrors and strings here, right?
你懂。就像那里 - 这里没有镜子和弦乐，对吧？

1320
01:20:22,030 --> 01:20:24,225
You know it's not that I have a separate-
你知道并不是我有一个单独的 -

1321
01:20:24,225 --> 01:20:28,330
a special sort of list in my Python where there's a difficult I'm looking up,
我的Python里有一个特殊的列表，我很难找到，

1322
01:20:28,330 --> 01:20:30,240
er, for Austria Austrian,
呃，奥地利奥地利，

1323
01:20:30,240 --> 01:20:31,910
uh, and things like that.
呃，等等。

1324
01:20:31,910 --> 01:20:35,310
But somehow these vector representations are
但不知何故，这些矢量表示是

1325
01:20:35,310 --> 01:20:38,760
such that it is actually encoding these semantic relationships,
这样它实际上编码了这些语义关系，

1326
01:20:38,760 --> 01:20:40,920
you know, so you can try different ones,
你知道，所以你可以尝试不同的，

1327
01:20:40,920 --> 01:20:43,360
you know, like it's not that only this one works.
你知道，就像它不仅仅是这个有效。

1328
01:20:43,360 --> 01:20:46,185
I can put in France, it says French.
我说法语可以放在法国。

1329
01:20:46,185 --> 01:20:49,780
I can put in Germany, it says German,
我可以把它放在德国，它说德语，

1330
01:20:49,780 --> 01:20:54,590
I can put in Australia not Austria and it says Australian,
我可以在澳大利亚而不是奥地利，它说澳大利亚，

1331
01:20:54,590 --> 01:20:59,480
you know that somehow if you want this vector representations of words that
你知道如果你想要这个单词的矢量表示

1332
01:20:59,480 --> 01:21:04,815
for sort of these ideas like understanding the relationships between words,
对于这些想法，比如理解单词之间的关系，

1333
01:21:04,815 --> 01:21:10,595
you're just doing this vector space manipulation on these 100 dimensional numbers,
你只是在这些100维数字上做这个向量空间操作，

1334
01:21:10,595 --> 01:21:15,830
that it actually knows about them.This not only the similarities of word meanings but
它实际上知道它们。这不仅仅是词义的相似之处

1335
01:21:15,830 --> 01:21:18,255
actually different semantic relationships
实际上是不同的语义关系

1336
01:21:18,255 --> 01:21:21,635
between words like country names and their peoples.
在诸如国名和人民之间的词汇之间。

1337
01:21:21,635 --> 01:21:23,850
And yeah that's actually pretty amazing.
是的，这真的很神奇。

1338
01:21:23,850 --> 01:21:31,340
It really-you know, it's sort of surprising that running such a dumb algorithm on um,
它真的 - 你知道，在um上运行这样一个愚蠢的算法有点令人惊讶，

1339
01:21:31,340 --> 01:21:35,100
vectors of numbers could capture so well the meaning of words.
数字向量可以很好地捕捉到词语的含义。

1340
01:21:35,100 --> 01:21:38,160
And so that's sort of became the foundation of a lot of sort
所以这就成了很多种类的基础

1341
01:21:38,160 --> 01:21:41,355
of modern distributed neural representations of words.
现代分布式词语神经表征。

1342
01:21:41,355 --> 01:21:42,630
Okay I'll stop there.
好的，我会在那里停下来。

1343
01:21:42,630 --> 01:21:46,700
Thanks a lot guys and see you on Thursday. [NOISE]
非常感谢，周四见到你。 [噪声]

1344


